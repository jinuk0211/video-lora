{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emhz6TsC0WMH",
        "outputId": "84e5ea50-067e-4d53-8374-71c3d7d6fca7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ\n",
            "From (redirected): https://drive.google.com/uc?id=1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ&confirm=t&uuid=f10adbce-9426-4d3a-90b1-be1971e6bfad\n",
            "To: /content/vlora.zip\n",
            "100% 717M/717M [00:09<00:00, 73.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gdown  # 설치 안되어 있다면 먼저 설치\n",
        "!gdown 1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ\n",
        "\n",
        "# !gdown --folder 1miYmYG8DwNQHMamcfBwJdzISCgH4C1nL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "!cp -r \"/content/drive/MyDrive/vlora\" ./myfolder\n",
        "!unzip -r vlora.zip myfolder -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PT-ToHt1dt3",
        "outputId": "0b3e50ff-771c-4344-9e74-061a8a506228"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n",
            "\n",
            "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\n",
            "  Default action is to extract files in list, except those in xlist, to exdir;\n",
            "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\n",
            "\n",
            "  -p  extract files to pipe, no messages     -l  list files (short format)\n",
            "  -f  freshen existing files, create none    -t  test compressed archive data\n",
            "  -u  update files, create if necessary      -z  display archive comment only\n",
            "  -v  list verbosely/show version info       -T  timestamp archive to latest\n",
            "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\n",
            "modifiers:\n",
            "  -n  never overwrite existing files         -q  quiet mode (-qq => quieter)\n",
            "  -o  overwrite files WITHOUT prompting      -a  auto-convert any text files\n",
            "  -j  junk paths (do not make directories)   -aa treat ALL files as text\n",
            "  -U  use escapes for all non-ASCII Unicode  -UU ignore any Unicode fields\n",
            "  -C  match filenames case-insensitively     -L  make (some) names lowercase\n",
            "  -X  restore UID/GID info                   -V  retain VMS version numbers\n",
            "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\n",
            "  -O CHARSET  specify a character encoding for DOS, Windows and OS/2 archives\n",
            "  -I CHARSET  specify a character encoding for UNIX and other archives\n",
            "\n",
            "See \"unzip -hh\" or unzip.txt for more help.  Examples:\n",
            "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\n",
            "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\n",
            "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffsynth easydict decord -q\n",
        "import argparse\n",
        "from easydict import EasyDict as ed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skTyoLRC0sqc",
        "outputId": "445f60a0-58f0-413c-8b4e-71112ddac9bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for controlnet-aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"huggingface_hub[cli]\"\n",
        "!mkdir Wan2.1-T2V-1.3B\n",
        "!huggingface-cli download Wan-AI/Wan2.1-T2V-1.3B --local-dir ./Wan2.1-T2V-1.3B"
      ],
      "metadata": {
        "id": "RYoPdlr6xJl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83138817-e6c2-46e6-9f07-3e38078153c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.11/dist-packages (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (1.1.5)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.51)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (2025.7.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
            "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: pfzy, InquirerPy\n",
            "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
            "Fetching 22 files:   0% 0/22 [00:00<?, ?it/s]Downloading 'Wan2.1_VAE.pth' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/OZTShqo6Di7rh0SEswnfwSjKa9w=.38071ab59bd94681c686fa51d75a1968f64e470262043be31f7a094e442fd981.incomplete'\n",
            "Downloading 'assets/.DS_Store' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/aHCrtOA_94YSUtnsyba37B_tPq0=.d65165279105ca6773180500688df4bdc69a2c7b771752f0a46ef120b7fd8ec3.incomplete'\n",
            "Downloading 'assets/comp_effic.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/X4-4NQEdffK1bUQbDx0NJ4IbcNo=.b0e225caffb4b31295ad150f95ee852e4c3dde4a00ac8f79a2ff500f2ce26b8d.incomplete'\n",
            "Downloading 'assets/data_for_diff_stage.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/UCVN8O248kjCIp8i1TvUXWfm-q4=.59aec08409f2d46b0e640e4e120dc7cca52c08c3de56d026602dbcff1ebf241a.incomplete'\n",
            "Downloading 'README.md' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.fbbf7c13900d37f3179c546d09372aeb52e0fae1.incomplete'\n",
            "Downloading 'LICENSE.txt' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/cyBuwAu93UXke23CJCWORBYR70A=.261eeb9e9f8b2b4b0d119366dda99c6fd7d35c64.incomplete'\n",
            "Downloading '.gitattributes' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.0a1f66aea84e17cbf6a60c51431723062f87df8a.incomplete'\n",
            "\n",
            "README.md: 0.00B [00:00, ?B/s]\u001b[ADownloading 'assets/i2v_res.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/GL7zbyOeRDu8VADezw2p_Gw3fW4=.6823b3206d8d0cb18d3b5b949dec1217f1178109ba11f14e977b67e1f7b8a248.incomplete'\n",
            "README.md: 16.9kB [00:00, 24.5MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/README.md\n",
            "\n",
            "LICENSE.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "LICENSE.txt: 11.4kB [00:00, 2.20MB/s]\n",
            ".gitattributes: 2.23kB [00:00, 450kB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/LICENSE.txt\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/.gitattributes\n",
            "Fetching 22 files:   5% 1/22 [00:00<00:03,  6.69it/s]\n",
            ".DS_Store: 100% 6.15k/6.15k [00:00<00:00, 37.1MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/.DS_Store\n",
            "\n",
            "data_for_diff_stage.jpg:   0% 0.00/528k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "comp_effic.png:   0% 0.00/1.79M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:   0% 0.00/508M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "data_for_diff_stage.jpg: 100% 528k/528k [00:00<00:00, 14.8MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/data_for_diff_stage.jpg\n",
            "i2v_res.png: 100% 892k/892k [00:00<00:00, 17.9MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/i2v_res.png\n",
            "Downloading 'assets/logo.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/gvouIpVGo_vjLxWDOGAmKk_SZvY=.96cddc0f667293436d0b9f92a299b6346b65b231d38ee49719a33d46c91fe1e3.incomplete'\n",
            "Downloading 'assets/vben_1.3b_vs_sota.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/yhawob5KxOUy3bpsGU-xOWB6FC8=.b7705db79f2e1428ec7a1e6fff8c4fbde062fb95bb233516ddbd04b20007c845.incomplete'\n",
            "Downloading 'assets/t2v_res.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/VwwCFkBXvnWpmAWpzHvOZFYnnp8=.91db579092446be2a834bc67721a8e4346936f38c4edb912f459ca3e10f8f439.incomplete'\n",
            "comp_effic.png: 100% 1.79M/1.79M [00:00<00:00, 21.6MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/comp_effic.png\n",
            "Downloading 'assets/vben_vs_sota.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/p0uIb0aMIBdDB8sg9tk5UvunoB8=.9a0e86ca85046d2675f97984b88b6e74df07bba8a62a31ab8a1aef50d4eda44e.incomplete'\n",
            "\n",
            "vben_vs_sota.png:   0% 0.00/1.55M [00:00<?, ?B/s]\u001b[ADownloading 'assets/video_dit_arch.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/PbT6aGUrWxKRPnz45UQ5EbqxKYE=.195dceec6570289d8b01cc51d2e28a7786216f19de55b23978a52610d1646a66.incomplete'\n",
            "\n",
            "\n",
            "vben_1.3b_vs_sota.png:   0% 0.00/516k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "logo.png:   0% 0.00/56.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "logo.png: 100% 56.3k/56.3k [00:00<00:00, 4.11MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/logo.png\n",
            "\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:   2% 10.5M/508M [00:00<00:07, 68.1MB/s]\u001b[A\u001b[A\u001b[ADownloading 'assets/video_vae_res.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/_r133FrlYqQbngOMpQWXWYhhvVM=.d8f9e7f7353848056a615c8ef35ab86ec22976bb46cb27405008b4089701945c.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "video_vae_res.jpg: 100% 213k/213k [00:00<00:00, 213MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/video_vae_res.jpg\n",
            "vben_1.3b_vs_sota.png: 100% 516k/516k [00:00<00:00, 7.82MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/vben_1.3b_vs_sota.png\n",
            "t2v_res.jpg: 100% 301k/301k [00:00<00:00, 5.57MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/t2v_res.jpg\n",
            "Downloading 'config.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.d203bef600b2f3c64fe1f5f53d70a2087f4ccd2f.incomplete'\n",
            "\n",
            "vben_vs_sota.png: 100% 1.55M/1.55M [00:00<00:00, 12.6MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/vben_vs_sota.png\n",
            "\n",
            "video_dit_arch.jpg:   0% 0.00/643k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 100% 249/249 [00:00<00:00, 1.87MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/config.json\n",
            "Downloading 'diffusion_pytorch_model.safetensors' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/4SfAgk9U607e8pVunEB9nSiU10k=.96b6b242ca1c2f24e9d02cd6596066fab6d310e2d7538f33ae267cb18d957e8f.incomplete'\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/5.68G [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'examples/i2v_input.JPG' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/examples/GqO1vCXUoNdTZc6wjxo1L7sjRdI=.077e3d965090c9028c69c00931675f42e1acc815c6eb450ab291b3b72d211a8e.incomplete'\n",
            "video_dit_arch.jpg: 100% 643k/643k [00:00<00:00, 8.20MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/video_dit_arch.jpg\n",
            "Downloading 'google/umt5-xxl/spiece.model' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/vj8E1loknrCNPSP8nWJC234Bff4=.e3909a67b780650b35cf529ac782ad2b6b26e6d1f849d3fbb6a872905f452458.incomplete'\n",
            "\n",
            "i2v_input.JPG: 100% 251k/251k [00:00<00:00, 280MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/examples/i2v_input.JPG\n",
            "Downloading 'google/umt5-xxl/special_tokens_map.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/ahkChHUJFxEmOdq5GDFEmerRzCY=.14855e7052ffbb595057dfd791d293c1c940db2c.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:   6% 31.5M/508M [00:00<00:04, 100MB/s] \u001b[A\u001b[A\u001b[ADownloading 'google/umt5-xxl/tokenizer_config.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/vzaExXFZNBay89bvlQv-ZcI6BTg=.4e1cc1cd85599ce0b47fd0a746af188fe4043ff2.incomplete'\n",
            "Downloading 'google/umt5-xxl/tokenizer.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6e197b4d3dbd71da14b4eb255f4fa91c9c1f2068b20a2de2472967ca3d22602b.incomplete'\n",
            "\n",
            "spiece.model:   0% 0.00/4.55M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 6.62kB [00:00, 21.0MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/special_tokens_map.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 61.7kB [00:00, 103MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/16.8M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 10.5M/5.68G [00:00<01:17, 73.3MB/s]\u001b[A\u001b[ADownloading 'models_t5_umt5-xxl-enc-bf16.pth' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/7xjTyx9p9-CteGiI3VEINu_Ohx0=.7cace0da2b446bbbbc57d031ab6cf163a3d59b366da94e5afe36745b746fd81d.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 0.00/11.4G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spiece.model: 100% 4.55M/4.55M [00:00<00:00, 24.6MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/spiece.model\n",
            "\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  10% 52.4M/508M [00:00<00:04, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 21.0M/5.68G [00:00<01:24, 67.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:  62% 10.5M/16.8M [00:00<00:00, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 10.5M/11.4G [00:00<02:49, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  12% 62.9M/508M [00:00<00:04, 99.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.json: 100% 16.8M/16.8M [00:00<00:00, 47.3MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 21.0M/11.4G [00:00<02:54, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 41.9M/5.68G [00:00<01:08, 82.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  14% 73.4M/508M [00:00<00:04, 87.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 31.5M/11.4G [00:00<03:08, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 52.4M/5.68G [00:00<01:12, 77.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  17% 83.9M/508M [00:00<00:05, 80.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 41.9M/11.4G [00:00<02:39, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  19% 94.4M/508M [00:01<00:05, 77.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 73.4M/5.68G [00:00<01:03, 88.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 52.4M/11.4G [00:00<02:24, 78.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  21% 105M/508M [00:01<00:05, 78.6MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   1% 83.9M/5.68G [00:01<01:05, 86.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 62.9M/11.4G [00:00<02:24, 78.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  23% 115M/508M [00:01<00:04, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 94.4M/5.68G [00:01<01:06, 83.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 83.9M/11.4G [00:01<02:01, 92.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  25% 126M/508M [00:01<00:04, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 105M/5.68G [00:01<01:09, 80.4MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 94.4M/11.4G [00:01<02:02, 92.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  27% 136M/508M [00:01<00:04, 82.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 115M/5.68G [00:01<01:12, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 105M/11.4G [00:01<02:08, 87.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  29% 147M/508M [00:01<00:04, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 126M/5.68G [00:01<01:15, 73.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 115M/11.4G [00:01<02:30, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  31% 157M/508M [00:01<00:04, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   2% 136M/5.68G [00:01<01:18, 70.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 126M/11.4G [00:01<02:37, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  33% 168M/508M [00:02<00:05, 64.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 147M/5.68G [00:01<01:14, 74.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 136M/11.4G [00:01<02:25, 77.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  35% 178M/508M [00:02<00:04, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 157M/5.68G [00:02<01:12, 76.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 147M/11.4G [00:01<02:14, 83.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  37% 189M/508M [00:02<00:04, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 168M/5.68G [00:02<01:10, 77.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 168M/11.4G [00:02<02:00, 92.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 178M/5.68G [00:02<01:07, 81.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  39% 199M/508M [00:02<00:04, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   3% 189M/5.68G [00:02<01:02, 87.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 189M/11.4G [00:02<01:56, 96.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 199M/5.68G [00:02<01:00, 90.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 199M/11.4G [00:02<01:55, 96.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  43% 220M/508M [00:02<00:03, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 210M/5.68G [00:02<01:04, 85.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 210M/11.4G [00:02<01:55, 96.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  45% 231M/508M [00:02<00:03, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 220M/5.68G [00:02<01:03, 86.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  48% 241M/508M [00:03<00:03, 80.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 231M/11.4G [00:02<01:53, 97.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   4% 241M/5.68G [00:02<00:55, 97.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 241M/11.4G [00:02<01:52, 98.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  52% 262M/508M [00:03<00:02, 91.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 252M/11.4G [00:02<01:52, 99.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 262M/5.68G [00:03<00:51, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  56% 283M/508M [00:03<00:02, 97.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 262M/11.4G [00:03<02:02, 90.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 283M/5.68G [00:03<00:47, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  58% 294M/508M [00:03<00:02, 95.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 273M/11.4G [00:03<02:05, 88.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   5% 304M/5.68G [00:03<00:48, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  62% 315M/508M [00:03<00:01, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 294M/11.4G [00:03<01:52, 98.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   6% 325M/5.68G [00:03<00:47, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 304M/11.4G [00:03<02:00, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  66% 336M/508M [00:03<00:01, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 325M/11.4G [00:03<01:39, 110MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   6% 346M/5.68G [00:03<00:46, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  70% 357M/508M [00:04<00:01, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   6% 367M/5.68G [00:04<00:56, 93.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 346M/11.4G [00:03<02:06, 87.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  74% 377M/508M [00:04<00:01, 93.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  78% 398M/508M [00:04<00:01, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   7% 388M/5.68G [00:04<01:01, 86.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 367M/11.4G [00:04<02:16, 80.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   7% 398M/5.68G [00:04<01:08, 76.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  81% 409M/508M [00:04<00:01, 77.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 377M/11.4G [00:04<02:39, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   7% 409M/5.68G [00:04<01:21, 64.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  83% 419M/508M [00:05<00:01, 64.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 388M/11.4G [00:04<03:10, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   7% 419M/5.68G [00:05<01:30, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  85% 430M/508M [00:05<00:01, 56.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 398M/11.4G [00:04<03:13, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  87% 440M/508M [00:05<00:01, 62.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 409M/11.4G [00:05<02:54, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 440M/5.68G [00:05<01:14, 69.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 419M/11.4G [00:05<02:42, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  89% 451M/508M [00:05<00:00, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 451M/5.68G [00:05<01:12, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 430M/11.4G [00:05<02:35, 70.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  91% 461M/508M [00:05<00:00, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 461M/5.68G [00:05<01:12, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  93% 472M/508M [00:05<00:00, 70.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 472M/5.68G [00:05<01:10, 73.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 451M/11.4G [00:05<02:21, 76.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  95% 482M/508M [00:06<00:00, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   8% 482M/5.68G [00:05<01:09, 75.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 461M/11.4G [00:05<02:24, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  97% 493M/508M [00:06<00:00, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   9% 503M/5.68G [00:06<01:01, 84.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Wan2.1_VAE.pth:  99% 503M/508M [00:06<00:00, 74.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 472M/11.4G [00:05<02:38, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.1_VAE.pth: 100% 508M/508M [00:06<00:00, 78.7MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\n",
            "Fetching 22 files:  18% 4/22 [00:06<00:32,  1.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 482M/11.4G [00:06<02:27, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   9% 535M/5.68G [00:06<00:50, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 503M/11.4G [00:06<02:02, 88.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  10% 556M/5.68G [00:06<00:45, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 514M/11.4G [00:06<02:05, 86.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  10% 577M/5.68G [00:06<00:45, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 535M/11.4G [00:06<01:52, 96.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 556M/11.4G [00:06<01:40, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  11% 598M/5.68G [00:06<00:46, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 577M/11.4G [00:06<01:34, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  11% 619M/5.68G [00:07<00:43, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  11% 640M/5.68G [00:07<00:41, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 598M/11.4G [00:07<01:32, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 619M/11.4G [00:07<01:35, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  12% 661M/5.68G [00:07<00:44, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  12% 682M/5.68G [00:07<00:44, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 640M/11.4G [00:07<01:38, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  12% 703M/5.68G [00:07<00:51, 96.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 661M/11.4G [00:07<01:57, 91.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 713M/5.68G [00:08<00:51, 95.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 724M/5.68G [00:08<00:52, 94.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 682M/11.4G [00:07<01:57, 90.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 734M/5.68G [00:08<00:54, 89.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 692M/11.4G [00:08<01:57, 90.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 744M/5.68G [00:08<00:54, 90.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 703M/11.4G [00:08<01:55, 92.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 713M/11.4G [00:08<01:53, 93.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 765M/5.68G [00:08<00:52, 94.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 724M/11.4G [00:08<01:56, 91.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 744M/11.4G [00:08<01:36, 110MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  14% 786M/5.68G [00:08<00:47, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 765M/11.4G [00:08<01:27, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  14% 807M/5.68G [00:08<00:43, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 786M/11.4G [00:09<02:10, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  15% 828M/5.68G [00:09<01:04, 75.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  15% 839M/5.68G [00:09<01:02, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 807M/11.4G [00:09<02:05, 84.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  15% 849M/5.68G [00:09<01:06, 72.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 828M/11.4G [00:09<01:57, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  15% 870M/5.68G [00:09<00:58, 82.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 849M/11.4G [00:09<01:49, 96.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 881M/5.68G [00:09<00:56, 84.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 870M/11.4G [00:09<01:37, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 902M/5.68G [00:10<00:45, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 891M/11.4G [00:09<01:22, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  16% 923M/5.68G [00:10<00:42, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 912M/11.4G [00:10<01:20, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  17% 944M/5.68G [00:10<00:38, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 933M/11.4G [00:10<01:21, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  17% 965M/5.68G [00:10<00:38, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 954M/11.4G [00:10<01:33, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  17% 986M/5.68G [00:10<00:42, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 975M/11.4G [00:10<01:30, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  18% 1.01G/5.68G [00:10<00:39, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 996M/11.4G [00:10<01:26, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  18% 1.03G/5.68G [00:11<00:38, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.02G/11.4G [00:11<01:38, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  18% 1.05G/5.68G [00:11<00:44, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.04G/11.4G [00:11<01:38, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  19% 1.07G/5.68G [00:11<00:40, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.06G/11.4G [00:11<01:34, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  19% 1.09G/5.68G [00:11<00:40, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.08G/11.4G [00:11<01:26, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  20% 1.11G/5.68G [00:11<00:37, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.10G/11.4G [00:11<01:23, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  20% 1.13G/5.68G [00:12<00:37, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.12G/11.4G [00:11<01:24, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  20% 1.15G/5.68G [00:12<00:35, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  21% 1.17G/5.68G [00:12<00:35, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.14G/11.4G [00:12<01:28, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  21% 1.20G/5.68G [00:12<00:32, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.16G/11.4G [00:12<01:24, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  21% 1.22G/5.68G [00:12<00:31, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.18G/11.4G [00:12<01:16, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  22% 1.24G/5.68G [00:12<00:31, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.21G/11.4G [00:12<01:15, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  22% 1.26G/5.68G [00:12<00:31, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.23G/11.4G [00:12<01:19, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  23% 1.28G/5.68G [00:12<00:28, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.25G/11.4G [00:12<01:20, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  23% 1.30G/5.68G [00:13<00:30, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.27G/11.4G [00:13<01:11, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  23% 1.32G/5.68G [00:13<00:31, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.29G/11.4G [00:13<01:21, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  24% 1.34G/5.68G [00:13<00:33, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.31G/11.4G [00:13<01:23, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  24% 1.36G/5.68G [00:13<00:34, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.33G/11.4G [00:13<01:18, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  24% 1.38G/5.68G [00:13<00:33, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.35G/11.4G [00:13<01:13, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  25% 1.41G/5.68G [00:14<00:35, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.37G/11.4G [00:13<01:16, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  25% 1.43G/5.68G [00:14<00:34, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.39G/11.4G [00:14<01:21, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  25% 1.45G/5.68G [00:14<00:34, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.42G/11.4G [00:14<01:17, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  26% 1.47G/5.68G [00:14<00:34, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.44G/11.4G [00:14<01:17, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  26% 1.49G/5.68G [00:14<00:33, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.46G/11.4G [00:14<01:14, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  27% 1.51G/5.68G [00:14<00:32, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.48G/11.4G [00:14<01:12, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  27% 1.53G/5.68G [00:15<00:35, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.50G/11.4G [00:14<01:21, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.52G/11.4G [00:15<01:23, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  27% 1.55G/5.68G [00:15<00:37, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  28% 1.57G/5.68G [00:15<00:36, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.54G/11.4G [00:15<01:26, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  28% 1.59G/5.68G [00:15<00:35, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.56G/11.4G [00:15<01:21, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.58G/11.4G [00:15<01:18, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  28% 1.61G/5.68G [00:15<00:34, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.60G/11.4G [00:15<01:15, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  29% 1.64G/5.68G [00:16<00:36, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  29% 1.66G/5.68G [00:16<00:34, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.63G/11.4G [00:16<01:26, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  30% 1.68G/5.68G [00:16<00:33, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.65G/11.4G [00:16<01:25, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  30% 1.70G/5.68G [00:16<00:32, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.67G/11.4G [00:16<01:20, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  30% 1.72G/5.68G [00:16<00:32, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.69G/11.4G [00:16<01:19, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.71G/11.4G [00:16<01:24, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 1.74G/5.68G [00:16<00:34, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.73G/11.4G [00:16<01:22, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 1.76G/5.68G [00:17<00:33, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.75G/11.4G [00:17<01:22, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 1.78G/5.68G [00:17<00:33, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  32% 1.80G/5.68G [00:17<00:34, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.77G/11.4G [00:17<01:28, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  32% 1.82G/5.68G [00:17<00:31, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.79G/11.4G [00:17<01:20, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  33% 1.85G/5.68G [00:17<00:28, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.81G/11.4G [00:17<01:14, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  33% 1.87G/5.68G [00:17<00:31, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.84G/11.4G [00:17<01:23, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  33% 1.89G/5.68G [00:18<00:29, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.86G/11.4G [00:17<01:16, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  34% 1.91G/5.68G [00:18<00:29, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.88G/11.4G [00:18<01:12, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  34% 1.93G/5.68G [00:18<00:29, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.90G/11.4G [00:18<01:09, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  34% 1.95G/5.68G [00:18<00:27, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.92G/11.4G [00:18<01:07, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  35% 1.97G/5.68G [00:18<00:29, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.94G/11.4G [00:18<01:15, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.96G/11.4G [00:18<01:10, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  35% 1.99G/5.68G [00:18<00:30, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.98G/11.4G [00:18<01:08, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  35% 2.01G/5.68G [00:19<00:31, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.00G/11.4G [00:19<01:10, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  36% 2.03G/5.68G [00:19<00:29, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.02G/11.4G [00:19<01:08, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  36% 2.06G/5.68G [00:19<00:28, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.04G/11.4G [00:19<01:06, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.08G/11.4G [00:19<00:55, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.10G/11.4G [00:19<00:58, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  37% 2.08G/5.68G [00:19<00:39, 91.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  19% 2.12G/11.4G [00:19<01:04, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  37% 2.10G/5.68G [00:20<00:38, 91.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  19% 2.14G/11.4G [00:19<01:05, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  37% 2.11G/5.68G [00:20<00:38, 91.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  19% 2.16G/11.4G [00:20<01:10, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 2.13G/5.68G [00:20<00:37, 94.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  19% 2.18G/11.4G [00:20<01:12, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 2.15G/5.68G [00:20<00:33, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  19% 2.20G/11.4G [00:20<01:12, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 2.17G/5.68G [00:20<00:31, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.22G/11.4G [00:20<01:09, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  39% 2.19G/5.68G [00:20<00:31, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.24G/11.4G [00:20<01:12, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  39% 2.21G/5.68G [00:21<00:30, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.26G/11.4G [00:20<01:14, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  39% 2.23G/5.68G [00:21<00:30, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.29G/11.4G [00:21<01:10, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  40% 2.25G/5.68G [00:23<02:13, 25.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  40% 2.26G/5.68G [00:24<02:41, 21.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.31G/11.4G [00:24<07:33, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  40% 2.29G/5.68G [00:24<01:54, 29.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  20% 2.33G/11.4G [00:24<05:33, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  41% 2.31G/5.68G [00:24<01:26, 38.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  21% 2.35G/11.4G [00:24<04:20, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  41% 2.33G/5.68G [00:24<01:06, 50.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  21% 2.37G/11.4G [00:24<03:22, 44.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  41% 2.35G/5.68G [00:25<00:54, 60.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  21% 2.39G/11.4G [00:24<02:39, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  21% 2.41G/11.4G [00:25<02:07, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  42% 2.37G/5.68G [00:25<00:45, 72.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  21% 2.43G/11.4G [00:25<01:48, 82.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  42% 2.39G/5.68G [00:25<00:40, 81.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  42% 2.41G/5.68G [00:25<00:33, 98.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  43% 2.44G/5.68G [00:25<00:26, 123MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.45G/11.4G [00:25<02:05, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  43% 2.46G/5.68G [00:25<00:24, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.47G/11.4G [00:25<01:49, 81.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  44% 2.49G/5.68G [00:25<00:23, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.50G/11.4G [00:25<01:36, 91.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  44% 2.51G/5.68G [00:26<00:23, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.52G/11.4G [00:26<01:33, 94.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  45% 2.53G/5.68G [00:26<00:26, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.54G/11.4G [00:26<01:29, 98.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  45% 2.55G/5.68G [00:26<00:27, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.56G/11.4G [00:26<01:29, 98.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  45% 2.57G/5.68G [00:26<00:26, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.58G/11.4G [00:26<01:17, 114MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  46% 2.59G/5.68G [00:26<00:23, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.61G/11.4G [00:26<01:01, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  46% 2.61G/5.68G [00:26<00:22, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.63G/11.4G [00:26<00:58, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  46% 2.63G/5.68G [00:27<00:21, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.65G/11.4G [00:27<00:57, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  47% 2.65G/5.68G [00:27<00:20, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.67G/11.4G [00:27<00:54, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  47% 2.67G/5.68G [00:27<00:19, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  47% 2.69G/5.68G [00:27<00:18, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.71G/11.4G [00:27<01:03, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  48% 2.72G/5.68G [00:27<00:26, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.73G/11.4G [00:27<01:15, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  48% 2.74G/5.68G [00:27<00:26, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.75G/11.4G [00:27<01:12, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  49% 2.76G/5.68G [00:28<00:24, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.77G/11.4G [00:27<01:05, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  49% 2.79G/5.68G [00:28<00:19, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.80G/11.4G [00:28<00:54, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 2.81G/5.68G [00:28<00:19, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.82G/11.4G [00:28<00:55, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 2.83G/5.68G [00:28<00:21, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.84G/11.4G [00:28<01:03, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 2.85G/5.68G [00:28<00:19, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.87G/11.4G [00:28<00:52, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.89G/11.4G [00:28<00:54, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  51% 2.87G/5.68G [00:28<00:22, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.92G/11.4G [00:28<00:54, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  51% 2.89G/5.68G [00:29<00:21, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  51% 2.92G/5.68G [00:29<00:20, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.94G/11.4G [00:29<01:10, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  52% 2.94G/5.68G [00:29<00:21, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.96G/11.4G [00:29<01:04, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  52% 2.96G/5.68G [00:29<00:22, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.98G/11.4G [00:29<01:05, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  52% 2.98G/5.68G [00:29<00:22, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 3.00G/11.4G [00:29<01:18, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  53% 3.00G/5.68G [00:30<00:30, 87.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.02G/11.4G [00:30<01:34, 88.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  53% 3.02G/5.68G [00:30<00:26, 100MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.05G/11.4G [00:30<01:11, 117MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  54% 3.04G/5.68G [00:30<00:22, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.07G/11.4G [00:30<01:04, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  54% 3.06G/5.68G [00:30<00:23, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.09G/11.4G [00:30<01:10, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  54% 3.08G/5.68G [00:30<00:23, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.11G/11.4G [00:30<01:10, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  55% 3.10G/5.68G [00:30<00:20, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.15G/11.4G [00:30<00:59, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  55% 3.12G/5.68G [00:31<00:18, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.17G/11.4G [00:30<00:56, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  55% 3.15G/5.68G [00:31<00:17, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.19G/11.4G [00:31<00:53, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  56% 3.17G/5.68G [00:31<00:15, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  56% 3.19G/5.68G [00:31<00:15, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.21G/11.4G [00:31<00:56, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  57% 3.21G/5.68G [00:31<00:16, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.23G/11.4G [00:31<00:56, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  57% 3.23G/5.68G [00:31<00:17, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.25G/11.4G [00:31<00:59, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  57% 3.25G/5.68G [00:31<00:16, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.27G/11.4G [00:31<00:59, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  58% 3.27G/5.68G [00:32<00:18, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.29G/11.4G [00:31<01:02, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  58% 3.29G/5.68G [00:32<00:17, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.31G/11.4G [00:32<01:03, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  58% 3.31G/5.68G [00:32<00:17, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.33G/11.4G [00:32<01:13, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  59% 3.33G/5.68G [00:32<00:20, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.36G/11.4G [00:32<01:11, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  59% 3.36G/5.68G [00:32<00:20, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.38G/11.4G [00:32<01:12, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  59% 3.38G/5.68G [00:32<00:20, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.40G/11.4G [00:32<01:10, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  60% 3.40G/5.68G [00:33<00:20, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.42G/11.4G [00:33<01:13, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  60% 3.42G/5.68G [00:34<00:42, 52.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  60% 3.43G/5.68G [00:34<01:04, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.44G/11.4G [00:34<03:50, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.46G/11.4G [00:34<02:53, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  61% 3.45G/5.68G [00:34<00:47, 46.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  61% 3.47G/5.68G [00:35<00:35, 62.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.48G/11.4G [00:34<02:13, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.50G/11.4G [00:35<01:58, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  62% 3.49G/5.68G [00:35<00:31, 69.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  62% 3.51G/5.68G [00:35<00:26, 83.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.52G/11.4G [00:35<01:43, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  62% 3.53G/5.68G [00:35<00:22, 93.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  63% 3.57G/5.68G [00:35<00:18, 117MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.54G/11.4G [00:35<01:52, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  63% 3.59G/5.68G [00:35<00:17, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.57G/11.4G [00:35<01:37, 80.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  64% 3.61G/5.68G [00:36<00:17, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.59G/11.4G [00:36<01:25, 90.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  64% 3.63G/5.68G [00:36<00:16, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.61G/11.4G [00:36<01:16, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  64% 3.65G/5.68G [00:36<00:16, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.63G/11.4G [00:36<01:08, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  65% 3.67G/5.68G [00:36<00:15, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.65G/11.4G [00:36<01:04, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  65% 3.69G/5.68G [00:36<00:14, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.67G/11.4G [00:36<01:00, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  65% 3.71G/5.68G [00:36<00:13, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.69G/11.4G [00:36<00:54, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  66% 3.73G/5.68G [00:37<00:14, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.71G/11.4G [00:36<00:56, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  66% 3.75G/5.68G [00:37<00:14, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.73G/11.4G [00:36<00:53, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.75G/11.4G [00:37<00:50, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  67% 3.77G/5.68G [00:37<00:13, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.77G/11.4G [00:37<00:49, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  67% 3.80G/5.68G [00:37<00:13, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.80G/11.4G [00:37<00:45, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  67% 3.82G/5.68G [00:37<00:12, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.82G/11.4G [00:37<00:50, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  68% 3.84G/5.68G [00:37<00:16, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.84G/11.4G [00:38<01:33, 80.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  68% 3.86G/5.68G [00:38<00:21, 86.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  68% 3.88G/5.68G [00:38<00:18, 97.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.86G/11.4G [00:38<01:22, 91.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 3.90G/5.68G [00:38<00:16, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.88G/11.4G [00:38<01:14, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.90G/11.4G [00:38<01:07, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 3.92G/5.68G [00:38<00:15, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.92G/11.4G [00:38<01:01, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 3.94G/5.68G [00:38<00:15, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.94G/11.4G [00:38<01:09, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.96G/11.4G [00:39<01:19, 92.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  70% 3.96G/5.68G [00:39<00:29, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.98G/11.4G [00:39<01:26, 84.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  70% 4.00G/5.68G [00:39<00:20, 83.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.00G/11.4G [00:39<01:28, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  71% 4.02G/5.68G [00:39<00:17, 97.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.01G/11.4G [00:39<01:30, 81.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  71% 4.04G/5.68G [00:40<00:14, 113MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.03G/11.4G [00:39<01:10, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  71% 4.06G/5.68G [00:40<00:13, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.05G/11.4G [00:40<01:01, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  72% 4.08G/5.68G [00:40<00:12, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.08G/11.4G [00:40<00:51, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  72% 4.10G/5.68G [00:40<00:11, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.10G/11.4G [00:40<00:47, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  73% 4.12G/5.68G [00:40<00:11, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.13G/11.4G [00:40<00:43, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  73% 4.14G/5.68G [00:40<00:10, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.16G/11.4G [00:40<00:40, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  73% 4.16G/5.68G [00:40<00:10, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.18G/11.4G [00:40<00:41, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  74% 4.18G/5.68G [00:41<00:11, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.20G/11.4G [00:40<00:44, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  74% 4.20G/5.68G [00:41<00:11, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.23G/11.4G [00:41<00:45, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  74% 4.23G/5.68G [00:41<00:10, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.25G/11.4G [00:41<00:50, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.27G/11.4G [00:41<00:50, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  75% 4.25G/5.68G [00:41<00:11, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.29G/11.4G [00:41<00:52, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  75% 4.27G/5.68G [00:41<00:12, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.31G/11.4G [00:41<00:54, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  76% 4.29G/5.68G [00:41<00:11, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.33G/11.4G [00:41<00:54, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  76% 4.31G/5.68G [00:42<00:11, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.35G/11.4G [00:42<00:56, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  76% 4.33G/5.68G [00:42<00:11, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.37G/11.4G [00:44<04:59, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  77% 4.35G/5.68G [00:44<00:56, 23.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.40G/11.4G [00:44<03:12, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  77% 4.38G/5.68G [00:44<00:36, 35.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.42G/11.4G [00:44<02:29, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  78% 4.40G/5.68G [00:45<00:27, 45.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.45G/11.4G [00:45<01:59, 58.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  78% 4.42G/5.68G [00:45<00:21, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.47G/11.4G [00:45<01:37, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  78% 4.45G/5.68G [00:45<00:17, 69.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.49G/11.4G [00:45<01:22, 83.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  79% 4.47G/5.68G [00:45<00:14, 81.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.51G/11.4G [00:45<01:08, 99.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  79% 4.49G/5.68G [00:45<00:12, 92.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.53G/11.4G [00:45<00:59, 114MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.55G/11.4G [00:45<00:57, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.58G/11.4G [00:45<00:46, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  79% 4.51G/5.68G [00:46<00:14, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.60G/11.4G [00:45<00:43, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  80% 4.54G/5.68G [00:46<00:10, 107MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.62G/11.4G [00:46<00:41, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 4.57G/5.68G [00:46<00:08, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.65G/11.4G [00:46<00:46, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 4.59G/5.68G [00:46<00:08, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.67G/11.4G [00:46<00:45, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 4.61G/5.68G [00:46<00:07, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.69G/11.4G [00:46<00:45, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  82% 4.63G/5.68G [00:46<00:07, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.71G/11.4G [00:46<00:42, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  82% 4.66G/5.68G [00:48<00:34, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.73G/11.4G [00:48<03:50, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  83% 4.69G/5.68G [00:49<00:22, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.76G/11.4G [00:48<02:30, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  83% 4.71G/5.68G [00:49<00:17, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.78G/11.4G [00:49<01:59, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  83% 4.73G/5.68G [00:49<00:14, 65.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.80G/11.4G [00:49<01:41, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  84% 4.75G/5.68G [00:49<00:12, 74.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.82G/11.4G [00:49<01:26, 75.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  84% 4.77G/5.68G [00:49<00:10, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.84G/11.4G [00:49<01:13, 88.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  84% 4.79G/5.68G [00:49<00:09, 95.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.87G/11.4G [00:49<01:07, 96.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  85% 4.81G/5.68G [00:49<00:08, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.89G/11.4G [00:49<01:01, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  85% 4.83G/5.68G [00:50<00:07, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.91G/11.4G [00:49<00:57, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  86% 4.85G/5.68G [00:50<00:07, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.93G/11.4G [00:50<00:56, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.95G/11.4G [00:50<00:51, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  86% 4.88G/5.68G [00:50<00:06, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.97G/11.4G [00:50<00:50, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  86% 4.90G/5.68G [00:50<00:06, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.99G/11.4G [00:50<00:46, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  87% 4.92G/5.68G [00:50<00:06, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.01G/11.4G [00:50<00:48, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  87% 4.94G/5.68G [00:50<00:05, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.03G/11.4G [00:50<00:44, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  87% 4.96G/5.68G [00:51<00:05, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.05G/11.4G [00:51<00:47, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  88% 4.98G/5.68G [00:51<00:05, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.08G/11.4G [00:51<00:47, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  88% 5.00G/5.68G [00:51<00:05, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.10G/11.4G [00:51<00:44, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  88% 5.02G/5.68G [00:51<00:04, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.12G/11.4G [00:51<00:43, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  89% 5.04G/5.68G [00:51<00:04, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.14G/11.4G [00:51<00:47, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  89% 5.06G/5.68G [00:51<00:04, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.16G/11.4G [00:51<00:51, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  90% 5.09G/5.68G [00:52<00:04, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.18G/11.4G [00:52<00:49, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  90% 5.11G/5.68G [00:52<00:04, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.20G/11.4G [00:52<00:47, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  90% 5.13G/5.68G [00:52<00:04, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.22G/11.4G [00:52<00:46, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  91% 5.15G/5.68G [00:52<00:04, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.24G/11.4G [00:52<00:43, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  91% 5.17G/5.68G [00:52<00:03, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.26G/11.4G [00:52<00:43, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  91% 5.19G/5.68G [00:52<00:03, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.28G/11.4G [00:52<00:43, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  92% 5.21G/5.68G [00:53<00:03, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.31G/11.4G [00:52<00:44, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  92% 5.23G/5.68G [00:53<00:03, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.33G/11.4G [00:53<00:43, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  93% 5.25G/5.68G [00:53<00:03, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.35G/11.4G [00:53<00:41, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.37G/11.4G [00:53<00:43, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  93% 5.27G/5.68G [00:53<00:03, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.39G/11.4G [00:53<00:40, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  93% 5.30G/5.68G [00:53<00:02, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 5.32G/5.68G [00:53<00:02, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.41G/11.4G [00:53<00:50, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 5.34G/5.68G [00:54<00:02, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.43G/11.4G [00:53<00:49, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 5.36G/5.68G [00:54<00:02, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.45G/11.4G [00:54<00:49, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  95% 5.38G/5.68G [00:54<00:02, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.47G/11.4G [00:54<01:13, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.48G/11.4G [00:54<01:17, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  95% 5.40G/5.68G [00:54<00:04, 68.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.51G/11.4G [00:54<01:06, 88.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  96% 5.42G/5.68G [00:55<00:03, 82.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.53G/11.4G [00:54<00:54, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  96% 5.44G/5.68G [00:55<00:02, 96.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.55G/11.4G [00:55<00:45, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  96% 5.46G/5.68G [00:55<00:01, 109MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.57G/11.4G [00:55<00:43, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.59G/11.4G [00:55<00:44, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  97% 5.48G/5.68G [00:55<00:01, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.61G/11.4G [00:55<00:42, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  97% 5.51G/5.68G [00:55<00:01, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.63G/11.4G [00:55<00:47, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  97% 5.53G/5.68G [00:55<00:01, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.65G/11.4G [00:55<00:45, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  98% 5.55G/5.68G [00:56<00:01, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.67G/11.4G [00:56<00:42, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  98% 5.57G/5.68G [00:56<00:00, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.69G/11.4G [00:56<00:43, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  98% 5.59G/5.68G [00:56<00:00, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.71G/11.4G [00:56<00:43, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  99% 5.61G/5.68G [00:56<00:00, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  99% 5.63G/5.68G [00:56<00:00, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.74G/11.4G [00:56<01:00, 92.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.77G/11.4G [00:56<00:44, 126MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 5.65G/5.68G [00:57<00:00, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.79G/11.4G [00:56<00:41, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 5.68G/5.68G [00:59<00:00, 96.0MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\n",
            "Fetching 22 files:  73% 16/22 [00:59<00:23,  3.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.81G/11.4G [00:58<02:54, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.84G/11.4G [00:59<01:55, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.87G/11.4G [00:59<01:24, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.89G/11.4G [00:59<01:15, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.92G/11.4G [00:59<00:55, 97.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.96G/11.4G [00:59<00:43, 124MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 5.99G/11.4G [00:59<00:35, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.02G/11.4G [00:59<00:30, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.05G/11.4G [00:59<00:27, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.08G/11.4G [01:00<00:24, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.11G/11.4G [01:00<00:23, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.14G/11.4G [01:00<00:22, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.18G/11.4G [01:00<00:21, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.21G/11.4G [01:00<00:19, 260MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.24G/11.4G [01:00<00:19, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.27G/11.4G [01:00<00:19, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.30G/11.4G [01:00<00:18, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.33G/11.4G [01:01<00:19, 253MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.36G/11.4G [01:01<00:18, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.40G/11.4G [01:01<00:19, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.43G/11.4G [01:01<00:18, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.46G/11.4G [01:01<00:18, 270MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.49G/11.4G [01:01<00:19, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.52G/11.4G [01:01<00:19, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.55G/11.4G [01:01<00:18, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.59G/11.4G [01:02<00:19, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.62G/11.4G [01:02<00:18, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.65G/11.4G [01:02<00:17, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.68G/11.4G [01:02<00:17, 263MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.71G/11.4G [01:02<00:18, 249MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.74G/11.4G [01:02<00:19, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.77G/11.4G [01:02<00:19, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.81G/11.4G [01:03<00:25, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.83G/11.4G [01:03<00:24, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.85G/11.4G [01:03<00:26, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.88G/11.4G [01:03<00:22, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.91G/11.4G [01:03<00:20, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.94G/11.4G [01:03<00:26, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.97G/11.4G [01:04<00:41, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.00G/11.4G [01:04<00:34, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.04G/11.4G [01:04<00:29, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.07G/11.4G [01:04<00:25, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.10G/11.4G [01:04<00:23, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.13G/11.4G [01:05<00:22, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.16G/11.4G [01:05<00:20, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.19G/11.4G [01:05<00:19, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.22G/11.4G [01:05<00:18, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.26G/11.4G [01:05<00:19, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.29G/11.4G [01:05<00:18, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.32G/11.4G [01:05<00:17, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.35G/11.4G [01:06<00:17, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.38G/11.4G [01:06<00:16, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.41G/11.4G [01:06<00:17, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.44G/11.4G [01:06<00:16, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.48G/11.4G [01:06<00:16, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.51G/11.4G [01:06<00:17, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.54G/11.4G [01:06<00:17, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.57G/11.4G [01:06<00:16, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.60G/11.4G [01:07<00:15, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.63G/11.4G [01:07<00:16, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.67G/11.4G [01:07<00:16, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.70G/11.4G [01:07<00:16, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.73G/11.4G [01:07<00:16, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.76G/11.4G [01:08<00:22, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.78G/11.4G [01:08<00:21, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.81G/11.4G [01:08<00:19, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.84G/11.4G [01:08<00:17, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.87G/11.4G [01:08<00:16, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.91G/11.4G [01:08<00:15, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.94G/11.4G [01:08<00:13, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.97G/11.4G [01:08<00:14, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 8.00G/11.4G [01:09<00:19, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.02G/11.4G [01:09<00:18, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.04G/11.4G [01:09<00:19, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.06G/11.4G [01:15<04:23, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.10G/11.4G [01:15<02:52, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.14G/11.4G [01:15<01:45, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.17G/11.4G [01:15<01:16, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.20G/11.4G [01:16<00:56, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.23G/11.4G [01:16<00:43, 71.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.26G/11.4G [01:16<00:33, 92.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.29G/11.4G [01:16<00:26, 115MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.33G/11.4G [01:16<00:21, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.36G/11.4G [01:16<00:18, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.39G/11.4G [01:16<00:16, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.42G/11.4G [01:16<00:14, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.45G/11.4G [01:17<00:13, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.48G/11.4G [01:17<00:12, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.51G/11.4G [01:17<00:12, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.55G/11.4G [01:17<00:11, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.58G/11.4G [01:17<00:13, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.61G/11.4G [01:17<00:14, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.64G/11.4G [01:17<00:13, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.67G/11.4G [01:18<00:11, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.70G/11.4G [01:18<00:11, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.73G/11.4G [01:18<00:17, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.76G/11.4G [01:18<00:16, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.79G/11.4G [01:18<00:14, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.82G/11.4G [01:18<00:13, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.85G/11.4G [01:19<00:12, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.88G/11.4G [01:19<00:11, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.91G/11.4G [01:19<00:11, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 8.94G/11.4G [01:19<00:10, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 8.98G/11.4G [01:19<00:10, 218MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 9.01G/11.4G [01:19<00:10, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.04G/11.4G [01:19<00:09, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.07G/11.4G [01:20<00:10, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.10G/11.4G [01:20<00:10, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.13G/11.4G [01:20<00:10, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.16G/11.4G [01:20<00:09, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.20G/11.4G [01:20<00:09, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.23G/11.4G [01:20<00:09, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.26G/11.4G [01:20<00:08, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.29G/11.4G [01:20<00:09, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.32G/11.4G [01:21<00:08, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.35G/11.4G [01:21<00:08, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.38G/11.4G [01:21<00:08, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.42G/11.4G [01:21<00:08, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.45G/11.4G [01:21<00:08, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.48G/11.4G [01:21<00:07, 242MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.51G/11.4G [01:21<00:07, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.54G/11.4G [01:22<00:07, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.57G/11.4G [01:22<00:07, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.60G/11.4G [01:22<00:07, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.64G/11.4G [01:22<00:07, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.67G/11.4G [01:22<00:06, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.70G/11.4G [01:22<00:07, 222MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.73G/11.4G [01:22<00:07, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.76G/11.4G [01:22<00:07, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.79G/11.4G [01:23<00:06, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.83G/11.4G [01:25<00:41, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.86G/11.4G [01:25<00:29, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.90G/11.4G [01:25<00:20, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.93G/11.4G [01:25<00:15, 92.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 9.96G/11.4G [01:26<00:12, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 9.99G/11.4G [01:26<00:10, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 10.0G/11.4G [01:26<00:08, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [01:26<00:07, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [01:26<00:06, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [01:26<00:05, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.2G/11.4G [01:26<00:05, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [01:26<00:04, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [01:27<00:04, 253MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [01:27<00:04, 253MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.3G/11.4G [01:27<00:04, 262MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.3G/11.4G [01:27<00:03, 269MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.3G/11.4G [01:27<00:04, 253MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.4G/11.4G [01:27<00:03, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.4G/11.4G [01:27<00:03, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.4G/11.4G [01:27<00:03, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.5G/11.4G [01:27<00:03, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.5G/11.4G [01:28<00:03, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.5G/11.4G [01:28<00:03, 270MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [01:28<00:02, 270MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [01:29<00:11, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [01:29<00:08, 90.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [01:29<00:06, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [01:29<00:04, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [01:30<00:04, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.7G/11.4G [01:30<00:03, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [01:30<00:02, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [01:30<00:02, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [01:30<00:02, 232MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [01:30<00:02, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [01:30<00:01, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [01:30<00:01, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [01:30<00:01, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [01:31<00:01, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [01:31<00:01, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.1G/11.4G [01:31<00:01, 258MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.1G/11.4G [01:31<00:01, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.1G/11.4G [01:31<00:00, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.2G/11.4G [01:31<00:00, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.2G/11.4G [01:31<00:00, 269MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.2G/11.4G [01:31<00:00, 268MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.3G/11.4G [01:32<00:00, 277MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.3G/11.4G [01:32<00:00, 272MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth: 100% 11.3G/11.4G [01:32<00:00, 269MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth: 100% 11.4G/11.4G [01:32<00:00, 123MB/s]\n",
            "Download complete. Moving file to Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n",
            "Fetching 22 files: 100% 22/22 [01:33<00:00,  4.23s/it]\n",
            "/content/Wan2.1-T2V-1.3B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import types\n",
        "from diffsynth.models import ModelManager\n",
        "from diffsynth.models.wan_video_dit import WanModel\n",
        "from diffsynth.models.wan_video_text_encoder import WanTextEncoder\n",
        "from diffsynth.models.wan_video_vae import WanVideoVAE\n",
        "from diffsynth.models.wan_video_image_encoder import WanImageEncoder\n",
        "from diffsynth.schedulers.flow_match import FlowMatchScheduler\n",
        "from diffsynth.pipelines.base import BasePipeline\n",
        "from diffsynth.prompters import WanPrompter\n",
        "import torch, os\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "from diffsynth.vram_management import enable_vram_management, AutoWrappedModule, AutoWrappedLinear\n",
        "from diffsynth.models.wan_video_text_encoder import T5RelativeEmbedding, T5LayerNorm\n",
        "from diffsynth.models.wan_video_dit import RMSNorm, sinusoidal_embedding_1d\n",
        "from diffsynth.models.wan_video_vae import RMS_norm, CausalConv3d, Upsample\n",
        "from diffsynth.models.wan_video_motion_controller import WanMotionControllerModel\n",
        "\n",
        "\n",
        "\n",
        "class WanVideoPipeline(BasePipeline):\n",
        "\n",
        "    def __init__(self, device=\"cuda\", torch_dtype=torch.float16, tokenizer_path=None):\n",
        "        super().__init__(device=device, torch_dtype=torch_dtype)\n",
        "        self.scheduler = FlowMatchScheduler(shift=5, sigma_min=0.0, extra_one_step=True)\n",
        "        self.prompter = WanPrompter(tokenizer_path=tokenizer_path)\n",
        "        self.text_encoder: WanTextEncoder = None\n",
        "        self.image_encoder: WanImageEncoder = None\n",
        "        self.dit: WanModel = None\n",
        "        self.vae: WanVideoVAE = None\n",
        "        self.motion_controller: WanMotionControllerModel = None\n",
        "        self.model_names = ['text_encoder', 'dit', 'vae', 'image_encoder', 'motion_controller']\n",
        "        self.height_division_factor = 16\n",
        "        self.width_division_factor = 16\n",
        "        self.use_unified_sequence_parallel = False\n",
        "\n",
        "\n",
        "    def enable_vram_management(self, num_persistent_param_in_dit=None):\n",
        "        dtype = next(iter(self.text_encoder.parameters())).dtype\n",
        "        enable_vram_management(\n",
        "            self.text_encoder,\n",
        "            module_map = {\n",
        "                torch.nn.Linear: AutoWrappedLinear,\n",
        "                torch.nn.Embedding: AutoWrappedModule,\n",
        "                T5RelativeEmbedding: AutoWrappedModule,\n",
        "                T5LayerNorm: AutoWrappedModule,\n",
        "            },\n",
        "            module_config = dict(\n",
        "                offload_dtype=dtype,\n",
        "                offload_device=\"cpu\",\n",
        "                onload_dtype=dtype,\n",
        "                onload_device=\"cpu\",\n",
        "                computation_dtype=self.torch_dtype,\n",
        "                computation_device=self.device,\n",
        "            ),\n",
        "        )\n",
        "        dtype = next(iter(self.dit.parameters())).dtype\n",
        "        enable_vram_management(\n",
        "            self.dit,\n",
        "            module_map = {\n",
        "                torch.nn.Linear: AutoWrappedLinear,\n",
        "                torch.nn.Conv3d: AutoWrappedModule,\n",
        "                torch.nn.LayerNorm: AutoWrappedModule,\n",
        "                RMSNorm: AutoWrappedModule,\n",
        "            },\n",
        "            module_config = dict(\n",
        "                offload_dtype=dtype,\n",
        "                offload_device=\"cpu\",\n",
        "                onload_dtype=dtype,\n",
        "                onload_device=self.device,\n",
        "                computation_dtype=self.torch_dtype,\n",
        "                computation_device=self.device,\n",
        "            ),\n",
        "            max_num_param=num_persistent_param_in_dit,\n",
        "            overflow_module_config = dict(\n",
        "                offload_dtype=dtype,\n",
        "                offload_device=\"cpu\",\n",
        "                onload_dtype=dtype,\n",
        "                onload_device=\"cpu\",\n",
        "                computation_dtype=self.torch_dtype,\n",
        "                computation_device=self.device,\n",
        "            ),\n",
        "        )\n",
        "        dtype = next(iter(self.vae.parameters())).dtype\n",
        "        enable_vram_management(\n",
        "            self.vae,\n",
        "            module_map = {\n",
        "                torch.nn.Linear: AutoWrappedLinear,\n",
        "                torch.nn.Conv2d: AutoWrappedModule,\n",
        "                RMS_norm: AutoWrappedModule,\n",
        "                CausalConv3d: AutoWrappedModule,\n",
        "                Upsample: AutoWrappedModule,\n",
        "                torch.nn.SiLU: AutoWrappedModule,\n",
        "                torch.nn.Dropout: AutoWrappedModule,\n",
        "            },\n",
        "            module_config = dict(\n",
        "                offload_dtype=dtype,\n",
        "                offload_device=\"cpu\",\n",
        "                onload_dtype=dtype,\n",
        "                onload_device=self.device,\n",
        "                computation_dtype=self.torch_dtype,\n",
        "                computation_device=self.device,\n",
        "            ),\n",
        "        )\n",
        "        if self.image_encoder is not None:\n",
        "            dtype = next(iter(self.image_encoder.parameters())).dtype\n",
        "            enable_vram_management(\n",
        "                self.image_encoder,\n",
        "                module_map = {\n",
        "                    torch.nn.Linear: AutoWrappedLinear,\n",
        "                    torch.nn.Conv2d: AutoWrappedModule,\n",
        "                    torch.nn.LayerNorm: AutoWrappedModule,\n",
        "                },\n",
        "                module_config = dict(\n",
        "                    offload_dtype=dtype,\n",
        "                    offload_device=\"cpu\",\n",
        "                    onload_dtype=dtype,\n",
        "                    onload_device=\"cpu\",\n",
        "                    computation_dtype=dtype,\n",
        "                    computation_device=self.device,\n",
        "                ),\n",
        "            )\n",
        "        if self.motion_controller is not None:\n",
        "            dtype = next(iter(self.motion_controller.parameters())).dtype\n",
        "            enable_vram_management(\n",
        "                self.motion_controller,\n",
        "                module_map = {\n",
        "                    torch.nn.Linear: AutoWrappedLinear,\n",
        "                },\n",
        "                module_config = dict(\n",
        "                    offload_dtype=dtype,\n",
        "                    offload_device=\"cpu\",\n",
        "                    onload_dtype=dtype,\n",
        "                    onload_device=\"cpu\",\n",
        "                    computation_dtype=dtype,\n",
        "                    computation_device=self.device,\n",
        "                ),\n",
        "            )\n",
        "        self.enable_cpu_offload()\n",
        "\n",
        "\n",
        "    def fetch_models(self, model_manager: ModelManager):\n",
        "        text_encoder_model_and_path = model_manager.fetch_model(\"wan_video_text_encoder\", require_model_path=True)\n",
        "        if text_encoder_model_and_path is not None:\n",
        "            self.text_encoder, tokenizer_path = text_encoder_model_and_path\n",
        "            self.prompter.fetch_models(self.text_encoder)\n",
        "            self.prompter.fetch_tokenizer(os.path.join(os.path.dirname(tokenizer_path), \"google/umt5-xxl\"))\n",
        "        self.dit = model_manager.fetch_model(\"wan_video_dit\")\n",
        "        self.vae = model_manager.fetch_model(\"wan_video_vae\")\n",
        "        self.image_encoder = model_manager.fetch_model(\"wan_video_image_encoder\")\n",
        "        self.motion_controller = model_manager.fetch_model(\"wan_video_motion_controller\")\n",
        "\n",
        "    @staticmethod\n",
        "    def from_model_manager(model_manager: ModelManager, torch_dtype=None, device=None, use_usp=False):\n",
        "        if device is None: device = model_manager.device\n",
        "        if torch_dtype is None: torch_dtype = model_manager.torch_dtype\n",
        "        pipe = WanVideoPipeline(device=device, torch_dtype=torch_dtype)\n",
        "        pipe.fetch_models(model_manager)\n",
        "        return pipe\n",
        "        # if use_usp:\n",
        "        #     from xfuser.core.distributed import get_sequence_parallel_world_size\n",
        "        #     from ..distributed.xdit_context_parallel import usp_attn_forward, usp_dit_forward\n",
        "\n",
        "        #     for block in pipe.dit.blocks:\n",
        "        #         block.self_attn.forward = types.MethodType(usp_attn_forward, block.self_attn)\n",
        "        #     pipe.dit.forward = types.MethodType(usp_dit_forward, pipe.dit)\n",
        "        #     pipe.sp_size = get_sequence_parallel_world_size()\n",
        "        #     pipe.use_unified_sequence_parallel = True\n",
        "        # return pipe\n",
        "\n",
        "\n",
        "\n",
        "    def denoising_model(self):\n",
        "        return self.dit\n",
        "\n",
        "\n",
        "    def encode_prompt(self, prompt, positive=True):\n",
        "        prompt_emb = self.prompter.encode_prompt(prompt, positive=positive, device=self.device)\n",
        "        return {\"context\": prompt_emb}\n",
        "\n",
        "\n",
        "    def encode_image(self, image, pseudo_video_path=None, mask_video_path=None, end_image=None, num_frames=81, height=480, width=832):\n",
        "        \"\"\"\n",
        "        Encode images and videos for I2V inference\n",
        "        Args:\n",
        "            image: First frame image (PIL Image)\n",
        "            pseudo_video_path: Pseudo video file path (new mode)\n",
        "            mask_video_path: Mask video file path (new mode)\n",
        "            end_image: End frame image (original mode)\n",
        "            num_frames: Number of frames\n",
        "            height, width: Video dimensions\n",
        "        \"\"\"\n",
        "        # New mode: Use pseudo video and mask video\n",
        "        # Original mode: use end_image (backward compatibility)\n",
        "\n",
        "        image = self.preprocess_image(image.resize((width, height))).to(self.device)\n",
        "        clip_context = self.image_encoder.encode_image([image])\n",
        "        msk = torch.ones(1, num_frames, height//8, width//8, device=self.device)\n",
        "        msk[:, 1:] = 0\n",
        "        if end_image is not None:\n",
        "            end_image = self.preprocess_image(end_image.resize((width, height))).to(self.device)\n",
        "            vae_input = torch.concat([image.transpose(0,1), torch.zeros(3, num_frames-2, height, width).to(image.device), end_image.transpose(0,1)],dim=1)\n",
        "            msk[:, -1:] = 1\n",
        "        else:\n",
        "            vae_input = torch.concat([image.transpose(0, 1), torch.zeros(3, num_frames-1, height, width).to(image.device)], dim=1)\n",
        "\n",
        "        msk = torch.concat([torch.repeat_interleave(msk[:, 0:1], repeats=4, dim=1), msk[:, 1:]], dim=1)\n",
        "        msk = msk.view(1, msk.shape[1] // 4, 4, height//8, width//8)\n",
        "        msk = msk.transpose(1, 2)[0]\n",
        "\n",
        "        y = self.vae.encode([vae_input.to(dtype=self.torch_dtype, device=self.device)], device=self.device)[0]\n",
        "        y = torch.concat([msk, y])\n",
        "        y = y.unsqueeze(0)\n",
        "        clip_context = clip_context.to(dtype=self.torch_dtype, device=self.device)\n",
        "        y = y.to(dtype=self.torch_dtype, device=self.device)\n",
        "        return {\"clip_feature\": clip_context, \"y\": y}\n",
        "\n",
        "\n",
        "    def encode_control_video(self, control_video, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
        "        control_video = self.preprocess_images(control_video)\n",
        "        # preprocess_images returns tensor list, each may be [1, 3, H, W], need to remove batch dimension\n",
        "        control_video = [tensor.squeeze(0) if tensor.dim() == 4 else tensor for tensor in control_video]\n",
        "        control_video = torch.stack(control_video, dim=1)  # [3, T, H, W]\n",
        "        control_video = control_video.to(dtype=self.torch_dtype, device=self.device)  # [3, T, H, W] - VAE expects this format\n",
        "        latents = self.encode_video(control_video, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride).to(dtype=self.torch_dtype, device=self.device)\n",
        "        return latents\n",
        "\n",
        "\n",
        "    def prepare_controlnet_kwargs(self, control_video, num_frames, height, width, clip_feature=None, y=None, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
        "        if control_video is not None:\n",
        "            control_latents = self.encode_control_video(control_video, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
        "            if clip_feature is None or y is None:\n",
        "                clip_feature = torch.zeros((1, 257, 1280), dtype=self.torch_dtype, device=self.device)\n",
        "                y = torch.zeros((1, 16, (num_frames - 1) // 4 + 1, height//8, width//8), dtype=self.torch_dtype, device=self.device)\n",
        "            else:\n",
        "                y = y[:, -16:]\n",
        "            y = torch.concat([control_latents, y], dim=1)\n",
        "        return {\"clip_feature\": clip_feature, \"y\": y}\n",
        "\n",
        "\n",
        "    def tensor2video(self, frames):\n",
        "        frames = rearrange(frames, \"C T H W -> T H W C\")\n",
        "        frames = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)\n",
        "        frames = [Image.fromarray(frame) for frame in frames]\n",
        "        return frames\n",
        "\n",
        "\n",
        "    def prepare_extra_input(self, latents=None):\n",
        "        return {}\n",
        "\n",
        "\n",
        "    def encode_video(self, input_video, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
        "        latents = self.vae.encode(input_video, device=self.device, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
        "        return latents\n",
        "\n",
        "\n",
        "    def decode_video(self, latents, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
        "        frames = self.vae.decode(latents, device=self.device, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
        "        return frames\n",
        "\n",
        "\n",
        "    def prepare_unified_sequence_parallel(self):\n",
        "        return {\"use_unified_sequence_parallel\": self.use_unified_sequence_parallel}\n",
        "\n",
        "\n",
        "    def prepare_motion_bucket_id(self, motion_bucket_id):\n",
        "        motion_bucket_id = torch.Tensor((motion_bucket_id,)).to(dtype=self.torch_dtype, device=self.device)\n",
        "        return {\"motion_bucket_id\": motion_bucket_id}\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(\n",
        "        self,\n",
        "        prompt,\n",
        "        negative_prompt=\"\",\n",
        "        input_image=None,\n",
        "        pseudo_video_path=None,\n",
        "        mask_video_path=None,\n",
        "        end_image=None,\n",
        "        input_video=None,\n",
        "        control_video=None,\n",
        "        denoising_strength=1.0,\n",
        "        seed=None,\n",
        "        rand_device=\"cpu\",\n",
        "        height=480,\n",
        "        width=832,\n",
        "        num_frames=81,\n",
        "        cfg_scale=5.0,\n",
        "        num_inference_steps=50,\n",
        "        sigma_shift=5.0,\n",
        "        motion_bucket_id=None,\n",
        "        tiled=True,\n",
        "        tile_size=(30, 52),\n",
        "        tile_stride=(15, 26),\n",
        "        tea_cache_l1_thresh=None,\n",
        "        tea_cache_model_id=\"\",\n",
        "        progress_bar_cmd=tqdm,\n",
        "        progress_bar_st=None,\n",
        "    ):\n",
        "        # Parameter check\n",
        "        height, width = self.check_resize_height_width(height, width)\n",
        "        if num_frames % 4 != 1:\n",
        "            num_frames = (num_frames + 2) // 4 * 4 + 1\n",
        "            print(f\"Only `num_frames % 4 != 1` is acceptable. We round it up to {num_frames}.\")\n",
        "\n",
        "        # Tiler parameters\n",
        "        tiler_kwargs = {\"tiled\": tiled, \"tile_size\": tile_size, \"tile_stride\": tile_stride}\n",
        "\n",
        "        # Scheduler\n",
        "        self.scheduler.set_timesteps(num_inference_steps, denoising_strength=denoising_strength, shift=sigma_shift)\n",
        "        # Original logic\n",
        "        noise = self.generate_noise(\n",
        "            (1, 16, (num_frames - 1) // 4 + 1, height//8, width//8),\n",
        "            seed=seed, device=rand_device, dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        noise = noise.to(dtype=self.torch_dtype, device=self.device)\n",
        "        if input_video is not None:\n",
        "            self.load_models_to_device(['vae'])\n",
        "            input_video = self.preprocess_images(input_video)\n",
        "            # Remove possible batch dimension\n",
        "            input_video = [tensor.squeeze(0) if tensor.dim() == 4 else tensor for tensor in input_video]\n",
        "            input_video = torch.stack(input_video, dim=1)  # [3, T, H, W]\n",
        "            input_video = input_video.to(dtype=self.torch_dtype, device=self.device)  # [3, T, H, W] - VAE expects this format\n",
        "            latents = self.encode_video(input_video, **tiler_kwargs).to(dtype=self.torch_dtype, device=self.device)\n",
        "            latents = self.scheduler.add_noise(latents, noise, timestep=self.scheduler.timesteps[0])\n",
        "        else:\n",
        "            latents = noise\n",
        "\n",
        "        # Encode prompts\n",
        "        self.load_models_to_device([\"text_encoder\"])\n",
        "        prompt_emb_posi = self.encode_prompt(prompt, positive=True)\n",
        "        if cfg_scale != 1.0:\n",
        "            prompt_emb_nega = self.encode_prompt(negative_prompt, positive=False)\n",
        "\n",
        "        # Encode image\n",
        "        if input_image is not None and self.image_encoder is not None:\n",
        "            self.load_models_to_device([\"image_encoder\", \"vae\"])\n",
        "            if pseudo_video_path is not None and mask_video_path is not None:\n",
        "                # New I2V mode\n",
        "                image_emb = self.encode_image(input_image, pseudo_video_path, mask_video_path)\n",
        "            else:\n",
        "                # Original mode (backward compatibility)\n",
        "                image_emb = self.encode_image(input_image, end_image=end_image, num_frames=num_frames, height=height, width=width)\n",
        "        else:\n",
        "            image_emb = {}\n",
        "\n",
        "        # ControlNet\n",
        "        if control_video is not None:\n",
        "            self.load_models_to_device([\"image_encoder\", \"vae\"])\n",
        "            image_emb = self.prepare_controlnet_kwargs(control_video, num_frames, height, width, **image_emb, **tiler_kwargs)\n",
        "\n",
        "        # Motion Controller\n",
        "        if self.motion_controller is not None and motion_bucket_id is not None:\n",
        "            motion_kwargs = self.prepare_motion_bucket_id(motion_bucket_id)\n",
        "        else:\n",
        "            motion_kwargs = {}\n",
        "\n",
        "        # Extra input\n",
        "        extra_input = self.prepare_extra_input(latents)\n",
        "\n",
        "        # TeaCache\n",
        "        tea_cache_posi = {\"tea_cache\": TeaCache(num_inference_steps, rel_l1_thresh=tea_cache_l1_thresh, model_id=tea_cache_model_id) if tea_cache_l1_thresh is not None else None}\n",
        "        tea_cache_nega = {\"tea_cache\": TeaCache(num_inference_steps, rel_l1_thresh=tea_cache_l1_thresh, model_id=tea_cache_model_id) if tea_cache_l1_thresh is not None else None}\n",
        "\n",
        "        # Unified Sequence Parallel\n",
        "        usp_kwargs = self.prepare_unified_sequence_parallel()\n",
        "\n",
        "        # Denoise\n",
        "        self.load_models_to_device([\"dit\", \"motion_controller\"])\n",
        "        for progress_id, timestep in enumerate(progress_bar_cmd(self.scheduler.timesteps)):\n",
        "            timestep = timestep.unsqueeze(0).to(dtype=self.torch_dtype, device=self.device)\n",
        "\n",
        "            # Inference\n",
        "            noise_pred_posi = model_fn_wan_video(\n",
        "                self.dit, motion_controller=self.motion_controller,\n",
        "                x=latents, timestep=timestep,\n",
        "                **prompt_emb_posi, **image_emb, **extra_input,\n",
        "                **tea_cache_posi, **usp_kwargs, **motion_kwargs\n",
        "            )\n",
        "            if cfg_scale != 1.0:\n",
        "                noise_pred_nega = model_fn_wan_video(\n",
        "                    self.dit, motion_controller=self.motion_controller,\n",
        "                    x=latents, timestep=timestep,\n",
        "                    **prompt_emb_nega, **image_emb, **extra_input,\n",
        "                    **tea_cache_nega, **usp_kwargs, **motion_kwargs\n",
        "                )\n",
        "                noise_pred = noise_pred_nega + cfg_scale * (noise_pred_posi - noise_pred_nega)\n",
        "            else:\n",
        "                noise_pred = noise_pred_posi\n",
        "\n",
        "            # Scheduler\n",
        "            latents = self.scheduler.step(noise_pred, self.scheduler.timesteps[progress_id], latents)\n",
        "\n",
        "        # Decode\n",
        "        self.load_models_to_device(['vae'])\n",
        "        frames = self.decode_video(latents, **tiler_kwargs)\n",
        "        self.load_models_to_device([])\n",
        "        frames = self.tensor2video(frames[0])\n",
        "\n",
        "        return frames\n",
        "\n",
        "class TeaCache:\n",
        "    def __init__(self, num_inference_steps, rel_l1_thresh, model_id):\n",
        "        self.num_inference_steps = num_inference_steps\n",
        "        self.step = 0\n",
        "        self.accumulated_rel_l1_distance = 0\n",
        "        self.previous_modulated_input = None\n",
        "        self.rel_l1_thresh = rel_l1_thresh\n",
        "        self.previous_residual = None\n",
        "        self.previous_hidden_states = None\n",
        "\n",
        "        self.coefficients_dict = {\n",
        "            \"Wan2.1-T2V-1.3B\": [-5.21862437e+04, 9.23041404e+03, -5.28275948e+02, 1.36987616e+01, -4.99875664e-02],\n",
        "            \"Wan2.1-T2V-14B\": [-3.03318725e+05, 4.90537029e+04, -2.65530556e+03, 5.87365115e+01, -3.15583525e-01],\n",
        "            \"Wan2.1-I2V-14B-480P\": [2.57151496e+05, -3.54229917e+04,  1.40286849e+03, -1.35890334e+01, 1.32517977e-01],\n",
        "            \"Wan2.1-I2V-14B-720P\": [ 8.10705460e+03,  2.13393892e+03, -3.72934672e+02,  1.66203073e+01, -4.17769401e-02],\n",
        "        }\n",
        "        if model_id not in self.coefficients_dict:\n",
        "            supported_model_ids = \", \".join([i for i in self.coefficients_dict])\n",
        "            raise ValueError(f\"{model_id} is not a supported TeaCache model id. Please choose a valid model id in ({supported_model_ids}).\")\n",
        "        self.coefficients = self.coefficients_dict[model_id]\n",
        "\n",
        "    def check(self, dit: WanModel, x, t_mod):\n",
        "        modulated_inp = t_mod.clone()\n",
        "        if self.step == 0 or self.step == self.num_inference_steps - 1:\n",
        "            should_calc = True\n",
        "            self.accumulated_rel_l1_distance = 0\n",
        "        else:\n",
        "            coefficients = self.coefficients\n",
        "            rescale_func = np.poly1d(coefficients)\n",
        "            self.accumulated_rel_l1_distance += rescale_func(((modulated_inp-self.previous_modulated_input).abs().mean() / self.previous_modulated_input.abs().mean()).cpu().item())\n",
        "            if self.accumulated_rel_l1_distance < self.rel_l1_thresh:\n",
        "                should_calc = False\n",
        "            else:\n",
        "                should_calc = True\n",
        "                self.accumulated_rel_l1_distance = 0\n",
        "        self.previous_modulated_input = modulated_inp\n",
        "        self.step += 1\n",
        "        if self.step == self.num_inference_steps:\n",
        "            self.step = 0\n",
        "        if should_calc:\n",
        "            self.previous_hidden_states = x.clone()\n",
        "        return not should_calc\n",
        "\n",
        "    def store(self, hidden_states):\n",
        "        self.previous_residual = hidden_states - self.previous_hidden_states\n",
        "        self.previous_hidden_states = None\n",
        "\n",
        "    def update(self, hidden_states):\n",
        "        hidden_states = hidden_states + self.previous_residual\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_wan_video(\n",
        "    dit: WanModel,\n",
        "    motion_controller: WanMotionControllerModel = None,\n",
        "    x: torch.Tensor = None,\n",
        "    timestep: torch.Tensor = None,\n",
        "    context: torch.Tensor = None,\n",
        "    clip_feature: Optional[torch.Tensor] = None,\n",
        "    y: Optional[torch.Tensor] = None,\n",
        "    tea_cache: TeaCache = None,\n",
        "    use_unified_sequence_parallel: bool = False,\n",
        "    motion_bucket_id: Optional[torch.Tensor] = None,\n",
        "    **kwargs,\n",
        "):\n",
        "    if use_unified_sequence_parallel:\n",
        "        import torch.distributed as dist\n",
        "        from xfuser.core.distributed import (get_sequence_parallel_rank,\n",
        "                                            get_sequence_parallel_world_size,\n",
        "                                            get_sp_group)\n",
        "\n",
        "    t = dit.time_embedding(sinusoidal_embedding_1d(dit.freq_dim, timestep))\n",
        "    t_mod = dit.time_projection(t).unflatten(1, (6, dit.dim))\n",
        "    if motion_bucket_id is not None and motion_controller is not None:\n",
        "        t_mod = t_mod + motion_controller(motion_bucket_id).unflatten(1, (6, dit.dim))\n",
        "    context = dit.text_embedding(context)\n",
        "\n",
        "    if dit.has_image_input:\n",
        "        x = torch.cat([x, y], dim=1)  # (b, c_x + c_y, f, h, w)\n",
        "        clip_embdding = dit.img_emb(clip_feature)\n",
        "        context = torch.cat([clip_embdding, context], dim=1)\n",
        "\n",
        "    x, (f, h, w) = dit.patchify(x)\n",
        "\n",
        "    freqs = torch.cat([\n",
        "        dit.freqs[0][:f].view(f, 1, 1, -1).expand(f, h, w, -1),\n",
        "        dit.freqs[1][:h].view(1, h, 1, -1).expand(f, h, w, -1),\n",
        "        dit.freqs[2][:w].view(1, 1, w, -1).expand(f, h, w, -1)\n",
        "    ], dim=-1).reshape(f * h * w, 1, -1).to(x.device)\n",
        "\n",
        "    # TeaCache\n",
        "    if tea_cache is not None:\n",
        "        tea_cache_update = tea_cache.check(dit, x, t_mod)\n",
        "    else:\n",
        "        tea_cache_update = False\n",
        "\n",
        "    # blocks\n",
        "    if use_unified_sequence_parallel:\n",
        "        if dist.is_initialized() and dist.get_world_size() > 1:\n",
        "            x = torch.chunk(x, get_sequence_parallel_world_size(), dim=1)[get_sequence_parallel_rank()]\n",
        "    if tea_cache_update:\n",
        "        x = tea_cache.update(x)\n",
        "    else:\n",
        "        for block in dit.blocks:\n",
        "            x = block(x, context, t_mod, freqs)\n",
        "        if tea_cache is not None:\n",
        "            tea_cache.store(x)\n",
        "\n",
        "    x = dit.head(x, t)\n",
        "    if use_unified_sequence_parallel:\n",
        "        if dist.is_initialized() and dist.get_world_size() > 1:\n",
        "            x = get_sp_group().all_gather(x, dim=1)\n",
        "    x = dit.unpatchify(x, (f, h, w))\n",
        "    return x"
      ],
      "metadata": {
        "id": "3OwClJMLGc7L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import re\n",
        "import random\n",
        "from PIL import Image\n",
        "from diffsynth import ModelManager, save_video, VideoData\n",
        "# from custom_wan_pipe import WanVideoPipeline\n",
        "\n",
        "# Florence model import - required dependency\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "\n",
        "# Global variables to store Florence model\n",
        "florence_model = None\n",
        "florence_processor = None\n",
        "\n",
        "def init_florence_model():\n",
        "    \"\"\"Initialize Florence model, only needs to be called once\"\"\"\n",
        "    global florence_model, florence_processor\n",
        "\n",
        "    if florence_model is not None and florence_processor is not None:\n",
        "        return True  # Model already loaded, no need to reload\n",
        "\n",
        "    print(\"Loading Florence model, please wait...\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "    # Load model and processor\n",
        "    florence_model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"multimodalart/Florence-2-large-no-flash-attn\", torch_dtype=torch_dtype, trust_remote_code=True\n",
        "    ).to(device)\n",
        "\n",
        "    florence_processor = AutoProcessor.from_pretrained(\n",
        "        \"multimodalart/Florence-2-large-no-flash-attn\", trust_remote_code=True\n",
        "    )\n",
        "    print(\"Florence model loaded successfully\")\n",
        "    return True\n",
        "\n",
        "def generate_caption(image, concept_prefix=\"\"):\n",
        "    \"\"\"Use Florence model to generate caption for image\"\"\"\n",
        "    global florence_model, florence_processor\n",
        "\n",
        "    if florence_model is None or florence_processor is None:\n",
        "        raise RuntimeError(\"Florence model not initialized, please call init_florence_model() first\")\n",
        "\n",
        "    device = next(florence_model.parameters()).device\n",
        "    torch_dtype = next(florence_model.parameters()).dtype\n",
        "\n",
        "    # If input is a path, read image; if PIL Image object, use directly\n",
        "    if isinstance(image, str):\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "    elif hasattr(image, 'convert'):\n",
        "        image = image.convert(\"RGB\")\n",
        "    else:\n",
        "        # If it's a numpy array, convert to PIL Image\n",
        "        if hasattr(image, 'shape'):\n",
        "            image = Image.fromarray(image).convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported image format\")\n",
        "\n",
        "    prompt = \"<DETAILED_CAPTION>\"\n",
        "\n",
        "    # Construct input\n",
        "    inputs = florence_processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
        "\n",
        "    # Generate caption\n",
        "    generated_ids = florence_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], pixel_values=inputs[\"pixel_values\"], max_new_tokens=1024, num_beams=3\n",
        "    )\n",
        "    generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    # Post-processing\n",
        "    parsed_answer = florence_processor.post_process_generation(\n",
        "        generated_text, task=prompt, image_size=(image.width, image.height)\n",
        "    )\n",
        "    caption_text = parsed_answer[\"<DETAILED_CAPTION>\"].replace(\"The image shows \", \"\")\n",
        "\n",
        "    # Add concept prefix\n",
        "    if concept_prefix:\n",
        "        caption_text = f\"{concept_prefix} {caption_text}\"\n",
        "\n",
        "    return caption_text\n",
        "\n",
        "def find_max_epoch_lora(data_dir, use_additional=False):\n",
        "    \"\"\"Find the lora file with maximum epoch\"\"\"\n",
        "    lora_dir_name = \"lora_additional\" if use_additional else \"lora\"\n",
        "    lora_base_dir = os.path.join(data_dir, lora_dir_name)\n",
        "    if not os.path.exists(lora_base_dir):\n",
        "        if use_additional:\n",
        "            raise FileNotFoundError(f\"Additional LoRA directory does not exist: {lora_base_dir}\\n\"\n",
        "                                  f\"Please train additional LoRA first using: python train.py --config {os.path.join(data_dir, 'configs', 'training_additional.toml')}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"LoRA directory does not exist: {lora_base_dir}\")\n",
        "\n",
        "    # Find all date directories\n",
        "    date_dirs = [d for d in os.listdir(lora_base_dir) if os.path.isdir(os.path.join(lora_base_dir, d))]\n",
        "    if not date_dirs:\n",
        "        raise FileNotFoundError(f\"No training directories found in LoRA directory: {lora_base_dir}\")\n",
        "\n",
        "    # Find the latest training directory (sorted by name, usually datetime format)\n",
        "    latest_date_dir = sorted(date_dirs)[-1]\n",
        "    date_dir_path = os.path.join(lora_base_dir, latest_date_dir)\n",
        "\n",
        "    # Find epoch directories\n",
        "    epoch_dirs = []\n",
        "    for item in os.listdir(date_dir_path):\n",
        "        item_path = os.path.join(date_dir_path, item)\n",
        "        if os.path.isdir(item_path) and item.startswith(\"epoch\"):\n",
        "            # Extract epoch number\n",
        "            match = re.search(r'epoch(\\d+)', item)\n",
        "            if match:\n",
        "                epoch_num = int(match.group(1))\n",
        "                epoch_dirs.append((epoch_num, item_path))\n",
        "\n",
        "    if not epoch_dirs:\n",
        "        raise FileNotFoundError(f\"No epoch directories found in {date_dir_path}\")\n",
        "\n",
        "    # Find maximum epoch\n",
        "    max_epoch_num, max_epoch_path = max(epoch_dirs, key=lambda x: x[0])\n",
        "    lora_file_path = os.path.join(max_epoch_path, \"adapter_model.safetensors\")\n",
        "\n",
        "    if not os.path.exists(lora_file_path):\n",
        "        raise FileNotFoundError(f\"LoRA file does not exist: {lora_file_path}\")\n",
        "\n",
        "    lora_type = \"additional\" if use_additional else \"standard\"\n",
        "    print(f\"Found {lora_type} LoRA file with maximum epoch: epoch{max_epoch_num} - {lora_file_path}\")\n",
        "    return lora_file_path\n",
        "\n",
        "def find_input_image(data_dir):\n",
        "    \"\"\"Find edited image, prioritize png, then jpg\"\"\"\n",
        "    png_path = os.path.join(data_dir, \"edited_image.png\")\n",
        "    jpg_path = os.path.join(data_dir, \"edited_image.jpg\")\n",
        "    # f\"1. Save the edited first frame (from {output_dir}/source_frames/00000.png) as: {output_dir}/edited_image.png (or .jpg)\",\n",
        "\n",
        "    if os.path.exists(png_path):\n",
        "        print(f\"Found edited image: {png_path}\")\n",
        "        return png_path\n",
        "    elif os.path.exists(jpg_path):\n",
        "        print(f\"Found edited image: {jpg_path}\")\n",
        "        return jpg_path\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Edited image does not exist, checked the following paths:\\n- {png_path}\\n- {jpg_path}\")\n",
        "\n",
        "def validate_paths(model_root_dir, data_dir):\n",
        "    \"\"\"Validate if paths exist\"\"\"\n",
        "    if not os.path.exists(model_root_dir):\n",
        "        raise FileNotFoundError(f\"Model root directory does not exist: {model_root_dir}\")\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        raise FileNotFoundError(f\"Data directory does not exist: {data_dir}\")\n",
        "\n",
        "    # Check required model files\n",
        "    required_files = [\n",
        "        # \"models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\",\n",
        "        \"models_t5_umt5-xxl-enc-bf16.pth\",\n",
        "        \"Wan2.1_VAE.pth\"\n",
        "    ]\n",
        "\n",
        "    for file_name in required_files:\n",
        "        file_path = os.path.join(model_root_dir, file_name)\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(f\"Required model file does not exist: {file_path}\")\n",
        "\n",
        "    # Check diffusion model files\n",
        "    diffusion_model_pattern = os.path.join(model_root_dir, \"diffusion_pytorch_model*.safetensors\")\n",
        "    diffusion_model_files = glob.glob(diffusion_model_pattern)\n",
        "    if not diffusion_model_files:\n",
        "        raise FileNotFoundError(f\"No diffusion model files found, pattern: {diffusion_model_pattern}\")\n",
        "\n",
        "def main(model_root_dir, data_dir, use_additional=False):\n",
        "    \"\"\"Main function\"\"\"\n",
        "    try:\n",
        "        # Validate paths\n",
        "        print(\"Validating paths...\")\n",
        "        validate_paths(model_root_dir, data_dir)\n",
        "\n",
        "        # Infer various paths\n",
        "        print(\"Inferring paths...\")\n",
        "        lora_path = find_max_epoch_lora(data_dir, use_additional=use_additional)\n",
        "        input_image_path = find_input_image(data_dir)\n",
        "        # pseudo_video_path = os.path.join(data_dir, \"inference_rgb.mp4\")\n",
        "        # mask_video_path = os.path.join(data_dir, \"inference_mask.mp4\")\n",
        "\n",
        "        # # Check if video files exist\n",
        "        # if not os.path.exists(pseudo_video_path):\n",
        "        #     raise FileNotFoundError(f\"Pseudo video file does not exist: {pseudo_video_path}\")\n",
        "        # if not os.path.exists(mask_video_path):\n",
        "        #     raise FileNotFoundError(f\"Mask video file does not exist: {mask_video_path}\")\n",
        "\n",
        "        print(f\"Using paths:\")\n",
        "        print(f\"  Model root directory: {model_root_dir}\")\n",
        "        print(f\"  Data directory: {data_dir}\")\n",
        "        print(f\"  LoRA file: {lora_path}\")\n",
        "        print(f\"  Edited image: {input_image_path}\")\n",
        "\n",
        "        # Automatically find all safetensors files starting with diffusion_pytorch_model\n",
        "        diffusion_model_pattern = os.path.join(model_root_dir, \"diffusion_pytorch_model*.safetensors\")\n",
        "        diffusion_model_files = sorted(glob.glob(diffusion_model_pattern))\n",
        "\n",
        "        print(\"Loading models...\")\n",
        "        model_manager = ModelManager(device=\"cpu\")\n",
        "        # model_manager.load_models([\n",
        "        #     os.path.join(model_root_dir, \"models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\"),\n",
        "        # ], torch_dtype=torch.float32)\n",
        "        model_manager.load_models([\n",
        "            diffusion_model_files,\n",
        "            os.path.join(model_root_dir, \"models_t5_umt5-xxl-enc-bf16.pth\"),\n",
        "            os.path.join(model_root_dir, \"Wan2.1_VAE.pth\"),\n",
        "        ], torch_dtype=torch.bfloat16)\n",
        "        model_manager.load_lora(lora_path, lora_alpha=1.0)\n",
        "        pipe = WanVideoPipeline.from_model_manager(model_manager, torch_dtype=torch.bfloat16, device=\"cuda\")\n",
        "        pipe.enable_vram_management(num_persistent_param_in_dit=0)\n",
        "\n",
        "        # Initialize Florence model\n",
        "        print(\"Initializing Florence model...\")\n",
        "        init_florence_model()\n",
        "\n",
        "        # Load edited image\n",
        "        input_image = Image.open(input_image_path)\n",
        "\n",
        "        # Read concept prefix from prefix.txt\n",
        "        prefix_file = os.path.join(data_dir, 'prefix.txt')\n",
        "        concept_prefix = \"\"\n",
        "        if os.path.exists(prefix_file):\n",
        "            try:\n",
        "                with open(prefix_file, 'r', encoding='utf-8') as f:\n",
        "                    concept_prefix = f.read().strip()\n",
        "                print(f\"Read concept prefix from {prefix_file}: {concept_prefix}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to read prefix.txt file: {e}\")\n",
        "                concept_prefix = \"p3rs0n,\"  # Use default value\n",
        "        else:\n",
        "            print(f\"prefix.txt file not found: {prefix_file}, using default prefix\")\n",
        "            concept_prefix = \"p3rs0n,\"\n",
        "\n",
        "        # Dynamically generate prompt\n",
        "        print(\"Generating caption for edited image...\")\n",
        "        generated_prompt = generate_caption(input_image, concept_prefix=concept_prefix)\n",
        "        print(f\"Generated prompt: {generated_prompt}\")\n",
        "\n",
        "        # Generate random seed\n",
        "        random_seed = random.randint(0, 2**32 - 1)\n",
        "        print(f\"Using random seed: {random_seed}\")\n",
        "\n",
        "        print(\"Starting inference...\")\n",
        "        video = pipe(\n",
        "            prompt=generated_prompt,\n",
        "            negative_prompt=\"Overexposure, static, blurred details, subtitles, paintings, pictures, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, mutilated, redundant fingers, poorly painted hands, poorly painted faces, deformed, disfigured, deformed limbs, fused fingers, cluttered background, three legs, a lot of people in the background, upside down\",\n",
        "            input_image=input_image,\n",
        "            # pseudo_video_path=pseudo_video_path,\n",
        "            # mask_video_path=mask_video_path,\n",
        "            num_inference_steps=30,\n",
        "            seed=random_seed, tiled=True,\n",
        "            # TeaCache parameters\n",
        "            tea_cache_l1_thresh=0.275, # The larger this value is, the faster the speed, but the worse the visual quality.\n",
        "            tea_cache_model_id=\"Wan2.1-I2V-14B-480P\", # Choose one in (Wan2.1-T2V-1.3B, Wan2.1-T2V-14B, Wan2.1-I2V-14B-480P, Wan2.1-I2V-14B-720P).\n",
        "        )\n",
        "\n",
        "        output_path = os.path.join(data_dir, \"edited_video.mp4\")\n",
        "        save_video(video, output_path, fps=30, quality=5)\n",
        "        print(f\"Video saved to: {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     parser = argparse.ArgumentParser(description=\"Video generation inference script\")\n",
        "#     parser.add_argument(\"--model_root_dir\", required=True, help=\"Model root directory path\")\n",
        "#     parser.add_argument(\"--data_dir\", required=True,    #     default=\"Wan2.1-T2V-1.3B\",\n",
        "#  help=\"Data directory path\")\n",
        "#     parser.add_argument(\"--additional\", action=\"store_true\",\n",
        "#                        help=\"Use additional LoRA model from lora_additional directory instead of standard lora directory\")\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "#     main(args.model_root_dir, args.data_dir, use_additional=args.additional) #여기까지 inference.py\n",
        "\n",
        "# python inference.py --model_root_dir ./Wan2.1-I2V-14B-480P --data_dir ./processed_data/your_sequence\n",
        "# Wan2.1-T2V-1.3B\n",
        "\n"
      ],
      "metadata": {
        "id": "HDa2jyJFGfMO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import argparse\n",
        "# parser = argparse.ArgumentParser(description=\"Video generation inference script\")\n",
        "# parser.add_argument(\"--model_root_dir\", required=False, default=\"Wan2.1-T2V-1.3B\",\n",
        "#                     help=\"Model root directory path\")\n",
        "# parser.add_argument(\"--data_dir\", required=False, default=\"/content/myfolder/data\",\n",
        "#                     help=\"Data directory path\")\n",
        "# parser.add_argument(\"--additional\", action=\"store_true\", default=\"Wan2.1-T2V-1.3B\",\n",
        "#                     help=\"Use additional LoRA model from lora_additional directory instead of standard lora directory\")\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# args, unknown = parser.parse_known_args()\n",
        "# config = ed(vars(args))\n",
        "from easydict import EasyDict as ed\n",
        "\n",
        "config = ed({\n",
        "    \"model_root_dir\": \"Wan2.1-T2V-1.3B\",\n",
        "    \"data_dir\": \"/content/myfolder/data\",\n",
        "    \"additional\": False,  # or False\n",
        "}) #--additional을 cmd에 안적으면 false\n",
        "# main(config.model_root_dir, config.data_dir, use_additional=args.additional) #여기까지 inference.py\n"
      ],
      "metadata": {
        "id": "I1eA5yTdxufx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your edited first frame as edited_image.png (or .jpg) in the data directory\n",
        "# Then run inference\n",
        "python inference.py --model_root_dir ./Wan2.1-I2V-14B-480P --data_dir ./processed_data/your_sequence"
      ],
      "metadata": {
        "id": "oBeu6uqTTLqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/myfolder/data/00000.jpg /content/myfolder/data/edited_image.jpg"
      ],
      "metadata": {
        "id": "1JyeJEmQVB1y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(config.model_root_dir, config.data_dir, use_additional=config.additional)"
      ],
      "metadata": {
        "id": "3jTHtr8v2xIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5c1780-1656-4c37-8829-14b130dd9382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating paths...\n",
            "Inferring paths...\n",
            "Found standard LoRA file with maximum epoch: epoch10 - /content/myfolder/data/lora/20250726_08-49-03/epoch10/adapter_model.safetensors\n",
            "Found edited image: /content/myfolder/data/edited_image.jpg\n",
            "Using paths:\n",
            "  Model root directory: Wan2.1-T2V-1.3B\n",
            "  Data directory: /content/myfolder/data\n",
            "  LoRA file: /content/myfolder/data/lora/20250726_08-49-03/epoch10/adapter_model.safetensors\n",
            "  Edited image: /content/myfolder/data/edited_image.jpg\n",
            "Loading models...\n",
            "Loading models from: ['Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors']\n",
            "    model_name: wan_video_dit model_class: WanModel\n",
            "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 16, 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 16, 'num_heads': 12, 'num_layers': 30, 'eps': 1e-06}\n",
            "    The following models are loaded: ['wan_video_dit'].\n",
            "Loading models from: Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main(config.model_root_dir, config.data_dir, use_additional=config.additional)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "apHladUpWN5t",
        "outputId": "0189aba5-36b9-4119-8bdb-6d90b44ce2e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'main' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2206545329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_root_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_additional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import json\n",
        "import decord\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "\n",
        "def sample_video_frames(video_path, num_frames=None):\n",
        "    vr = decord.VideoReader(video_path)\n",
        "    total_frames = len(vr)\n",
        "\n",
        "    if num_frames is None:\n",
        "        frame_indices = np.arange(total_frames)\n",
        "    else:\n",
        "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
        "\n",
        "    frames = []\n",
        "    for idx in frame_indices:\n",
        "        frame = vr[int(idx)].asnumpy()\n",
        "        pil_image = Image.fromarray(frame)\n",
        "        frames.append(pil_image)\n",
        "\n",
        "    return frames\n",
        "\n",
        "\n",
        "def compute_farneback_optical_flow(frames):\n",
        "    prev_gray = cv2.cvtColor(np.array(frames[0]), cv2.COLOR_BGR2GRAY)\n",
        "    flow_maps = []\n",
        "    magnitudes = []\n",
        "    angles = []\n",
        "    images = []\n",
        "    hsv = np.zeros_like(frames[0])\n",
        "    hsv[..., 1] = 255\n",
        "\n",
        "    for frame in frames[1:]:\n",
        "        gray = cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY)\n",
        "        flow_map = cv2.calcOpticalFlowFarneback(\n",
        "            prev_gray,\n",
        "            gray,\n",
        "            flow=None,\n",
        "            pyr_scale=0.5,\n",
        "            levels=3,\n",
        "            winsize=15,\n",
        "            iterations=3,\n",
        "            poly_n=5,\n",
        "            poly_sigma=1.2,\n",
        "            flags=0,\n",
        "        )\n",
        "        magnitude, angle = cv2.cartToPolar(flow_map[..., 0], flow_map[..., 1])\n",
        "        hsv[..., 0] = angle * 180 / np.pi / 2\n",
        "        hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "        flow_maps.append(flow_map)\n",
        "        magnitudes.append(magnitude)\n",
        "        angles.append(angle)\n",
        "        images.append(bgr)\n",
        "        prev_gray = gray\n",
        "    return flow_maps, magnitudes, angles, images\n",
        "\n",
        "\n",
        "def compute_lk_optical_flow(frames):\n",
        "    maxCorners = 50\n",
        "    feature_params = {\n",
        "        \"maxCorners\": maxCorners,\n",
        "        \"qualityLevel\": 0.3,\n",
        "        \"minDistance\": 7,\n",
        "        \"blockSize\": 7,\n",
        "    }\n",
        "    lk_params = {\n",
        "        \"winSize\": (15, 15),\n",
        "        \"maxLevel\": 2,\n",
        "        \"criteria\": (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        "    }\n",
        "    color = np.random.randint(0, 255, (maxCorners, 3))\n",
        "    old_frame = frames[0]\n",
        "    old_gray = cv2.cvtColor(np.array(old_frame), cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    for frame in frames[1:]:\n",
        "        frame_gray = cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY)\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "            old_gray, frame_gray, p0, None, **lk_params\n",
        "        )\n",
        "        if p1 is not None:\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(\n",
        "                mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2\n",
        "            )\n",
        "        old_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _downscale_maps(flow_maps, downscale_size: int = 16):\n",
        "    return [\n",
        "        cv2.resize(\n",
        "            flow,\n",
        "            (downscale_size, int(flow.shape[0] * (downscale_size / flow.shape[1]))),\n",
        "            interpolation=cv2.INTER_AREA,\n",
        "        )\n",
        "        for flow in flow_maps\n",
        "    ]\n",
        "\n",
        "\n",
        "def _motion_score(flow_maps):\n",
        "    average_flow_map = np.mean(np.array(flow_maps), axis=0)\n",
        "    return np.mean(average_flow_map)\n",
        "\n",
        "\n",
        "def process_video(video_path):\n",
        "    frames = sample_video_frames(video_path, num_frames=None)\n",
        "\n",
        "    farneback, _, _, _ = compute_farneback_optical_flow(frames)\n",
        "    farneback = float(_motion_score(_downscale_maps(farneback)))\n",
        "    lucas_kanade = float(_motion_score(compute_lk_optical_flow(frames)))\n",
        "\n",
        "    return {\n",
        "        \"motion_fb\": abs(farneback),\n",
        "        \"motion_lk\": lucas_kanade,\n",
        "    }\n",
        "\n",
        "\n",
        "# def parse_args():\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument(\n",
        "    #     \"--input_video_folder\",\n",
        "    #     type=str,\n",
        "    #     default=\"demo_result/model_name_input_video\",\n",
        "    # )\n",
        "    # parser.add_argument(\n",
        "    #     \"--output_json_folder\",\n",
        "    #     type=str,\n",
        "    #     default=\"demo_result/model_name_output_json\",\n",
        "    # )\n",
        "    # parser.add_argument(\"--num_workers\", type=int, default=32)\n",
        "    # return parser.parse_args()\n",
        "\n",
        "\n",
        "# def parse_args():\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument(\n",
        "#         \"--input_video_folder\",\n",
        "#         type=str,\n",
        "#         default=\"content/video\",\n",
        "#     )\n",
        "#     parser.add_argument(\n",
        "#         \"--output_json_folder\",\n",
        "#         type=str,\n",
        "#         default=\"content/output\",\n",
        "#     )\n",
        "#     parser.add_argument(\"--num_workers\", type=int, default=32)\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     # EasyDict로 변환\n",
        "#     config = ed(vars(args))\n",
        "\n",
        "#     return config\n",
        "# import argparse\n",
        "# from easydict import EasyDict as ed\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--input_video_folder\",\n",
        "        type=str,\n",
        "        default=\"/content/video\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_json_folder\",\n",
        "        type=str,\n",
        "        default=\"/content/output\",\n",
        "    )\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=32)\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    config = ed(vars(args))\n",
        "    return config\n",
        "\n",
        "# 사용\n",
        "config = parse_args()\n",
        "print(config.input_video_folder)\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    input_video_folder = args.input_video_folder\n",
        "    output_json_folder = args.output_json_folder\n",
        "    num_workers = args.num_workers\n",
        "\n",
        "    output_json_file = os.path.join(output_json_folder, \"motionscore.json\")\n",
        "    os.makedirs(output_json_folder, exist_ok=True)\n",
        "\n",
        "    all_results = {}\n",
        "    video_files = [f for f in os.listdir(input_video_folder) if f.endswith(\".mp4\")]\n",
        "\n",
        "    def worker(filename):\n",
        "        video_path = os.path.join(input_video_folder, filename)\n",
        "        video_prefix = os.path.splitext(filename)[0]\n",
        "        motion_scores = process_video(video_path)\n",
        "        return video_prefix, motion_scores\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        futures = [executor.submit(worker, filename) for filename in video_files]\n",
        "        for future in as_completed(futures):\n",
        "            video_prefix, motion_scores = future.result()\n",
        "            all_results[video_prefix] = motion_scores\n",
        "\n",
        "    with open(output_json_file, \"w\") as f:\n",
        "        json.dump(all_results, f, indent=4)\n",
        "\n",
        "    print(f\"All results have been saved to {output_json_file}\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "    # main()"
      ],
      "metadata": {
        "id": "2BJ5U5MbnEfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973e3397-de63-458d-ecd0-9cc6f58fddee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CoBVLGcVn-C",
        "outputId": "0e63c56f-7360-487b-eb79-0cb5cc903dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results have been saved to /content/output/motionscore.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  !cp /content/drive/MyDrive/vlora/data/A.mp4 /content/video"
      ],
      "metadata": {
        "id": "tA3y_1CNNHVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--input_video_folder\",\n",
        "        type=str,\n",
        "        default=\"content/video\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_json_folder\",\n",
        "        type=str,\n",
        "        default=\"content/output\",\n",
        "    )\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=32)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # EasyDict로 변환\n",
        "    config = ed(vars(args))\n",
        "\n",
        "    return config\n",
        "\n",
        "# 사용 예시\n",
        "config = parse_args()\n",
        "print(config.input_video_folder)  # 'demo_result/model_name_input_video'\n",
        "print(config.num_workers)  # 32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "kBFvqXaY20ZR",
        "outputId": "628531df-e419-4e84-ab43-4595dd383b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--input_video_folder INPUT_VIDEO_FOLDER]\n",
            "                                [--output_json_folder OUTPUT_JSON_FOLDER]\n",
            "                                [--num_workers NUM_WORKERS]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-54a0da6b-b0ed-42cf-87c4-7a645fdd0d91.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}