{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emhz6TsC0WMH",
    "outputId": "84e5ea50-067e-4d53-8374-71c3d7d6fca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-5.2.0 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ\n",
      "From (redirected): https://drive.google.com/uc?id=1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ&confirm=t&uuid=8c0df92e-1b89-445a-8a35-9b686210df51\n",
      "To: /workspace/vlora.zip\n",
      "100%|████████████████████████████████████████| 717M/717M [00:09<00:00, 73.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gdown  # 설치 안되어 있다면 먼저 설치\n",
    "!gdown 1bDf8OCVlZfJ6XauPIzZYfVkQhj7BMiFJ\n",
    "\n",
    "# !gdown --folder 1miYmYG8DwNQHMamcfBwJdzISCgH4C1nL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PT-ToHt1dt3",
    "outputId": "0b3e50ff-771c-4344-9e74-061a8a506228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: unzip: command not found\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# !cp -r \"/content/drive/MyDrive/vlora\" ./myfolder\n",
    "!unzip -q vlora.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"vlora.zip\"\n",
    "extract_dir = \"vlora\"\n",
    "\n",
    "# 디렉토리 없으면 생성\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# 압축 해제\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skTyoLRC0sqc",
    "outputId": "445f60a0-58f0-413c-8b4e-71112ddac9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install diffsynth easydict decord -q\n",
    "import argparse\n",
    "from easydict import EasyDict as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYoPdlr6xJl_",
    "outputId": "83138817-e6c2-46e6-9f07-3e38078153c9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (1.1.5)\n",
      "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[cli]) (0.3.4)\n",
      "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.50)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[cli]) (2025.1.31)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "Fetching 22 files:   0%|                                 | 0/22 [00:00<?, ?it/s]Downloading 'assets/data_for_diff_stage.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/UCVN8O248kjCIp8i1TvUXWfm-q4=.59aec08409f2d46b0e640e4e120dc7cca52c08c3de56d026602dbcff1ebf241a.incomplete'\n",
      "Still waiting to acquire lock on Wan2.1-T2V-1.3B/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Still waiting to acquire lock on Wan2.1-T2V-1.3B/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Still waiting to acquire lock on Wan2.1-T2V-1.3B/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Still waiting to acquire lock on Wan2.1-T2V-1.3B/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Still waiting to acquire lock on Wan2.1-T2V-1.3B/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "\n",
      "data_for_diff_stage.jpg:   0%|                       | 0.00/528k [00:00<?, ?B/s]\u001b[ADownloading 'assets/i2v_res.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/GL7zbyOeRDu8VADezw2p_Gw3fW4=.6823b3206d8d0cb18d3b5b949dec1217f1178109ba11f14e977b67e1f7b8a248.incomplete'\n",
      "data_for_diff_stage.jpg: 100%|███████████████| 528k/528k [00:00<00:00, 13.1MB/s]\n",
      "Downloading 'assets/comp_effic.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/X4-4NQEdffK1bUQbDx0NJ4IbcNo=.b0e225caffb4b31295ad150f95ee852e4c3dde4a00ac8f79a2ff500f2ce26b8d.incomplete'\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/data_for_diff_stage.jpg\n",
      "Downloading 'Wan2.1_VAE.pth' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/OZTShqo6Di7rh0SEswnfwSjKa9w=.38071ab59bd94681c686fa51d75a1968f64e470262043be31f7a094e442fd981.incomplete'\n",
      "Downloading 'assets/.DS_Store' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/aHCrtOA_94YSUtnsyba37B_tPq0=.d65165279105ca6773180500688df4bdc69a2c7b771752f0a46ef120b7fd8ec3.incomplete'\n",
      "Downloading 'README.md' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.fbbf7c13900d37f3179c546d09372aeb52e0fae1.incomplete'\n",
      "Downloading '.gitattributes' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.0a1f66aea84e17cbf6a60c51431723062f87df8a.incomplete'\n",
      "Downloading 'LICENSE.txt' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/cyBuwAu93UXke23CJCWORBYR70A=.261eeb9e9f8b2b4b0d119366dda99c6fd7d35c64.incomplete'\n",
      "\n",
      "comp_effic.png:   0%|                               | 0.00/1.79M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:   0%|                                | 0.00/508M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "i2v_res.png:   0%|                                   | 0.00/892k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      ".DS_Store: 100%|███████████████████████████| 6.15k/6.15k [00:00<00:00, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/.DS_Store\n",
      "Downloading 'assets/logo.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/gvouIpVGo_vjLxWDOGAmKk_SZvY=.96cddc0f667293436d0b9f92a299b6346b65b231d38ee49719a33d46c91fe1e3.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "README.md: 16.9kB [00:00, 49.2MB/s]A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/README.md\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".gitattributes: 2.23kB [00:00, 7.41MB/s]A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/.gitattributes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LICENSE.txt: 11.4kB [00:00, 33.0MB/s]A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/LICENSE.txt\n",
      "Fetching 22 files:   5%|█▏                       | 1/22 [00:00<00:06,  3.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "logo.png: 100%|████████████████████████████| 56.3k/56.3k [00:00<00:00, 98.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "comp_effic.png: 100%|██████████████████████| 1.79M/1.79M [00:00<00:00, 31.0MB/s]\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/logo.png\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/comp_effic.png\n",
      "i2v_res.png: 100%|███████████████████████████| 892k/892k [00:00<00:00, 13.3MB/s]\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/i2v_res.png\n",
      "Downloading 'assets/vben_1.3b_vs_sota.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/yhawob5KxOUy3bpsGU-xOWB6FC8=.b7705db79f2e1428ec7a1e6fff8c4fbde062fb95bb233516ddbd04b20007c845.incomplete'\n",
      "Downloading 'assets/t2v_res.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/VwwCFkBXvnWpmAWpzHvOZFYnnp8=.91db579092446be2a834bc67721a8e4346936f38c4edb912f459ca3e10f8f439.incomplete'\n",
      "Downloading 'assets/vben_vs_sota.png' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/p0uIb0aMIBdDB8sg9tk5UvunoB8=.9a0e86ca85046d2675f97984b88b6e74df07bba8a62a31ab8a1aef50d4eda44e.incomplete'\n",
      "Downloading 'assets/video_dit_arch.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/PbT6aGUrWxKRPnz45UQ5EbqxKYE=.195dceec6570289d8b01cc51d2e28a7786216f19de55b23978a52610d1646a66.incomplete'\n",
      "\n",
      "t2v_res.jpg:   0%|                                   | 0.00/301k [00:00<?, ?B/s]\u001b[ADownloading 'assets/video_vae_res.jpg' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/assets/_r133FrlYqQbngOMpQWXWYhhvVM=.d8f9e7f7353848056a615c8ef35ab86ec22976bb46cb27405008b4089701945c.incomplete'\n",
      "\n",
      "\n",
      "Wan2.1_VAE.pth:   4%|▉                       | 21.0M/508M [00:00<00:03, 142MB/s]\u001b[A\u001b[ADownloading 'config.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.d203bef600b2f3c64fe1f5f53d70a2087f4ccd2f.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "vben_vs_sota.png:   0%|                             | 0.00/1.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'diffusion_pytorch_model.safetensors' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/4SfAgk9U607e8pVunEB9nSiU10k=.96b6b242ca1c2f24e9d02cd6596066fab6d310e2d7538f33ae267cb18d957e8f.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t2v_res.jpg: 100%|███████████████████████████| 301k/301k [00:00<00:00, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/t2v_res.jpg\n",
      "\n",
      "video_vae_res.jpg:   0%|                             | 0.00/213k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "video_vae_res.jpg: 100%|█████████████████████| 213k/213k [00:00<00:00, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/video_vae_res.jpg\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 249/249 [00:00<00:00, 2.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "vben_1.3b_vs_sota.png: 100%|█████████████████| 516k/516k [00:00<00:00, 13.2MB/s]\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/vben_1.3b_vs_sota.png\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/config.json\n",
      "vben_vs_sota.png: 100%|████████████████████| 1.55M/1.55M [00:00<00:00, 29.0MB/s]\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/vben_vs_sota.png\n",
      "video_dit_arch.jpg: 100%|████████████████████| 643k/643k [00:00<00:00, 16.1MB/s]\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/assets/video_dit_arch.jpg\n",
      "Downloading 'examples/i2v_input.JPG' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/examples/GqO1vCXUoNdTZc6wjxo1L7sjRdI=.077e3d965090c9028c69c00931675f42e1acc815c6eb450ab291b3b72d211a8e.incomplete'\n",
      "Downloading 'google/umt5-xxl/spiece.model' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/vj8E1loknrCNPSP8nWJC234Bff4=.e3909a67b780650b35cf529ac782ad2b6b26e6d1f849d3fbb6a872905f452458.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "i2v_input.JPG: 100%|█████████████████████████| 251k/251k [00:00<00:00, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/examples/i2v_input.JPG\n",
      "\n",
      "\n",
      "Wan2.1_VAE.pth:  10%|██▍                     | 52.4M/508M [00:00<00:02, 181MB/s]\u001b[A\u001b[ADownloading 'models_t5_umt5-xxl-enc-bf16.pth' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/7xjTyx9p9-CteGiI3VEINu_Ohx0=.7cace0da2b446bbbbc57d031ab6cf163a3d59b366da94e5afe36745b746fd81d.incomplete'\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   0%|  | 21.0M/5.68G [00:00<00:30, 184MB/s]\u001b[A\n",
      "\n",
      "\n",
      "spiece.model:   0%|                                 | 0.00/4.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'google/umt5-xxl/tokenizer.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6e197b4d3dbd71da14b4eb255f4fa91c9c1f2068b20a2de2472967ca3d22602b.incomplete'\n",
      "Downloading 'google/umt5-xxl/special_tokens_map.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/ahkChHUJFxEmOdq5GDFEmerRzCY=.14855e7052ffbb595057dfd791d293c1c940db2c.incomplete'\n",
      "Downloading 'google/umt5-xxl/tokenizer_config.json' to 'Wan2.1-T2V-1.3B/.cache/huggingface/download/google/umt5-xxl/vzaExXFZNBay89bvlQv-ZcI6BTg=.4e1cc1cd85599ce0b47fd0a746af188fe4043ff2.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   0%|              | 0.00/11.4G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "special_tokens_map.json: 6.62kB [00:00, 22.8MB/s]A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/special_tokens_map.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spiece.model: 100%|████████████████████████| 4.55M/4.55M [00:00<00:00, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Wan2.1_VAE.pth:  14%|███▍                    | 73.4M/508M [00:00<00:02, 183MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer_config.json: 61.7kB [00:00, 160MB/s][A\u001b[A\n",
      "\n",
      "diffusion_pytorch_model.safetensors:   1%|  | 41.9M/5.68G [00:00<00:28, 195MB/s]\u001b[ADownload complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/spiece.model\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/tokenizer_config.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|███████████████████████| 16.8M/16.8M [00:00<00:00, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   0%|      | 21.0M/11.4G [00:00<01:14, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownload complete. Moving file to Wan2.1-T2V-1.3B/google/umt5-xxl/tokenizer.json\n",
      "\n",
      "\n",
      "Wan2.1_VAE.pth:  19%|████▍                   | 94.4M/508M [00:00<00:02, 184MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   1%|  | 62.9M/5.68G [00:00<00:28, 194MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   0%|      | 52.4M/11.4G [00:00<00:56, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  25%|██████▏                  | 126M/508M [00:00<00:01, 209MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   2%|  | 94.4M/5.68G [00:00<00:25, 218MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   1%|      | 83.9M/11.4G [00:00<00:53, 210MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  31%|███████▋                 | 157M/508M [00:00<00:01, 224MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   2%|   | 126M/5.68G [00:00<00:24, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   1%|       | 115M/11.4G [00:00<00:51, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  37%|█████████▎               | 189M/508M [00:00<00:01, 235MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   3%|   | 157M/5.68G [00:00<00:22, 240MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   1%|       | 147M/11.4G [00:00<00:48, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  43%|██████████▊              | 220M/508M [00:01<00:01, 244MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   3%|   | 189M/5.68G [00:00<00:22, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   2%|       | 178M/11.4G [00:00<00:47, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  50%|████████████▍            | 252M/508M [00:01<00:01, 244MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   4%|   | 220M/5.68G [00:00<00:22, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   2%|▏      | 210M/11.4G [00:00<00:46, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  56%|█████████████▉           | 283M/508M [00:01<00:00, 247MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   4%|▏  | 252M/5.68G [00:01<00:22, 246MB/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  62%|███████████████▍         | 315M/508M [00:01<00:00, 250MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   2%|▏      | 241M/11.4G [00:01<00:45, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   5%|▏  | 283M/5.68G [00:01<00:21, 247MB/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  68%|█████████████████        | 346M/508M [00:01<00:00, 252MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   2%|▏      | 273M/11.4G [00:01<00:45, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   6%|▏  | 315M/5.68G [00:01<00:21, 250MB/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  74%|██████████████████▌      | 377M/508M [00:01<00:00, 255MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   3%|▏      | 304M/11.4G [00:01<00:44, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   6%|▏  | 346M/5.68G [00:01<00:21, 253MB/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  81%|████████████████████▏    | 409M/508M [00:01<00:00, 256MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   7%|▏  | 377M/5.68G [00:01<00:20, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   3%|▏      | 336M/11.4G [00:01<00:45, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  87%|█████████████████████▋   | 440M/508M [00:01<00:00, 256MB/s]\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   7%|▏  | 409M/5.68G [00:01<00:20, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   3%|▏      | 367M/11.4G [00:01<00:45, 244MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   8%|▏  | 440M/5.68G [00:01<00:20, 253MB/s]\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  93%|███████████████████████▏ | 472M/508M [00:02<00:00, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   4%|▏      | 398M/11.4G [00:01<00:46, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:   8%|▏  | 472M/5.68G [00:01<00:20, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   4%|▎      | 430M/11.4G [00:01<00:46, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Wan2.1_VAE.pth:  99%|████████████████████████▊| 503M/508M [00:02<00:00, 199MB/s]\u001b[A\u001b[A\n",
      "Wan2.1_VAE.pth: 100%|█████████████████████████| 508M/508M [00:02<00:00, 222MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   4%|▎      | 461M/11.4G [00:01<00:44, 244MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownload complete. Moving file to Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\n",
      "Fetching 22 files:  18%|████▌                    | 4/22 [00:02<00:12,  1.48it/s]\n",
      "diffusion_pytorch_model.safetensors:   9%|▎  | 535M/5.68G [00:02<00:19, 259MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  10%|▎  | 566M/5.68G [00:02<00:19, 258MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   4%|▎      | 493M/11.4G [00:02<00:53, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   5%|▎      | 524M/11.4G [00:02<00:50, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  11%|▎  | 598M/5.68G [00:02<00:20, 244MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  11%|▎  | 629M/5.68G [00:02<00:20, 249MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   5%|▎      | 556M/11.4G [00:02<00:52, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  12%|▎  | 661M/5.68G [00:02<00:20, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   5%|▎      | 587M/11.4G [00:02<00:53, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  12%|▎  | 692M/5.68G [00:02<00:20, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   5%|▍      | 619M/11.4G [00:02<00:51, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  13%|▍  | 724M/5.68G [00:02<00:19, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   6%|▍      | 650M/11.4G [00:02<00:48, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  13%|▍  | 755M/5.68G [00:03<00:19, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   6%|▍      | 682M/11.4G [00:03<00:47, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  14%|▍  | 786M/5.68G [00:03<00:19, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   6%|▍      | 713M/11.4G [00:03<00:46, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  14%|▍  | 818M/5.68G [00:03<00:19, 246MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   7%|▍      | 744M/11.4G [00:03<00:45, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  15%|▍  | 849M/5.68G [00:03<00:19, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   7%|▍      | 776M/11.4G [00:03<00:44, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  16%|▍  | 881M/5.68G [00:03<00:18, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   7%|▍      | 807M/11.4G [00:03<00:43, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  16%|▍  | 912M/5.68G [00:03<00:18, 258MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  17%|▍  | 944M/5.68G [00:03<00:18, 261MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   7%|▌      | 839M/11.4G [00:03<00:43, 240MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  17%|▌  | 975M/5.68G [00:03<00:18, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   8%|▌      | 870M/11.4G [00:03<00:45, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  18%|▎ | 1.01G/5.68G [00:04<00:19, 241MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   8%|▌      | 902M/11.4G [00:03<00:44, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  18%|▎ | 1.04G/5.68G [00:04<00:18, 244MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   8%|▌      | 933M/11.4G [00:04<00:45, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  19%|▍ | 1.07G/5.68G [00:04<00:18, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   8%|▌      | 965M/11.4G [00:04<00:45, 230MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  19%|▍ | 1.10G/5.68G [00:04<00:18, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   9%|▌      | 996M/11.4G [00:04<00:44, 233MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  20%|▍ | 1.13G/5.68G [00:04<00:18, 251MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   9%|▌     | 1.03G/11.4G [00:04<00:43, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  21%|▍ | 1.16G/5.68G [00:04<00:17, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:   9%|▌     | 1.06G/11.4G [00:04<00:42, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  21%|▍ | 1.20G/5.68G [00:04<00:17, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  10%|▌     | 1.09G/11.4G [00:04<00:43, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  22%|▍ | 1.23G/5.68G [00:04<00:17, 255MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  22%|▍ | 1.26G/5.68G [00:05<00:17, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  10%|▌     | 1.12G/11.4G [00:04<00:47, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  23%|▍ | 1.29G/5.68G [00:05<00:17, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  10%|▌     | 1.15G/11.4G [00:05<00:48, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  23%|▍ | 1.32G/5.68G [00:05<00:17, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  10%|▋     | 1.18G/11.4G [00:05<00:46, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  24%|▍ | 1.35G/5.68G [00:05<00:17, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  11%|▋     | 1.22G/11.4G [00:05<00:45, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  24%|▍ | 1.38G/5.68G [00:05<00:18, 228MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  11%|▋     | 1.25G/11.4G [00:05<00:45, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  25%|▍ | 1.42G/5.68G [00:05<00:18, 232MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  11%|▋     | 1.28G/11.4G [00:05<00:43, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  25%|▌ | 1.45G/5.68G [00:05<00:17, 238MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  12%|▋     | 1.31G/11.4G [00:05<00:43, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  26%|▌ | 1.48G/5.68G [00:06<00:18, 229MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  12%|▋     | 1.34G/11.4G [00:05<00:42, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  27%|▌ | 1.51G/5.68G [00:06<00:17, 234MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  12%|▋     | 1.37G/11.4G [00:06<00:41, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  27%|▌ | 1.54G/5.68G [00:06<00:16, 244MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  12%|▋     | 1.41G/11.4G [00:06<00:40, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  28%|▌ | 1.57G/5.68G [00:06<00:16, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  13%|▊     | 1.44G/11.4G [00:06<00:41, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  28%|▌ | 1.60G/5.68G [00:06<00:16, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  13%|▊     | 1.47G/11.4G [00:06<00:42, 231MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  29%|▌ | 1.64G/5.68G [00:06<00:16, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  13%|▊     | 1.50G/11.4G [00:06<00:44, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  29%|▌ | 1.67G/5.68G [00:06<00:16, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  13%|▊     | 1.53G/11.4G [00:06<00:44, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  30%|▌ | 1.70G/5.68G [00:06<00:15, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  14%|▊     | 1.56G/11.4G [00:06<00:44, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  30%|▌ | 1.73G/5.68G [00:07<00:15, 252MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  31%|▌ | 1.76G/5.68G [00:07<00:15, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  14%|▊     | 1.59G/11.4G [00:06<00:42, 227MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  32%|▋ | 1.79G/5.68G [00:07<00:15, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  14%|▊     | 1.63G/11.4G [00:07<00:41, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  32%|▋ | 1.82G/5.68G [00:07<00:15, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  15%|▊     | 1.66G/11.4G [00:07<00:41, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  33%|▋ | 1.86G/5.68G [00:07<00:15, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  15%|▉     | 1.69G/11.4G [00:07<00:40, 241MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  33%|▋ | 1.89G/5.68G [00:07<00:15, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  15%|▉     | 1.72G/11.4G [00:07<00:41, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  34%|▋ | 1.92G/5.68G [00:07<00:15, 240MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  15%|▉     | 1.75G/11.4G [00:07<00:39, 242MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  16%|▉     | 1.78G/11.4G [00:07<00:38, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  34%|▋ | 1.95G/5.68G [00:07<00:15, 243MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  35%|▋ | 1.98G/5.68G [00:08<00:14, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  16%|▉     | 1.81G/11.4G [00:07<00:38, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  35%|▋ | 2.01G/5.68G [00:08<00:14, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  16%|▉     | 1.85G/11.4G [00:08<00:38, 247MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  17%|▉     | 1.88G/11.4G [00:08<00:39, 243MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  36%|▋ | 2.04G/5.68G [00:08<00:15, 235MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  37%|▋ | 2.08G/5.68G [00:08<00:14, 244MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  17%|█     | 1.91G/11.4G [00:08<00:38, 244MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  17%|█     | 1.94G/11.4G [00:08<00:38, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  37%|▋ | 2.11G/5.68G [00:08<00:14, 244MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  38%|▊ | 2.14G/5.68G [00:08<00:14, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  17%|█     | 1.97G/11.4G [00:08<00:38, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  38%|▊ | 2.17G/5.68G [00:08<00:13, 251MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  18%|█     | 2.00G/11.4G [00:08<00:38, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  39%|▊ | 2.20G/5.68G [00:08<00:13, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  18%|█     | 2.03G/11.4G [00:08<00:37, 247MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  39%|▊ | 2.23G/5.68G [00:09<00:13, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  18%|█     | 2.07G/11.4G [00:08<00:37, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  40%|▊ | 2.26G/5.68G [00:09<00:13, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  18%|█     | 2.10G/11.4G [00:09<00:42, 220MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  40%|▊ | 2.30G/5.68G [00:09<00:13, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  19%|█     | 2.13G/11.4G [00:09<00:41, 221MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  41%|▊ | 2.33G/5.68G [00:09<00:13, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  19%|█▏    | 2.16G/11.4G [00:09<00:41, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  42%|▊ | 2.36G/5.68G [00:09<00:12, 258MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  42%|▊ | 2.39G/5.68G [00:09<00:13, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  19%|█▏    | 2.19G/11.4G [00:09<00:41, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  43%|▊ | 2.42G/5.68G [00:09<00:12, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  20%|█▏    | 2.22G/11.4G [00:09<00:40, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  43%|▊ | 2.45G/5.68G [00:09<00:12, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  20%|█▏    | 2.25G/11.4G [00:09<00:38, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  44%|▉ | 2.49G/5.68G [00:10<00:12, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  20%|█▏    | 2.29G/11.4G [00:09<00:38, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  20%|█▏    | 2.32G/11.4G [00:10<00:38, 236MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  44%|▉ | 2.52G/5.68G [00:10<00:20, 151MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  21%|█▏    | 2.35G/11.4G [00:10<00:56, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  21%|█▎    | 2.37G/11.4G [00:10<01:11, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  45%|▉ | 2.54G/5.68G [00:10<00:30, 102MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  21%|█▎    | 2.40G/11.4G [00:10<01:00, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  21%|█▎    | 2.42G/11.4G [00:10<01:00, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  45%|▍| 2.56G/5.68G [00:11<00:35, 88.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█▎    | 2.44G/11.4G [00:11<01:04, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  45%|▍| 2.58G/5.68G [00:11<00:35, 88.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█▎    | 2.46G/11.4G [00:11<01:08, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  46%|▉ | 2.60G/5.68G [00:11<00:29, 103MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█▎    | 2.49G/11.4G [00:11<01:22, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  46%|▉ | 2.62G/5.68G [00:11<00:30, 101MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  47%|▍| 2.64G/5.68G [00:11<00:30, 99.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█    | 2.51G/11.4G [00:11<01:39, 89.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  47%|▍| 2.66G/5.68G [00:12<00:32, 93.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█    | 2.52G/11.4G [00:12<01:52, 79.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  22%|█    | 2.54G/11.4G [00:12<01:38, 89.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  47%|▍| 2.68G/5.68G [00:12<00:32, 92.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  23%|█▎    | 2.56G/11.4G [00:12<01:23, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  48%|▉ | 2.71G/5.68G [00:12<00:27, 107MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  48%|▉ | 2.73G/5.68G [00:12<00:26, 110MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  23%|█▎    | 2.59G/11.4G [00:12<01:13, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  23%|█▍    | 2.61G/11.4G [00:12<01:24, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  48%|▍| 2.75G/5.68G [00:13<00:33, 88.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  23%|█▍    | 2.63G/11.4G [00:13<01:19, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  49%|▉ | 2.78G/5.68G [00:13<00:26, 109MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  23%|█▍    | 2.66G/11.4G [00:13<01:02, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  49%|▉ | 2.80G/5.68G [00:13<00:22, 125MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▍    | 2.68G/11.4G [00:13<01:19, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  50%|▉ | 2.82G/5.68G [00:13<00:27, 104MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▍    | 2.71G/11.4G [00:13<01:15, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  50%|█ | 2.84G/5.68G [00:13<00:27, 102MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  50%|█ | 2.86G/5.68G [00:14<00:25, 110MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▍    | 2.73G/11.4G [00:13<01:24, 103MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  51%|█ | 2.88G/5.68G [00:14<00:25, 107MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  51%|█ | 2.90G/5.68G [00:14<00:22, 125MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▏   | 2.75G/11.4G [00:14<01:37, 87.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▏   | 2.76G/11.4G [00:14<01:44, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  52%|█ | 2.93G/5.68G [00:14<00:26, 104MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  24%|█▏   | 2.77G/11.4G [00:14<01:44, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▏   | 2.79G/11.4G [00:14<01:42, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  52%|▌| 2.95G/5.68G [00:14<00:30, 90.6MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  52%|▌| 2.97G/5.68G [00:15<00:31, 87.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▏   | 2.81G/11.4G [00:15<01:47, 79.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  52%|▌| 2.98G/5.68G [00:15<00:30, 89.6MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  53%|▌| 2.99G/5.68G [00:15<00:30, 88.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▏   | 2.83G/11.4G [00:15<01:44, 81.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  53%|█ | 3.02G/5.68G [00:15<00:26, 101MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▎   | 2.85G/11.4G [00:15<01:42, 83.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▎   | 2.86G/11.4G [00:15<01:42, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▎   | 2.87G/11.4G [00:15<01:53, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  54%|▌| 3.05G/5.68G [00:16<00:27, 97.0MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  54%|▌| 3.07G/5.68G [00:16<00:26, 98.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  25%|█▎   | 2.89G/11.4G [00:16<01:54, 73.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  54%|█ | 3.09G/5.68G [00:16<00:22, 115MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  26%|█▎   | 2.90G/11.4G [00:16<01:48, 78.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  55%|█ | 3.12G/5.68G [00:16<00:17, 144MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  26%|█▌    | 2.93G/11.4G [00:16<01:23, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  56%|█ | 3.16G/5.68G [00:16<00:14, 173MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  26%|█▌    | 2.96G/11.4G [00:16<00:59, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  56%|█ | 3.19G/5.68G [00:16<00:13, 190MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  26%|█▌    | 2.99G/11.4G [00:16<00:48, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  57%|█▏| 3.22G/5.68G [00:16<00:11, 209MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  27%|█▌    | 3.02G/11.4G [00:16<00:43, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  57%|█▏| 3.25G/5.68G [00:16<00:10, 221MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  27%|█▌    | 3.05G/11.4G [00:16<00:40, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  58%|█▏| 3.28G/5.68G [00:17<00:10, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  27%|█▋    | 3.08G/11.4G [00:17<00:41, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  58%|█▏| 3.31G/5.68G [00:17<00:09, 238MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  27%|█▋    | 3.10G/11.4G [00:17<00:41, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  59%|█▏| 3.34G/5.68G [00:17<00:09, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.12G/11.4G [00:17<00:43, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  59%|█▏| 3.38G/5.68G [00:17<00:09, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.15G/11.4G [00:17<00:43, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  60%|█▏| 3.41G/5.68G [00:17<00:09, 242MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.17G/11.4G [00:17<00:43, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  61%|█▏| 3.44G/5.68G [00:17<00:09, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.19G/11.4G [00:17<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  61%|█▏| 3.47G/5.68G [00:17<00:08, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.21G/11.4G [00:17<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  62%|█▏| 3.50G/5.68G [00:17<00:08, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  28%|█▋    | 3.23G/11.4G [00:17<00:43, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  62%|█▏| 3.53G/5.68G [00:18<00:08, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  29%|█▋    | 3.25G/11.4G [00:17<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  29%|█▋    | 3.27G/11.4G [00:18<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  63%|█▎| 3.57G/5.68G [00:18<00:08, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  29%|█▋    | 3.29G/11.4G [00:18<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  63%|█▎| 3.60G/5.68G [00:18<00:08, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  29%|█▋    | 3.31G/11.4G [00:18<00:43, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  64%|█▎| 3.63G/5.68G [00:18<00:08, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  29%|█▊    | 3.33G/11.4G [00:18<00:42, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  64%|█▎| 3.66G/5.68G [00:18<00:07, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.36G/11.4G [00:18<00:42, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  65%|█▎| 3.69G/5.68G [00:18<00:07, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.38G/11.4G [00:18<00:42, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  66%|█▎| 3.72G/5.68G [00:18<00:07, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.40G/11.4G [00:18<00:41, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  66%|█▎| 3.75G/5.68G [00:18<00:07, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.42G/11.4G [00:18<00:41, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.44G/11.4G [00:18<00:41, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  67%|█▎| 3.79G/5.68G [00:19<00:07, 245MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  30%|█▊    | 3.46G/11.4G [00:19<00:41, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  67%|█▎| 3.82G/5.68G [00:19<00:08, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  31%|█▊    | 3.48G/11.4G [00:19<00:42, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  68%|█▎| 3.85G/5.68G [00:19<00:07, 233MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  31%|█▊    | 3.50G/11.4G [00:19<00:41, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  68%|█▎| 3.88G/5.68G [00:19<00:07, 240MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  31%|█▊    | 3.52G/11.4G [00:19<00:41, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  69%|█▍| 3.91G/5.68G [00:19<00:07, 247MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  31%|█▊    | 3.54G/11.4G [00:19<00:40, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  31%|█▉    | 3.57G/11.4G [00:19<00:40, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  69%|█▍| 3.94G/5.68G [00:19<00:06, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.59G/11.4G [00:19<00:39, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  70%|█▍| 3.97G/5.68G [00:19<00:06, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.61G/11.4G [00:19<00:39, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  71%|█▍| 4.01G/5.68G [00:20<00:06, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.63G/11.4G [00:19<00:39, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  71%|█▍| 4.04G/5.68G [00:20<00:06, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.65G/11.4G [00:20<00:38, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  72%|█▍| 4.07G/5.68G [00:20<00:06, 260MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.67G/11.4G [00:20<00:38, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  72%|█▍| 4.10G/5.68G [00:20<00:06, 262MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  32%|█▉    | 3.69G/11.4G [00:20<00:38, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  73%|█▍| 4.13G/5.68G [00:20<00:05, 263MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  33%|█▉    | 3.71G/11.4G [00:20<00:38, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  73%|█▍| 4.16G/5.68G [00:20<00:05, 264MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  33%|█▉    | 3.73G/11.4G [00:20<00:38, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  33%|█▉    | 3.75G/11.4G [00:20<00:38, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  74%|█▍| 4.19G/5.68G [00:20<00:05, 267MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  33%|█▉    | 3.77G/11.4G [00:20<00:37, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  74%|█▍| 4.23G/5.68G [00:20<00:05, 260MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  33%|██    | 3.80G/11.4G [00:20<00:37, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  75%|█▌| 4.26G/5.68G [00:20<00:05, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  34%|██    | 3.82G/11.4G [00:20<00:37, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  76%|█▌| 4.29G/5.68G [00:21<00:05, 250MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  34%|██    | 3.84G/11.4G [00:20<00:37, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  76%|█▌| 4.32G/5.68G [00:21<00:05, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  34%|██    | 3.86G/11.4G [00:21<00:36, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  34%|██    | 3.88G/11.4G [00:21<00:36, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  77%|█▌| 4.35G/5.68G [00:21<00:05, 259MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  34%|██    | 3.90G/11.4G [00:21<00:36, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  77%|█▌| 4.38G/5.68G [00:21<00:04, 264MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██    | 3.92G/11.4G [00:21<00:36, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  78%|█▌| 4.41G/5.68G [00:21<00:04, 264MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██    | 3.94G/11.4G [00:21<00:36, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  78%|█▌| 4.45G/5.68G [00:21<00:04, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██    | 3.96G/11.4G [00:21<00:35, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  79%|█▌| 4.48G/5.68G [00:21<00:04, 259MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██    | 3.98G/11.4G [00:21<00:35, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██    | 4.01G/11.4G [00:21<00:35, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  79%|█▌| 4.51G/5.68G [00:21<00:04, 259MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  35%|██▏   | 4.03G/11.4G [00:21<00:35, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  80%|█▌| 4.54G/5.68G [00:22<00:04, 259MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  36%|██▏   | 4.05G/11.4G [00:21<00:35, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  81%|█▌| 4.57G/5.68G [00:22<00:04, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  36%|██▏   | 4.08G/11.4G [00:22<00:34, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  81%|█▌| 4.60G/5.68G [00:22<00:04, 258MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  36%|██▏   | 4.10G/11.4G [00:22<00:34, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  82%|█▋| 4.63G/5.68G [00:22<00:04, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  36%|██▏   | 4.12G/11.4G [00:22<00:34, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  82%|█▋| 4.67G/5.68G [00:22<00:03, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  36%|██▏   | 4.14G/11.4G [00:22<00:34, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  83%|█▋| 4.70G/5.68G [00:22<00:03, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  37%|██▏   | 4.17G/11.4G [00:22<00:34, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  83%|█▋| 4.73G/5.68G [00:22<00:03, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  37%|██▏   | 4.19G/11.4G [00:22<00:34, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  84%|█▋| 4.76G/5.68G [00:22<00:03, 258MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  37%|██▏   | 4.22G/11.4G [00:22<00:36, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  84%|█▋| 4.79G/5.68G [00:23<00:03, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  37%|██▏   | 4.25G/11.4G [00:22<00:33, 210MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  85%|█▋| 4.82G/5.68G [00:23<00:03, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  38%|██▎   | 4.28G/11.4G [00:23<00:33, 210MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  86%|█▋| 4.85G/5.68G [00:23<00:03, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  38%|██▎   | 4.31G/11.4G [00:23<00:33, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  86%|█▋| 4.89G/5.68G [00:23<00:03, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  38%|██▎   | 4.34G/11.4G [00:23<00:33, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  87%|█▋| 4.92G/5.68G [00:23<00:02, 256MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  87%|█▋| 4.95G/5.68G [00:23<00:02, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  38%|██▎   | 4.37G/11.4G [00:23<00:32, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  88%|█▊| 4.98G/5.68G [00:23<00:02, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  39%|██▎   | 4.40G/11.4G [00:23<00:32, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  88%|█▊| 5.01G/5.68G [00:23<00:02, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  39%|██▎   | 4.44G/11.4G [00:23<00:32, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  89%|█▊| 5.04G/5.68G [00:24<00:02, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  39%|██▎   | 4.47G/11.4G [00:23<00:32, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  89%|█▊| 5.08G/5.68G [00:24<00:02, 259MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  90%|█▊| 5.11G/5.68G [00:24<00:02, 258MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  40%|██▍   | 4.50G/11.4G [00:24<00:32, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  91%|█▊| 5.14G/5.68G [00:24<00:02, 256MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  40%|██▍   | 4.53G/11.4G [00:24<00:32, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  91%|█▊| 5.17G/5.68G [00:24<00:01, 261MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  40%|██▍   | 4.56G/11.4G [00:24<00:31, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  92%|█▊| 5.20G/5.68G [00:24<00:01, 252MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  40%|██▍   | 4.59G/11.4G [00:24<00:31, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  92%|█▊| 5.23G/5.68G [00:24<00:01, 246MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  41%|██▍   | 4.62G/11.4G [00:24<00:31, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  93%|█▊| 5.26G/5.68G [00:24<00:01, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  41%|██▍   | 4.66G/11.4G [00:24<00:31, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  93%|█▊| 5.30G/5.68G [00:25<00:01, 251MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  94%|█▉| 5.33G/5.68G [00:25<00:01, 257MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  41%|██▍   | 4.69G/11.4G [00:25<00:31, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  94%|█▉| 5.36G/5.68G [00:25<00:01, 261MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  42%|██▍   | 4.72G/11.4G [00:25<00:30, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  95%|█▉| 5.39G/5.68G [00:25<00:01, 266MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  42%|██▌   | 4.75G/11.4G [00:25<00:30, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  96%|█▉| 5.42G/5.68G [00:25<00:00, 263MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  42%|██▌   | 4.78G/11.4G [00:25<00:30, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  96%|█▉| 5.45G/5.68G [00:25<00:00, 255MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  42%|██▌   | 4.81G/11.4G [00:25<00:30, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  97%|█▉| 5.48G/5.68G [00:25<00:00, 251MB/s]\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  97%|█▉| 5.52G/5.68G [00:25<00:00, 254MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  43%|██▌   | 4.84G/11.4G [00:25<00:30, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  98%|█▉| 5.55G/5.68G [00:26<00:00, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  43%|██▌   | 4.88G/11.4G [00:25<00:30, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  98%|█▉| 5.58G/5.68G [00:26<00:00, 248MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  43%|██▌   | 4.91G/11.4G [00:26<00:30, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  99%|█▉| 5.61G/5.68G [00:26<00:00, 249MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  43%|██▌   | 4.94G/11.4G [00:26<00:30, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors:  99%|█▉| 5.64G/5.68G [00:26<00:00, 162MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  44%|██▌   | 4.97G/11.4G [00:26<00:38, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "diffusion_pytorch_model.safetensors: 100%|██| 5.68G/5.68G [00:26<00:00, 212MB/s]\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\n",
      "Fetching 22 files:  73%|█████████████████▍      | 16/22 [00:27<00:10,  1.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  44%|██▋   | 4.99G/11.4G [00:26<00:48, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  44%|██▋   | 5.01G/11.4G [00:26<00:52, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  44%|██▋   | 5.03G/11.4G [00:27<00:56, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  44%|██▋   | 5.05G/11.4G [00:27<00:57, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▋   | 5.08G/11.4G [00:27<00:55, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▋   | 5.10G/11.4G [00:27<01:00, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.12G/11.4G [00:28<01:10, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.13G/11.4G [00:28<01:17, 80.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.14G/11.4G [00:28<01:15, 82.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.15G/11.4G [00:28<01:28, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.16G/11.4G [00:28<01:34, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  45%|██▎  | 5.17G/11.4G [00:29<01:39, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.18G/11.4G [00:29<01:42, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.19G/11.4G [00:29<01:43, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.21G/11.4G [00:29<01:23, 73.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.22G/11.4G [00:29<01:21, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.23G/11.4G [00:30<01:35, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.25G/11.4G [00:30<01:25, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  46%|██▎  | 5.27G/11.4G [00:30<01:19, 76.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▎  | 5.30G/11.4G [00:30<01:12, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▎  | 5.32G/11.4G [00:30<01:03, 94.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▎  | 5.33G/11.4G [00:31<01:09, 87.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▎  | 5.35G/11.4G [00:31<01:09, 87.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▎  | 5.37G/11.4G [00:31<01:03, 94.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  47%|██▊   | 5.39G/11.4G [00:31<00:53, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  48%|██▊   | 5.42G/11.4G [00:31<00:42, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  48%|██▉   | 5.45G/11.4G [00:31<00:35, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  48%|██▉   | 5.48G/11.4G [00:31<00:32, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  49%|██▉   | 5.52G/11.4G [00:32<00:30, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  49%|██▉   | 5.55G/11.4G [00:32<00:29, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  49%|██▉   | 5.58G/11.4G [00:32<00:28, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  49%|██▉   | 5.61G/11.4G [00:32<00:29, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|██▉   | 5.63G/11.4G [00:32<00:31, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|██▉   | 5.65G/11.4G [00:32<00:32, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|██▉   | 5.67G/11.4G [00:33<00:33, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|███   | 5.69G/11.4G [00:33<00:33, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|███   | 5.71G/11.4G [00:33<00:34, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  50%|███   | 5.74G/11.4G [00:33<00:34, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  51%|███   | 5.76G/11.4G [00:33<00:34, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  51%|███   | 5.78G/11.4G [00:33<00:33, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  51%|███   | 5.80G/11.4G [00:33<00:33, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  51%|███   | 5.82G/11.4G [00:33<00:33, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  51%|███   | 5.84G/11.4G [00:34<00:33, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  52%|███   | 5.86G/11.4G [00:34<00:32, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  52%|███   | 5.88G/11.4G [00:34<00:32, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  52%|███   | 5.90G/11.4G [00:34<00:31, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  52%|███▏  | 5.92G/11.4G [00:34<00:31, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  52%|███▏  | 5.95G/11.4G [00:34<00:31, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  53%|███▏  | 5.97G/11.4G [00:34<00:31, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  53%|███▏  | 5.99G/11.4G [00:34<00:32, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  53%|███▏  | 6.01G/11.4G [00:35<00:31, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  53%|██▋  | 6.03G/11.4G [00:35<00:53, 99.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  53%|███▏  | 6.05G/11.4G [00:35<00:45, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▏  | 6.08G/11.4G [00:35<00:36, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▏  | 6.10G/11.4G [00:35<00:34, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▏  | 6.12G/11.4G [00:35<00:32, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▏  | 6.14G/11.4G [00:36<00:31, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▎  | 6.17G/11.4G [00:36<00:30, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  54%|███▎  | 6.19G/11.4G [00:36<00:29, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  55%|███▎  | 6.21G/11.4G [00:36<00:28, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  55%|███▎  | 6.23G/11.4G [00:36<00:27, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  55%|███▎  | 6.25G/11.4G [00:36<00:27, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  55%|███▎  | 6.27G/11.4G [00:36<00:27, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  55%|███▎  | 6.29G/11.4G [00:36<00:26, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▎  | 6.31G/11.4G [00:36<00:26, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▎  | 6.33G/11.4G [00:37<00:26, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▎  | 6.35G/11.4G [00:37<00:26, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▎  | 6.38G/11.4G [00:37<00:26, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▍  | 6.40G/11.4G [00:37<00:25, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  56%|███▍  | 6.42G/11.4G [00:37<00:25, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  57%|███▍  | 6.44G/11.4G [00:37<00:25, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  57%|███▍  | 6.46G/11.4G [00:37<00:24, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  57%|███▍  | 6.48G/11.4G [00:37<00:26, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  57%|███▍  | 6.50G/11.4G [00:37<00:25, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  57%|███▍  | 6.53G/11.4G [00:38<00:24, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  58%|███▍  | 6.55G/11.4G [00:38<00:24, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  58%|███▍  | 6.57G/11.4G [00:38<00:24, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  58%|███▍  | 6.60G/11.4G [00:38<00:23, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  58%|███▍  | 6.62G/11.4G [00:38<00:23, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  58%|███▌  | 6.64G/11.4G [00:38<00:23, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  59%|███▌  | 6.66G/11.4G [00:38<00:23, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  59%|███▌  | 6.68G/11.4G [00:38<00:23, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  59%|███▌  | 6.70G/11.4G [00:38<00:22, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  59%|███▌  | 6.72G/11.4G [00:39<00:26, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  59%|███▌  | 6.74G/11.4G [00:39<00:26, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  60%|███▌  | 6.77G/11.4G [00:39<00:30, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  60%|███▌  | 6.81G/11.4G [00:39<00:26, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  60%|███▌  | 6.84G/11.4G [00:39<00:23, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  60%|███▋  | 6.87G/11.4G [00:39<00:22, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  61%|███▋  | 6.89G/11.4G [00:39<00:22, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  61%|███▋  | 6.92G/11.4G [00:40<00:21, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  61%|███▋  | 6.94G/11.4G [00:40<00:21, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  61%|███▋  | 6.96G/11.4G [00:40<00:21, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  61%|███▋  | 6.98G/11.4G [00:40<00:21, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  62%|███▋  | 7.01G/11.4G [00:40<00:21, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  62%|███▋  | 7.04G/11.4G [00:40<00:20, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  62%|███▋  | 7.07G/11.4G [00:40<00:20, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  62%|███▋  | 7.09G/11.4G [00:40<00:20, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  63%|███▊  | 7.12G/11.4G [00:41<00:20, 210MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  63%|███▊  | 7.14G/11.4G [00:41<00:20, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  63%|███▊  | 7.17G/11.4G [00:41<00:19, 211MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  63%|███▊  | 7.20G/11.4G [00:41<00:19, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  64%|███▊  | 7.22G/11.4G [00:41<00:28, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  64%|███▊  | 7.25G/11.4G [00:41<00:27, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  64%|███▊  | 7.27G/11.4G [00:42<00:30, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  64%|███▊  | 7.29G/11.4G [00:42<00:30, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  64%|███▊  | 7.31G/11.4G [00:42<00:34, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▊  | 7.33G/11.4G [00:42<00:33, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▉  | 7.35G/11.4G [00:42<00:35, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▏ | 7.37G/11.4G [00:43<00:42, 93.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▏ | 7.38G/11.4G [00:43<00:46, 85.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▎ | 7.39G/11.4G [00:43<00:49, 80.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▎ | 7.41G/11.4G [00:43<00:43, 91.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▎ | 7.42G/11.4G [00:43<00:44, 87.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  65%|███▎ | 7.43G/11.4G [00:43<00:52, 74.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.46G/11.4G [00:44<00:45, 85.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.47G/11.4G [00:44<00:53, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.48G/11.4G [00:44<00:57, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.50G/11.4G [00:44<00:53, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.51G/11.4G [00:44<00:51, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.52G/11.4G [00:45<00:51, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.54G/11.4G [00:45<00:40, 95.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  66%|███▎ | 7.55G/11.4G [00:45<00:43, 88.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  67%|███▎ | 7.56G/11.4G [00:45<00:46, 81.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  67%|███▎ | 7.58G/11.4G [00:45<00:41, 91.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  67%|███▎ | 7.59G/11.4G [00:45<00:40, 93.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  67%|████  | 7.61G/11.4G [00:45<00:35, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  67%|████  | 7.64G/11.4G [00:46<00:30, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  68%|████  | 7.68G/11.4G [00:46<00:25, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  68%|████  | 7.71G/11.4G [00:46<00:21, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  68%|████  | 7.73G/11.4G [00:46<00:21, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  68%|████  | 7.75G/11.4G [00:46<00:21, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  68%|████  | 7.77G/11.4G [00:46<00:21, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  69%|████  | 7.79G/11.4G [00:47<00:22, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  69%|████▏ | 7.81G/11.4G [00:47<00:22, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  69%|████▏ | 7.83G/11.4G [00:47<00:22, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  69%|████▏ | 7.85G/11.4G [00:47<00:32, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  69%|████▏ | 7.89G/11.4G [00:47<00:25, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  70%|████▏ | 7.91G/11.4G [00:47<00:24, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  70%|████▏ | 7.93G/11.4G [00:48<00:23, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  70%|████▏ | 7.95G/11.4G [00:48<00:22, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  70%|████▏ | 7.97G/11.4G [00:48<00:22, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  70%|████▏ | 7.99G/11.4G [00:48<00:21, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▏ | 8.01G/11.4G [00:48<00:21, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▏ | 8.03G/11.4G [00:48<00:21, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▎ | 8.05G/11.4G [00:48<00:20, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▎ | 8.07G/11.4G [00:48<00:20, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▎ | 8.10G/11.4G [00:49<00:19, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  71%|████▎ | 8.12G/11.4G [00:49<00:19, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  72%|████▎ | 8.14G/11.4G [00:49<00:19, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  72%|████▎ | 8.16G/11.4G [00:49<00:19, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  72%|████▎ | 8.18G/11.4G [00:49<00:18, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  72%|████▎ | 8.20G/11.4G [00:49<00:18, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  72%|████▎ | 8.22G/11.4G [00:49<00:18, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▎ | 8.24G/11.4G [00:49<00:18, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▎ | 8.26G/11.4G [00:50<00:18, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▎ | 8.28G/11.4G [00:50<00:17, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▍ | 8.30G/11.4G [00:50<00:17, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▍ | 8.33G/11.4G [00:50<00:17, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  73%|████▍ | 8.35G/11.4G [00:50<00:17, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  74%|████▍ | 8.37G/11.4G [00:50<00:17, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  74%|████▍ | 8.39G/11.4G [00:50<00:17, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  74%|████▍ | 8.41G/11.4G [00:50<00:16, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  74%|████▍ | 8.43G/11.4G [00:50<00:16, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  74%|████▍ | 8.45G/11.4G [00:51<00:16, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▍ | 8.47G/11.4G [00:51<00:16, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▍ | 8.49G/11.4G [00:51<00:16, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▍ | 8.51G/11.4G [00:51<00:16, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▌ | 8.54G/11.4G [00:51<00:15, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▌ | 8.56G/11.4G [00:51<00:15, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  75%|████▌ | 8.58G/11.4G [00:51<00:15, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  76%|████▌ | 8.60G/11.4G [00:51<00:15, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  76%|████▌ | 8.62G/11.4G [00:52<00:15, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  76%|████▌ | 8.64G/11.4G [00:52<00:15, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  76%|████▌ | 8.66G/11.4G [00:52<00:15, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  76%|████▌ | 8.68G/11.4G [00:52<00:15, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  77%|████▌ | 8.70G/11.4G [00:52<00:14, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  77%|████▌ | 8.72G/11.4G [00:52<00:14, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  77%|████▌ | 8.75G/11.4G [00:52<00:14, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  77%|████▋ | 8.77G/11.4G [00:52<00:14, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  77%|████▋ | 8.79G/11.4G [00:52<00:14, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.81G/11.4G [00:53<00:14, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.83G/11.4G [00:53<00:14, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.85G/11.4G [00:53<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.87G/11.4G [00:53<00:14, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.89G/11.4G [00:53<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  78%|████▋ | 8.91G/11.4G [00:53<00:13, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  79%|████▋ | 8.93G/11.4G [00:53<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  79%|████▋ | 8.95G/11.4G [00:53<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  79%|████▋ | 8.98G/11.4G [00:54<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  79%|████▊ | 9.00G/11.4G [00:54<00:13, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  79%|████▊ | 9.02G/11.4G [00:54<00:12, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.04G/11.4G [00:54<00:12, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.06G/11.4G [00:54<00:12, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.08G/11.4G [00:54<00:12, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.10G/11.4G [00:54<00:12, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.12G/11.4G [00:54<00:12, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  80%|████▊ | 9.14G/11.4G [00:54<00:12, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  81%|████▊ | 9.16G/11.4G [00:55<00:12, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  81%|████▊ | 9.19G/11.4G [00:55<00:11, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  81%|████▊ | 9.21G/11.4G [00:55<00:11, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  81%|████▊ | 9.23G/11.4G [00:55<00:11, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  81%|████▉ | 9.25G/11.4G [00:55<00:11, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  82%|████▉ | 9.27G/11.4G [00:55<00:11, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  82%|████▉ | 9.29G/11.4G [00:55<00:11, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  82%|████▉ | 9.31G/11.4G [00:55<00:11, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  82%|████▉ | 9.33G/11.4G [00:55<00:11, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  82%|████▉ | 9.35G/11.4G [00:56<00:11, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|████▉ | 9.37G/11.4G [00:56<00:11, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|████▉ | 9.40G/11.4G [00:56<00:10, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|████▉ | 9.42G/11.4G [00:56<00:10, 186MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|████▉ | 9.44G/11.4G [00:56<00:11, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|████▉ | 9.46G/11.4G [00:56<00:10, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  83%|█████ | 9.48G/11.4G [00:56<00:10, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  84%|█████ | 9.50G/11.4G [00:57<00:16, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  84%|█████ | 9.52G/11.4G [00:57<00:14, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  84%|█████ | 9.54G/11.4G [00:57<00:14, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  84%|█████ | 9.56G/11.4G [00:57<00:12, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  84%|█████ | 9.58G/11.4G [00:57<00:14, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████ | 9.60G/11.4G [00:57<00:13, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████ | 9.63G/11.4G [00:58<00:14, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████ | 9.65G/11.4G [00:58<00:13, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████ | 9.67G/11.4G [00:58<00:13, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████ | 9.69G/11.4G [00:58<00:12, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  85%|█████▏| 9.71G/11.4G [00:58<00:11, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  86%|█████▏| 9.73G/11.4G [00:58<00:10, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  86%|█████▏| 9.75G/11.4G [00:58<00:09, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  86%|█████▏| 9.77G/11.4G [00:59<00:09, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  86%|█████▏| 9.79G/11.4G [00:59<00:09, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  86%|█████▏| 9.81G/11.4G [00:59<00:09, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.84G/11.4G [00:59<00:08, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.86G/11.4G [00:59<00:08, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.88G/11.4G [00:59<00:08, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.90G/11.4G [00:59<00:08, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.92G/11.4G [00:59<00:08, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  87%|█████▏| 9.94G/11.4G [01:00<00:09, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  88%|█████▎| 9.96G/11.4G [01:00<00:08, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  88%|█████▎| 9.98G/11.4G [01:00<00:09, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  88%|█████▎| 10.0G/11.4G [01:00<00:12, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  88%|████▍| 10.0G/11.4G [01:01<00:16, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  88%|████▍| 10.0G/11.4G [01:01<00:14, 89.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  89%|████▍| 10.1G/11.4G [01:01<00:13, 97.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  89%|█████▎| 10.1G/11.4G [01:01<00:11, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  89%|█████▎| 10.1G/11.4G [01:01<00:09, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  89%|█████▎| 10.1G/11.4G [01:01<00:08, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  89%|█████▎| 10.2G/11.4G [01:01<00:08, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▎| 10.2G/11.4G [01:01<00:07, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▍| 10.2G/11.4G [01:02<00:07, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▍| 10.2G/11.4G [01:02<00:08, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▍| 10.2G/11.4G [01:02<00:08, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▍| 10.3G/11.4G [01:02<00:07, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  90%|█████▍| 10.3G/11.4G [01:02<00:07, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  91%|█████▍| 10.3G/11.4G [01:02<00:07, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  91%|█████▍| 10.3G/11.4G [01:03<00:07, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  91%|█████▍| 10.3G/11.4G [01:03<00:07, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  91%|█████▍| 10.4G/11.4G [01:03<00:07, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  91%|█████▍| 10.4G/11.4G [01:03<00:06, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▍| 10.4G/11.4G [01:03<00:06, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▌| 10.4G/11.4G [01:03<00:06, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▌| 10.4G/11.4G [01:03<00:06, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▌| 10.5G/11.4G [01:04<00:06, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▌| 10.5G/11.4G [01:04<00:05, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  92%|█████▌| 10.5G/11.4G [01:04<00:05, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  93%|█████▌| 10.5G/11.4G [01:04<00:05, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  93%|█████▌| 10.5G/11.4G [01:04<00:05, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  93%|█████▌| 10.6G/11.4G [01:04<00:05, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  93%|█████▌| 10.6G/11.4G [01:04<00:04, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  93%|█████▌| 10.6G/11.4G [01:04<00:04, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  94%|█████▌| 10.6G/11.4G [01:05<00:04, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  94%|█████▋| 10.7G/11.4G [01:05<00:04, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  94%|█████▋| 10.7G/11.4G [01:05<00:04, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  94%|█████▋| 10.7G/11.4G [01:05<00:04, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  94%|█████▋| 10.7G/11.4G [01:05<00:03, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  95%|█████▋| 10.7G/11.4G [01:05<00:03, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  95%|█████▋| 10.8G/11.4G [01:05<00:03, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  95%|█████▋| 10.8G/11.4G [01:06<00:03, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  95%|█████▋| 10.8G/11.4G [01:06<00:04, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  95%|█████▋| 10.8G/11.4G [01:06<00:03, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▋| 10.9G/11.4G [01:06<00:03, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▋| 10.9G/11.4G [01:06<00:03, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▊| 10.9G/11.4G [01:06<00:02, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▊| 10.9G/11.4G [01:06<00:02, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▊| 10.9G/11.4G [01:07<00:02, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  96%|█████▊| 11.0G/11.4G [01:07<00:02, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  97%|█████▊| 11.0G/11.4G [01:07<00:02, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  97%|█████▊| 11.0G/11.4G [01:07<00:02, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  97%|█████▊| 11.0G/11.4G [01:07<00:02, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  97%|█████▊| 11.0G/11.4G [01:07<00:02, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  97%|█████▊| 11.1G/11.4G [01:07<00:02, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▊| 11.1G/11.4G [01:08<00:02, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▊| 11.1G/11.4G [01:08<00:01, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▉| 11.1G/11.4G [01:08<00:01, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▉| 11.1G/11.4G [01:08<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▉| 11.2G/11.4G [01:08<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  98%|█████▉| 11.2G/11.4G [01:08<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  99%|█████▉| 11.2G/11.4G [01:09<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  99%|█████▉| 11.2G/11.4G [01:09<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  99%|█████▉| 11.3G/11.4G [01:09<00:00, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  99%|█████▉| 11.3G/11.4G [01:09<00:00, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth:  99%|█████▉| 11.3G/11.4G [01:09<00:00, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth: 100%|█████▉| 11.3G/11.4G [01:09<00:00, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth: 100%|█████▉| 11.3G/11.4G [01:09<00:00, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "models_t5_umt5-xxl-enc-bf16.pth: 100%|██████| 11.4G/11.4G [01:10<00:00, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "Fetching 22 files: 100%|████████████████████████| 22/22 [01:10<00:00,  3.22s/it]\n",
      "/workspace/Wan2.1-T2V-1.3B\n"
     ]
    }
   ],
   "source": [
    "!pip install \"huggingface_hub[cli]\"\n",
    "!mkdir Wan2.1-T2V-1.3B\n",
    "!huggingface-cli download Wan-AI/Wan2.1-T2V-1.3B --local-dir ./Wan2.1-T2V-1.3B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3OwClJMLGc7L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac741eae3de840828538d5ecccdfae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import types\n",
    "from diffsynth.models import ModelManager\n",
    "from diffsynth.models.wan_video_dit import WanModel\n",
    "from diffsynth.models.wan_video_text_encoder import WanTextEncoder\n",
    "from diffsynth.models.wan_video_vae import WanVideoVAE\n",
    "from diffsynth.models.wan_video_image_encoder import WanImageEncoder\n",
    "from diffsynth.schedulers.flow_match import FlowMatchScheduler\n",
    "from diffsynth.pipelines.base import BasePipeline\n",
    "from diffsynth.prompters import WanPrompter\n",
    "import torch, os\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "from diffsynth.vram_management import enable_vram_management, AutoWrappedModule, AutoWrappedLinear\n",
    "from diffsynth.models.wan_video_text_encoder import T5RelativeEmbedding, T5LayerNorm\n",
    "from diffsynth.models.wan_video_dit import RMSNorm, sinusoidal_embedding_1d\n",
    "from diffsynth.models.wan_video_vae import RMS_norm, CausalConv3d, Upsample\n",
    "from diffsynth.models.wan_video_motion_controller import WanMotionControllerModel\n",
    "\n",
    "\n",
    "\n",
    "class WanVideoPipeline(BasePipeline):\n",
    "\n",
    "    def __init__(self, device=\"cuda\", torch_dtype=torch.float16, tokenizer_path=None):\n",
    "        super().__init__(device=device, torch_dtype=torch_dtype)\n",
    "        self.scheduler = FlowMatchScheduler(shift=5, sigma_min=0.0, extra_one_step=True)\n",
    "        self.prompter = WanPrompter(tokenizer_path=tokenizer_path)\n",
    "        self.text_encoder: WanTextEncoder = None\n",
    "        self.image_encoder: WanImageEncoder = None\n",
    "        self.dit: WanModel = None\n",
    "        self.vae: WanVideoVAE = None\n",
    "        self.motion_controller: WanMotionControllerModel = None\n",
    "        self.model_names = ['text_encoder', 'dit', 'vae', 'image_encoder', 'motion_controller']\n",
    "        self.height_division_factor = 16\n",
    "        self.width_division_factor = 16\n",
    "        self.use_unified_sequence_parallel = False\n",
    "\n",
    "\n",
    "    def enable_vram_management(self, num_persistent_param_in_dit=None):\n",
    "        dtype = next(iter(self.text_encoder.parameters())).dtype\n",
    "        enable_vram_management(\n",
    "            self.text_encoder,\n",
    "            module_map = {\n",
    "                torch.nn.Linear: AutoWrappedLinear,\n",
    "                torch.nn.Embedding: AutoWrappedModule,\n",
    "                T5RelativeEmbedding: AutoWrappedModule,\n",
    "                T5LayerNorm: AutoWrappedModule,\n",
    "            },\n",
    "            module_config = dict(\n",
    "                offload_dtype=dtype,\n",
    "                offload_device=\"cpu\",\n",
    "                onload_dtype=dtype,\n",
    "                onload_device=\"cpu\",\n",
    "                computation_dtype=self.torch_dtype,\n",
    "                computation_device=self.device,\n",
    "            ),\n",
    "        )\n",
    "        dtype = next(iter(self.dit.parameters())).dtype\n",
    "        enable_vram_management(\n",
    "            self.dit,\n",
    "            module_map = {\n",
    "                torch.nn.Linear: AutoWrappedLinear,\n",
    "                torch.nn.Conv3d: AutoWrappedModule,\n",
    "                torch.nn.LayerNorm: AutoWrappedModule,\n",
    "                RMSNorm: AutoWrappedModule,\n",
    "            },\n",
    "            module_config = dict(\n",
    "                offload_dtype=dtype,\n",
    "                offload_device=\"cpu\",\n",
    "                onload_dtype=dtype,\n",
    "                onload_device=self.device,\n",
    "                computation_dtype=self.torch_dtype,\n",
    "                computation_device=self.device,\n",
    "            ),\n",
    "            max_num_param=num_persistent_param_in_dit,\n",
    "            overflow_module_config = dict(\n",
    "                offload_dtype=dtype,\n",
    "                offload_device=\"cpu\",\n",
    "                onload_dtype=dtype,\n",
    "                onload_device=\"cpu\",\n",
    "                computation_dtype=self.torch_dtype,\n",
    "                computation_device=self.device,\n",
    "            ),\n",
    "        )\n",
    "        dtype = next(iter(self.vae.parameters())).dtype\n",
    "        enable_vram_management(\n",
    "            self.vae,\n",
    "            module_map = {\n",
    "                torch.nn.Linear: AutoWrappedLinear,\n",
    "                torch.nn.Conv2d: AutoWrappedModule,\n",
    "                RMS_norm: AutoWrappedModule,\n",
    "                CausalConv3d: AutoWrappedModule,\n",
    "                Upsample: AutoWrappedModule,\n",
    "                torch.nn.SiLU: AutoWrappedModule,\n",
    "                torch.nn.Dropout: AutoWrappedModule,\n",
    "            },\n",
    "            module_config = dict(\n",
    "                offload_dtype=dtype,\n",
    "                offload_device=\"cpu\",\n",
    "                onload_dtype=dtype,\n",
    "                onload_device=self.device,\n",
    "                computation_dtype=self.torch_dtype,\n",
    "                computation_device=self.device,\n",
    "            ),\n",
    "        )\n",
    "        if self.image_encoder is not None:\n",
    "            dtype = next(iter(self.image_encoder.parameters())).dtype\n",
    "            enable_vram_management(\n",
    "                self.image_encoder,\n",
    "                module_map = {\n",
    "                    torch.nn.Linear: AutoWrappedLinear,\n",
    "                    torch.nn.Conv2d: AutoWrappedModule,\n",
    "                    torch.nn.LayerNorm: AutoWrappedModule,\n",
    "                },\n",
    "                module_config = dict(\n",
    "                    offload_dtype=dtype,\n",
    "                    offload_device=\"cpu\",\n",
    "                    onload_dtype=dtype,\n",
    "                    onload_device=\"cpu\",\n",
    "                    computation_dtype=dtype,\n",
    "                    computation_device=self.device,\n",
    "                ),\n",
    "            )\n",
    "        if self.motion_controller is not None:\n",
    "            dtype = next(iter(self.motion_controller.parameters())).dtype\n",
    "            enable_vram_management(\n",
    "                self.motion_controller,\n",
    "                module_map = {\n",
    "                    torch.nn.Linear: AutoWrappedLinear,\n",
    "                },\n",
    "                module_config = dict(\n",
    "                    offload_dtype=dtype,\n",
    "                    offload_device=\"cpu\",\n",
    "                    onload_dtype=dtype,\n",
    "                    onload_device=\"cpu\",\n",
    "                    computation_dtype=dtype,\n",
    "                    computation_device=self.device,\n",
    "                ),\n",
    "            )\n",
    "        self.enable_cpu_offload()\n",
    "\n",
    "\n",
    "    def fetch_models(self, model_manager: ModelManager):\n",
    "        text_encoder_model_and_path = model_manager.fetch_model(\"wan_video_text_encoder\", require_model_path=True)\n",
    "        if text_encoder_model_and_path is not None:\n",
    "            self.text_encoder, tokenizer_path = text_encoder_model_and_path\n",
    "            self.prompter.fetch_models(self.text_encoder)\n",
    "            self.prompter.fetch_tokenizer(os.path.join(os.path.dirname(tokenizer_path), \"google/umt5-xxl\"))\n",
    "        self.dit = model_manager.fetch_model(\"wan_video_dit\")\n",
    "        self.vae = model_manager.fetch_model(\"wan_video_vae\")\n",
    "        self.image_encoder = model_manager.fetch_model(\"wan_video_image_encoder\")\n",
    "        self.motion_controller = model_manager.fetch_model(\"wan_video_motion_controller\")\n",
    "\n",
    "    @staticmethod\n",
    "    def from_model_manager(model_manager: ModelManager, torch_dtype=None, device=None, use_usp=False):\n",
    "        if device is None: device = model_manager.device\n",
    "        if torch_dtype is None: torch_dtype = model_manager.torch_dtype\n",
    "        pipe = WanVideoPipeline(device=device, torch_dtype=torch_dtype)\n",
    "        pipe.fetch_models(model_manager)\n",
    "        return pipe\n",
    "        # if use_usp:\n",
    "        #     from xfuser.core.distributed import get_sequence_parallel_world_size\n",
    "        #     from ..distributed.xdit_context_parallel import usp_attn_forward, usp_dit_forward\n",
    "\n",
    "        #     for block in pipe.dit.blocks:\n",
    "        #         block.self_attn.forward = types.MethodType(usp_attn_forward, block.self_attn)\n",
    "        #     pipe.dit.forward = types.MethodType(usp_dit_forward, pipe.dit)\n",
    "        #     pipe.sp_size = get_sequence_parallel_world_size()\n",
    "        #     pipe.use_unified_sequence_parallel = True\n",
    "        # return pipe\n",
    "\n",
    "\n",
    "\n",
    "    def denoising_model(self):\n",
    "        return self.dit\n",
    "\n",
    "\n",
    "    def encode_prompt(self, prompt, positive=True):\n",
    "        prompt_emb = self.prompter.encode_prompt(prompt, positive=positive, device=self.device)\n",
    "        return {\"context\": prompt_emb}\n",
    "\n",
    "\n",
    "    def encode_image(self, image, pseudo_video_path=None, mask_video_path=None, end_image=None, num_frames=81, height=480, width=832):\n",
    "        \"\"\"\n",
    "        Encode images and videos for I2V inference\n",
    "        Args:\n",
    "            image: First frame image (PIL Image)\n",
    "            pseudo_video_path: Pseudo video file path (new mode)\n",
    "            mask_video_path: Mask video file path (new mode)\n",
    "            end_image: End frame image (original mode)\n",
    "            num_frames: Number of frames\n",
    "            height, width: Video dimensions\n",
    "        \"\"\"\n",
    "        # New mode: Use pseudo video and mask video\n",
    "        # Original mode: use end_image (backward compatibility)\n",
    "\n",
    "        image = self.preprocess_image(image.resize((width, height))).to(self.device)\n",
    "        clip_context = self.image_encoder.encode_image([image])\n",
    "        msk = torch.ones(1, num_frames, height//8, width//8, device=self.device)\n",
    "        msk[:, 1:] = 0\n",
    "        if end_image is not None:\n",
    "            end_image = self.preprocess_image(end_image.resize((width, height))).to(self.device)\n",
    "            vae_input = torch.concat([image.transpose(0,1), torch.zeros(3, num_frames-2, height, width).to(image.device), end_image.transpose(0,1)],dim=1)\n",
    "            msk[:, -1:] = 1\n",
    "        else:\n",
    "            vae_input = torch.concat([image.transpose(0, 1), torch.zeros(3, num_frames-1, height, width).to(image.device)], dim=1)\n",
    "\n",
    "        msk = torch.concat([torch.repeat_interleave(msk[:, 0:1], repeats=4, dim=1), msk[:, 1:]], dim=1)\n",
    "        msk = msk.view(1, msk.shape[1] // 4, 4, height//8, width//8)\n",
    "        msk = msk.transpose(1, 2)[0]\n",
    "\n",
    "        y = self.vae.encode([vae_input.to(dtype=self.torch_dtype, device=self.device)], device=self.device)[0]\n",
    "        y = torch.concat([msk, y])\n",
    "        y = y.unsqueeze(0)\n",
    "        clip_context = clip_context.to(dtype=self.torch_dtype, device=self.device)\n",
    "        y = y.to(dtype=self.torch_dtype, device=self.device)\n",
    "        return {\"clip_feature\": clip_context, \"y\": y}\n",
    "\n",
    "\n",
    "    def encode_control_video(self, control_video, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
    "        control_video = self.preprocess_images(control_video)\n",
    "        # preprocess_images returns tensor list, each may be [1, 3, H, W], need to remove batch dimension\n",
    "        control_video = [tensor.squeeze(0) if tensor.dim() == 4 else tensor for tensor in control_video]\n",
    "        control_video = torch.stack(control_video, dim=1)  # [3, T, H, W]\n",
    "        control_video = control_video.to(dtype=self.torch_dtype, device=self.device)  # [3, T, H, W] - VAE expects this format\n",
    "        latents = self.encode_video(control_video, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride).to(dtype=self.torch_dtype, device=self.device)\n",
    "        return latents\n",
    "\n",
    "\n",
    "    def prepare_controlnet_kwargs(self, control_video, num_frames, height, width, clip_feature=None, y=None, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
    "        if control_video is not None:\n",
    "            control_latents = self.encode_control_video(control_video, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
    "            if clip_feature is None or y is None:\n",
    "                clip_feature = torch.zeros((1, 257, 1280), dtype=self.torch_dtype, device=self.device)\n",
    "                y = torch.zeros((1, 16, (num_frames - 1) // 4 + 1, height//8, width//8), dtype=self.torch_dtype, device=self.device)\n",
    "            else:\n",
    "                y = y[:, -16:]\n",
    "            y = torch.concat([control_latents, y], dim=1)\n",
    "        return {\"clip_feature\": clip_feature, \"y\": y}\n",
    "\n",
    "\n",
    "    def tensor2video(self, frames):\n",
    "        frames = rearrange(frames, \"C T H W -> T H W C\")\n",
    "        frames = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)\n",
    "        frames = [Image.fromarray(frame) for frame in frames]\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def prepare_extra_input(self, latents=None):\n",
    "        return {}\n",
    "\n",
    "\n",
    "    def encode_video(self, input_video, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
    "        latents = self.vae.encode(input_video, device=self.device, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
    "        return latents\n",
    "\n",
    "\n",
    "    def decode_video(self, latents, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):\n",
    "        frames = self.vae.decode(latents, device=self.device, tiled=tiled, tile_size=tile_size, tile_stride=tile_stride)\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def prepare_unified_sequence_parallel(self):\n",
    "        return {\"use_unified_sequence_parallel\": self.use_unified_sequence_parallel}\n",
    "\n",
    "\n",
    "    def prepare_motion_bucket_id(self, motion_bucket_id):\n",
    "        motion_bucket_id = torch.Tensor((motion_bucket_id,)).to(dtype=self.torch_dtype, device=self.device)\n",
    "        return {\"motion_bucket_id\": motion_bucket_id}\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        prompt,\n",
    "        negative_prompt=\"\",\n",
    "        input_image=None,\n",
    "        pseudo_video_path=None,\n",
    "        mask_video_path=None,\n",
    "        end_image=None,\n",
    "        input_video=None,\n",
    "        control_video=None,\n",
    "        denoising_strength=1.0,\n",
    "        seed=None,\n",
    "        rand_device=\"cpu\",\n",
    "        height=480,\n",
    "        width=832,\n",
    "        num_frames=81,\n",
    "        cfg_scale=5.0,\n",
    "        num_inference_steps=50,\n",
    "        sigma_shift=5.0,\n",
    "        motion_bucket_id=None,\n",
    "        tiled=True,\n",
    "        tile_size=(30, 52),\n",
    "        tile_stride=(15, 26),\n",
    "        tea_cache_l1_thresh=None,\n",
    "        tea_cache_model_id=\"\",\n",
    "        progress_bar_cmd=tqdm,\n",
    "        progress_bar_st=None,\n",
    "    ):\n",
    "        # Parameter check\n",
    "        height, width = self.check_resize_height_width(height, width)\n",
    "        if num_frames % 4 != 1:\n",
    "            num_frames = (num_frames + 2) // 4 * 4 + 1\n",
    "            print(f\"Only `num_frames % 4 != 1` is acceptable. We round it up to {num_frames}.\")\n",
    "\n",
    "        # Tiler parameters\n",
    "        tiler_kwargs = {\"tiled\": tiled, \"tile_size\": tile_size, \"tile_stride\": tile_stride}\n",
    "\n",
    "        # Scheduler\n",
    "        self.scheduler.set_timesteps(num_inference_steps, denoising_strength=denoising_strength, shift=sigma_shift)\n",
    "        # Original logic\n",
    "        noise = self.generate_noise(\n",
    "            (1, 16, (num_frames - 1) // 4 + 1, height//8, width//8),\n",
    "            seed=seed, device=rand_device, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        noise = noise.to(dtype=self.torch_dtype, device=self.device)\n",
    "        if input_video is not None:\n",
    "            self.load_models_to_device(['vae'])\n",
    "            input_video = self.preprocess_images(input_video)\n",
    "            # Remove possible batch dimension\n",
    "            input_video = [tensor.squeeze(0) if tensor.dim() == 4 else tensor for tensor in input_video]\n",
    "            input_video = torch.stack(input_video, dim=1)  # [3, T, H, W]\n",
    "            input_video = input_video.to(dtype=self.torch_dtype, device=self.device)  # [3, T, H, W] - VAE expects this format\n",
    "            latents = self.encode_video(input_video, **tiler_kwargs).to(dtype=self.torch_dtype, device=self.device)\n",
    "            latents = self.scheduler.add_noise(latents, noise, timestep=self.scheduler.timesteps[0])\n",
    "        else:\n",
    "            latents = noise\n",
    "\n",
    "        # Encode prompts\n",
    "        self.load_models_to_device([\"text_encoder\"])\n",
    "        prompt_emb_posi = self.encode_prompt(prompt, positive=True)\n",
    "        if cfg_scale != 1.0:\n",
    "            prompt_emb_nega = self.encode_prompt(negative_prompt, positive=False)\n",
    "\n",
    "        # Encode image\n",
    "        if input_image is not None and self.image_encoder is not None:\n",
    "            self.load_models_to_device([\"image_encoder\", \"vae\"])\n",
    "            if pseudo_video_path is not None and mask_video_path is not None:\n",
    "                # New I2V mode\n",
    "                image_emb = self.encode_image(input_image, pseudo_video_path, mask_video_path)\n",
    "            else:\n",
    "                # Original mode (backward compatibility)\n",
    "                image_emb = self.encode_image(input_image, end_image=end_image, num_frames=num_frames, height=height, width=width)\n",
    "        else:\n",
    "            image_emb = {}\n",
    "\n",
    "        # ControlNet\n",
    "        if control_video is not None:\n",
    "            self.load_models_to_device([\"image_encoder\", \"vae\"])\n",
    "            image_emb = self.prepare_controlnet_kwargs(control_video, num_frames, height, width, **image_emb, **tiler_kwargs)\n",
    "\n",
    "        # Motion Controller\n",
    "        if self.motion_controller is not None and motion_bucket_id is not None:\n",
    "            motion_kwargs = self.prepare_motion_bucket_id(motion_bucket_id)\n",
    "        else:\n",
    "            motion_kwargs = {}\n",
    "\n",
    "        # Extra input\n",
    "        extra_input = self.prepare_extra_input(latents)\n",
    "\n",
    "        # TeaCache\n",
    "        tea_cache_posi = {\"tea_cache\": TeaCache(num_inference_steps, rel_l1_thresh=tea_cache_l1_thresh, model_id=tea_cache_model_id) if tea_cache_l1_thresh is not None else None}\n",
    "        tea_cache_nega = {\"tea_cache\": TeaCache(num_inference_steps, rel_l1_thresh=tea_cache_l1_thresh, model_id=tea_cache_model_id) if tea_cache_l1_thresh is not None else None}\n",
    "\n",
    "        # Unified Sequence Parallel\n",
    "        usp_kwargs = self.prepare_unified_sequence_parallel()\n",
    "\n",
    "        # Denoise\n",
    "        self.load_models_to_device([\"dit\", \"motion_controller\"])\n",
    "        for progress_id, timestep in enumerate(progress_bar_cmd(self.scheduler.timesteps)):\n",
    "            timestep = timestep.unsqueeze(0).to(dtype=self.torch_dtype, device=self.device)\n",
    "\n",
    "            # Inference\n",
    "            noise_pred_posi = model_fn_wan_video(\n",
    "                self.dit, motion_controller=self.motion_controller,\n",
    "                x=latents, timestep=timestep,\n",
    "                **prompt_emb_posi, **image_emb, **extra_input,\n",
    "                **tea_cache_posi, **usp_kwargs, **motion_kwargs\n",
    "            )\n",
    "            if cfg_scale != 1.0:\n",
    "                noise_pred_nega = model_fn_wan_video(\n",
    "                    self.dit, motion_controller=self.motion_controller,\n",
    "                    x=latents, timestep=timestep,\n",
    "                    **prompt_emb_nega, **image_emb, **extra_input,\n",
    "                    **tea_cache_nega, **usp_kwargs, **motion_kwargs\n",
    "                )\n",
    "                noise_pred = noise_pred_nega + cfg_scale * (noise_pred_posi - noise_pred_nega)\n",
    "            else:\n",
    "                noise_pred = noise_pred_posi\n",
    "\n",
    "            # Scheduler\n",
    "            latents = self.scheduler.step(noise_pred, self.scheduler.timesteps[progress_id], latents)\n",
    "\n",
    "        # Decode\n",
    "        self.load_models_to_device(['vae'])\n",
    "        frames = self.decode_video(latents, **tiler_kwargs)\n",
    "        self.load_models_to_device([])\n",
    "        frames = self.tensor2video(frames[0])\n",
    "\n",
    "        return frames\n",
    "\n",
    "class TeaCache:\n",
    "    def __init__(self, num_inference_steps, rel_l1_thresh, model_id):\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        self.step = 0\n",
    "        self.accumulated_rel_l1_distance = 0\n",
    "        self.previous_modulated_input = None\n",
    "        self.rel_l1_thresh = rel_l1_thresh\n",
    "        self.previous_residual = None\n",
    "        self.previous_hidden_states = None\n",
    "\n",
    "        self.coefficients_dict = {\n",
    "            \"Wan2.1-T2V-1.3B\": [-5.21862437e+04, 9.23041404e+03, -5.28275948e+02, 1.36987616e+01, -4.99875664e-02],\n",
    "            \"Wan2.1-T2V-14B\": [-3.03318725e+05, 4.90537029e+04, -2.65530556e+03, 5.87365115e+01, -3.15583525e-01],\n",
    "            \"Wan2.1-I2V-14B-480P\": [2.57151496e+05, -3.54229917e+04,  1.40286849e+03, -1.35890334e+01, 1.32517977e-01],\n",
    "            \"Wan2.1-I2V-14B-720P\": [ 8.10705460e+03,  2.13393892e+03, -3.72934672e+02,  1.66203073e+01, -4.17769401e-02],\n",
    "        }\n",
    "        if model_id not in self.coefficients_dict:\n",
    "            supported_model_ids = \", \".join([i for i in self.coefficients_dict])\n",
    "            raise ValueError(f\"{model_id} is not a supported TeaCache model id. Please choose a valid model id in ({supported_model_ids}).\")\n",
    "        self.coefficients = self.coefficients_dict[model_id]\n",
    "\n",
    "    def check(self, dit: WanModel, x, t_mod):\n",
    "        modulated_inp = t_mod.clone()\n",
    "        if self.step == 0 or self.step == self.num_inference_steps - 1:\n",
    "            should_calc = True\n",
    "            self.accumulated_rel_l1_distance = 0\n",
    "        else:\n",
    "            coefficients = self.coefficients\n",
    "            rescale_func = np.poly1d(coefficients)\n",
    "            self.accumulated_rel_l1_distance += rescale_func(((modulated_inp-self.previous_modulated_input).abs().mean() / self.previous_modulated_input.abs().mean()).cpu().item())\n",
    "            if self.accumulated_rel_l1_distance < self.rel_l1_thresh:\n",
    "                should_calc = False\n",
    "            else:\n",
    "                should_calc = True\n",
    "                self.accumulated_rel_l1_distance = 0\n",
    "        self.previous_modulated_input = modulated_inp\n",
    "        self.step += 1\n",
    "        if self.step == self.num_inference_steps:\n",
    "            self.step = 0\n",
    "        if should_calc:\n",
    "            self.previous_hidden_states = x.clone()\n",
    "        return not should_calc\n",
    "\n",
    "    def store(self, hidden_states):\n",
    "        self.previous_residual = hidden_states - self.previous_hidden_states\n",
    "        self.previous_hidden_states = None\n",
    "\n",
    "    def update(self, hidden_states):\n",
    "        hidden_states = hidden_states + self.previous_residual\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "\n",
    "def model_fn_wan_video(\n",
    "    dit: WanModel,\n",
    "    motion_controller: WanMotionControllerModel = None,\n",
    "    x: torch.Tensor = None,\n",
    "    timestep: torch.Tensor = None,\n",
    "    context: torch.Tensor = None,\n",
    "    clip_feature: Optional[torch.Tensor] = None,\n",
    "    y: Optional[torch.Tensor] = None,\n",
    "    tea_cache: TeaCache = None,\n",
    "    use_unified_sequence_parallel: bool = False,\n",
    "    motion_bucket_id: Optional[torch.Tensor] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    if use_unified_sequence_parallel:\n",
    "        import torch.distributed as dist\n",
    "        from xfuser.core.distributed import (get_sequence_parallel_rank,\n",
    "                                            get_sequence_parallel_world_size,\n",
    "                                            get_sp_group)\n",
    "\n",
    "    t = dit.time_embedding(sinusoidal_embedding_1d(dit.freq_dim, timestep))\n",
    "    t_mod = dit.time_projection(t).unflatten(1, (6, dit.dim))\n",
    "    if motion_bucket_id is not None and motion_controller is not None:\n",
    "        t_mod = t_mod + motion_controller(motion_bucket_id).unflatten(1, (6, dit.dim))\n",
    "    context = dit.text_embedding(context)\n",
    "\n",
    "    if dit.has_image_input:\n",
    "        x = torch.cat([x, y], dim=1)  # (b, c_x + c_y, f, h, w)\n",
    "        clip_embdding = dit.img_emb(clip_feature)\n",
    "        context = torch.cat([clip_embdding, context], dim=1)\n",
    "\n",
    "    x, (f, h, w) = dit.patchify(x)\n",
    "\n",
    "    freqs = torch.cat([\n",
    "        dit.freqs[0][:f].view(f, 1, 1, -1).expand(f, h, w, -1),\n",
    "        dit.freqs[1][:h].view(1, h, 1, -1).expand(f, h, w, -1),\n",
    "        dit.freqs[2][:w].view(1, 1, w, -1).expand(f, h, w, -1)\n",
    "    ], dim=-1).reshape(f * h * w, 1, -1).to(x.device)\n",
    "\n",
    "    # TeaCache\n",
    "    if tea_cache is not None:\n",
    "        tea_cache_update = tea_cache.check(dit, x, t_mod)\n",
    "    else:\n",
    "        tea_cache_update = False\n",
    "\n",
    "    # blocks\n",
    "    if use_unified_sequence_parallel:\n",
    "        if dist.is_initialized() and dist.get_world_size() > 1:\n",
    "            x = torch.chunk(x, get_sequence_parallel_world_size(), dim=1)[get_sequence_parallel_rank()]\n",
    "    if tea_cache_update:\n",
    "        x = tea_cache.update(x)\n",
    "    else:\n",
    "        for block in dit.blocks:\n",
    "            x = block(x, context, t_mod, freqs)\n",
    "        if tea_cache is not None:\n",
    "            tea_cache.store(x)\n",
    "\n",
    "    x = dit.head(x, t)\n",
    "    if use_unified_sequence_parallel:\n",
    "        if dist.is_initialized() and dist.get_world_size() > 1:\n",
    "            x = get_sp_group().all_gather(x, dim=1)\n",
    "    x = dit.unpatchify(x, (f, h, w))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HDa2jyJFGfMO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import re\n",
    "import random\n",
    "from PIL import Image\n",
    "from diffsynth import ModelManager, save_video, VideoData\n",
    "# from custom_wan_pipe import WanVideoPipeline\n",
    "\n",
    "# Florence model import - required dependency\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "# Global variables to store Florence model\n",
    "florence_model = None\n",
    "florence_processor = None\n",
    "\n",
    "def init_florence_model():\n",
    "    \"\"\"Initialize Florence model, only needs to be called once\"\"\"\n",
    "    global florence_model, florence_processor\n",
    "\n",
    "    if florence_model is not None and florence_processor is not None:\n",
    "        return True  # Model already loaded, no need to reload\n",
    "\n",
    "    print(\"Loading Florence model, please wait...\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    # Load model and processor\n",
    "    florence_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"multimodalart/Florence-2-large-no-flash-attn\", torch_dtype=torch_dtype, trust_remote_code=True\n",
    "    ).to(device)\n",
    "\n",
    "    florence_processor = AutoProcessor.from_pretrained(\n",
    "        \"multimodalart/Florence-2-large-no-flash-attn\", trust_remote_code=True\n",
    "    )\n",
    "    print(\"Florence model loaded successfully\")\n",
    "    return True\n",
    "\n",
    "def generate_caption(image, concept_prefix=\"\"):\n",
    "    \"\"\"Use Florence model to generate caption for image\"\"\"\n",
    "    global florence_model, florence_processor\n",
    "\n",
    "    if florence_model is None or florence_processor is None:\n",
    "        raise RuntimeError(\"Florence model not initialized, please call init_florence_model() first\")\n",
    "\n",
    "    device = next(florence_model.parameters()).device\n",
    "    torch_dtype = next(florence_model.parameters()).dtype\n",
    "\n",
    "    # If input is a path, read image; if PIL Image object, use directly\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image).convert(\"RGB\")\n",
    "    elif hasattr(image, 'convert'):\n",
    "        image = image.convert(\"RGB\")\n",
    "    else:\n",
    "        # If it's a numpy array, convert to PIL Image\n",
    "        if hasattr(image, 'shape'):\n",
    "            image = Image.fromarray(image).convert(\"RGB\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported image format\")\n",
    "\n",
    "    prompt = \"<DETAILED_CAPTION>\"\n",
    "\n",
    "    # Construct input\n",
    "    inputs = florence_processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "\n",
    "    # Generate caption\n",
    "    generated_ids = florence_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], pixel_values=inputs[\"pixel_values\"], max_new_tokens=1024, num_beams=3\n",
    "    )\n",
    "    generated_text = florence_processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    # Post-processing\n",
    "    parsed_answer = florence_processor.post_process_generation(\n",
    "        generated_text, task=prompt, image_size=(image.width, image.height)\n",
    "    )\n",
    "    caption_text = parsed_answer[\"<DETAILED_CAPTION>\"].replace(\"The image shows \", \"\")\n",
    "\n",
    "    # Add concept prefix\n",
    "    if concept_prefix:\n",
    "        caption_text = f\"{concept_prefix} {caption_text}\"\n",
    "\n",
    "    return caption_text\n",
    "\n",
    "def find_max_epoch_lora(data_dir, use_additional=False):\n",
    "    \"\"\"Find the lora file with maximum epoch\"\"\"\n",
    "    lora_dir_name = \"lora_additional\" if use_additional else \"lora\"\n",
    "    lora_base_dir = os.path.join(data_dir, lora_dir_name)\n",
    "    if not os.path.exists(lora_base_dir):\n",
    "        if use_additional:\n",
    "            raise FileNotFoundError(f\"Additional LoRA directory does not exist: {lora_base_dir}\\n\"\n",
    "                                  f\"Please train additional LoRA first using: python train.py --config {os.path.join(data_dir, 'configs', 'training_additional.toml')}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"LoRA directory does not exist: {lora_base_dir}\")\n",
    "\n",
    "    # Find all date directories\n",
    "    date_dirs = [d for d in os.listdir(lora_base_dir) if os.path.isdir(os.path.join(lora_base_dir, d))]\n",
    "    if not date_dirs:\n",
    "        raise FileNotFoundError(f\"No training directories found in LoRA directory: {lora_base_dir}\")\n",
    "\n",
    "    # Find the latest training directory (sorted by name, usually datetime format)\n",
    "    latest_date_dir = sorted(date_dirs)[-1]\n",
    "    date_dir_path = os.path.join(lora_base_dir, latest_date_dir)\n",
    "\n",
    "    # Find epoch directories\n",
    "    epoch_dirs = []\n",
    "    for item in os.listdir(date_dir_path):\n",
    "        item_path = os.path.join(date_dir_path, item)\n",
    "        if os.path.isdir(item_path) and item.startswith(\"epoch\"):\n",
    "            # Extract epoch number\n",
    "            match = re.search(r'epoch(\\d+)', item)\n",
    "            if match:\n",
    "                epoch_num = int(match.group(1))\n",
    "                epoch_dirs.append((epoch_num, item_path))\n",
    "\n",
    "    if not epoch_dirs:\n",
    "        raise FileNotFoundError(f\"No epoch directories found in {date_dir_path}\")\n",
    "\n",
    "    # Find maximum epoch\n",
    "    max_epoch_num, max_epoch_path = max(epoch_dirs, key=lambda x: x[0])\n",
    "    lora_file_path = os.path.join(max_epoch_path, \"adapter_model.safetensors\")\n",
    "\n",
    "    if not os.path.exists(lora_file_path):\n",
    "        raise FileNotFoundError(f\"LoRA file does not exist: {lora_file_path}\")\n",
    "\n",
    "    lora_type = \"additional\" if use_additional else \"standard\"\n",
    "    print(f\"Found {lora_type} LoRA file with maximum epoch: epoch{max_epoch_num} - {lora_file_path}\")\n",
    "    return lora_file_path\n",
    "\n",
    "def find_input_image(data_dir):\n",
    "    \"\"\"Find edited image, prioritize png, then jpg\"\"\"\n",
    "    png_path = os.path.join(data_dir, \"edited_image.png\")\n",
    "    jpg_path = os.path.join(data_dir, \"edited_image.jpg\")\n",
    "    # f\"1. Save the edited first frame (from {output_dir}/source_frames/00000.png) as: {output_dir}/edited_image.png (or .jpg)\",\n",
    "\n",
    "    if os.path.exists(png_path):\n",
    "        print(f\"Found edited image: {png_path}\")\n",
    "        return png_path\n",
    "    elif os.path.exists(jpg_path):\n",
    "        print(f\"Found edited image: {jpg_path}\")\n",
    "        return jpg_path\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Edited image does not exist, checked the following paths:\\n- {png_path}\\n- {jpg_path}\")\n",
    "\n",
    "def validate_paths(model_root_dir, data_dir):\n",
    "    \"\"\"Validate if paths exist\"\"\"\n",
    "    if not os.path.exists(model_root_dir):\n",
    "        raise FileNotFoundError(f\"Model root directory does not exist: {model_root_dir}\")\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"Data directory does not exist: {data_dir}\")\n",
    "\n",
    "    # Check required model files\n",
    "    required_files = [\n",
    "        # \"models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\",\n",
    "        \"models_t5_umt5-xxl-enc-bf16.pth\",\n",
    "        \"Wan2.1_VAE.pth\"\n",
    "    ]\n",
    "\n",
    "    for file_name in required_files:\n",
    "        file_path = os.path.join(model_root_dir, file_name)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Required model file does not exist: {file_path}\")\n",
    "\n",
    "    # Check diffusion model files\n",
    "    diffusion_model_pattern = os.path.join(model_root_dir, \"diffusion_pytorch_model*.safetensors\")\n",
    "    diffusion_model_files = glob.glob(diffusion_model_pattern)\n",
    "    if not diffusion_model_files:\n",
    "        raise FileNotFoundError(f\"No diffusion model files found, pattern: {diffusion_model_pattern}\")\n",
    "\n",
    "def main(model_root_dir, data_dir, use_additional=False):\n",
    "    \"\"\"Main function\"\"\"\n",
    "    try:\n",
    "        # Validate paths\n",
    "        print(\"Validating paths...\")\n",
    "        validate_paths(model_root_dir, data_dir)\n",
    "\n",
    "        # Infer various paths\n",
    "        print(\"Inferring paths...\")\n",
    "        lora_path = find_max_epoch_lora(data_dir, use_additional=use_additional)\n",
    "        input_image_path = find_input_image(data_dir)\n",
    "        # pseudo_video_path = os.path.join(data_dir, \"inference_rgb.mp4\")\n",
    "        # mask_video_path = os.path.join(data_dir, \"inference_mask.mp4\")\n",
    "\n",
    "        # # Check if video files exist\n",
    "        # if not os.path.exists(pseudo_video_path):\n",
    "        #     raise FileNotFoundError(f\"Pseudo video file does not exist: {pseudo_video_path}\")\n",
    "        # if not os.path.exists(mask_video_path):\n",
    "        #     raise FileNotFoundError(f\"Mask video file does not exist: {mask_video_path}\")\n",
    "\n",
    "        print(f\"Using paths:\")\n",
    "        print(f\"  Model root directory: {model_root_dir}\")\n",
    "        print(f\"  Data directory: {data_dir}\")\n",
    "        print(f\"  LoRA file: {lora_path}\")\n",
    "        print(f\"  Edited image: {input_image_path}\")\n",
    "\n",
    "        # Automatically find all safetensors files starting with diffusion_pytorch_model\n",
    "        diffusion_model_pattern = os.path.join(model_root_dir, \"diffusion_pytorch_model*.safetensors\")\n",
    "        diffusion_model_files = sorted(glob.glob(diffusion_model_pattern))\n",
    "\n",
    "        print(\"Loading models...\")\n",
    "        model_manager = ModelManager(device=\"cpu\")\n",
    "        # model_manager.load_models([\n",
    "        #     os.path.join(model_root_dir, \"models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth\"),\n",
    "        # ], torch_dtype=torch.float32)\n",
    "        model_manager.load_models([\n",
    "            diffusion_model_files,\n",
    "            os.path.join(model_root_dir, \"models_t5_umt5-xxl-enc-bf16.pth\"),\n",
    "            os.path.join(model_root_dir, \"Wan2.1_VAE.pth\"),\n",
    "        ], torch_dtype=torch.bfloat16)\n",
    "        model_manager.load_lora(lora_path, lora_alpha=1.0)\n",
    "        pipe = WanVideoPipeline.from_model_manager(model_manager, torch_dtype=torch.bfloat16, device=\"cuda\")\n",
    "        pipe.enable_vram_management(num_persistent_param_in_dit=0)\n",
    "\n",
    "        # Initialize Florence model\n",
    "        print(\"Initializing Florence model...\")\n",
    "        init_florence_model()\n",
    "\n",
    "        # Load edited image\n",
    "        input_image = Image.open(input_image_path)\n",
    "\n",
    "        # Read concept prefix from prefix.txt\n",
    "        prefix_file = os.path.join(data_dir, 'prefix.txt')\n",
    "        concept_prefix = \"\"\n",
    "        if os.path.exists(prefix_file):\n",
    "            try:\n",
    "                with open(prefix_file, 'r', encoding='utf-8') as f:\n",
    "                    concept_prefix = f.read().strip()\n",
    "                print(f\"Read concept prefix from {prefix_file}: {concept_prefix}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read prefix.txt file: {e}\")\n",
    "                concept_prefix = \"p3rs0n,\"  # Use default value\n",
    "        else:\n",
    "            print(f\"prefix.txt file not found: {prefix_file}, using default prefix\")\n",
    "            concept_prefix = \"p3rs0n,\"\n",
    "\n",
    "        # Dynamically generate prompt\n",
    "        print(\"Generating caption for edited image...\")\n",
    "        generated_prompt = generate_caption(input_image, concept_prefix=concept_prefix)\n",
    "        print(f\"Generated prompt: {generated_prompt}\")\n",
    "\n",
    "        # Generate random seed\n",
    "        random_seed = random.randint(0, 2**32 - 1)\n",
    "        print(f\"Using random seed: {random_seed}\")\n",
    "\n",
    "        print(\"Starting inference...\")\n",
    "        video = pipe(\n",
    "            prompt=generated_prompt,\n",
    "            negative_prompt=\"Overexposure, static, blurred details, subtitles, paintings, pictures, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, mutilated, redundant fingers, poorly painted hands, poorly painted faces, deformed, disfigured, deformed limbs, fused fingers, cluttered background, three legs, a lot of people in the background, upside down\",\n",
    "            input_image=input_image,\n",
    "            # pseudo_video_path=pseudo_video_path,\n",
    "            # mask_video_path=mask_video_path,\n",
    "            num_inference_steps=30,\n",
    "            seed=random_seed, tiled=True,\n",
    "            # TeaCache parameters\n",
    "            tea_cache_l1_thresh=0.275, # The larger this value is, the faster the speed, but the worse the visual quality.\n",
    "            tea_cache_model_id=\"Wan2.1-I2V-14B-480P\", # Choose one in (Wan2.1-T2V-1.3B, Wan2.1-T2V-14B, Wan2.1-I2V-14B-480P, Wan2.1-I2V-14B-720P).\n",
    "        )\n",
    "\n",
    "        output_path = os.path.join(data_dir, \"edited_video.mp4\")\n",
    "        save_video(video, output_path, fps=30, quality=5)\n",
    "        print(f\"Video saved to: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Video generation inference script\")\n",
    "#     parser.add_argument(\"--model_root_dir\", required=True, help=\"Model root directory path\")\n",
    "#     parser.add_argument(\"--data_dir\", required=True,    #     default=\"Wan2.1-T2V-1.3B\",\n",
    "#  help=\"Data directory path\")\n",
    "#     parser.add_argument(\"--additional\", action=\"store_true\",\n",
    "#                        help=\"Use additional LoRA model from lora_additional directory instead of standard lora directory\")\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     main(args.model_root_dir, args.data_dir, use_additional=args.additional) #여기까지 inference.py\n",
    "\n",
    "# python inference.py --model_root_dir ./Wan2.1-I2V-14B-480P --data_dir ./processed_data/your_sequence\n",
    "# Wan2.1-T2V-1.3B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "I1eA5yTdxufx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description=\"Video generation inference script\")\n",
    "# parser.add_argument(\"--model_root_dir\", required=False, default=\"Wan2.1-T2V-1.3B\",\n",
    "#                     help=\"Model root directory path\")\n",
    "# parser.add_argument(\"--data_dir\", required=False, default=\"/content/myfolder/data\",\n",
    "#                     help=\"Data directory path\")\n",
    "# parser.add_argument(\"--additional\", action=\"store_true\", default=\"Wan2.1-T2V-1.3B\",\n",
    "#                     help=\"Use additional LoRA model from lora_additional directory instead of standard lora directory\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# args, unknown = parser.parse_known_args()\n",
    "# config = ed(vars(args))\n",
    "from easydict import EasyDict as ed\n",
    "\n",
    "config = ed({\n",
    "    \"model_root_dir\": \"/workspace/Wan2.1-T2V-1.3B\",\n",
    "    \"data_dir\": \"/workspace/myfolder/data\",\n",
    "    \"additional\": False,  # or False\n",
    "}) #--additional을 cmd에 안적으면 false\n",
    "# main(config.model_root_dir, config.data_dir, use_additional=args.additional) #여기까지 inference.py\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBeu6uqTTLqb"
   },
   "outputs": [],
   "source": [
    "# Save your edited first frame as edited_image.png (or .jpg) in the data directory\n",
    "# Then run inference\n",
    "python inference.py --model_root_dir ./Wan2.1-I2V-14B-480P --data_dir ./processed_data/your_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1JyeJEmQVB1y"
   },
   "outputs": [],
   "source": [
    "!cp /workspace/myfolder/data/00000.jpg /workspace/myfolder/data/edited_image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jTHtr8v2xIt",
    "outputId": "3f5c1780-1656-4c37-8829-14b130dd9382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating paths...\n",
      "Inferring paths...\n",
      "Found standard LoRA file with maximum epoch: epoch10 - /workspace/myfolder/data/lora/20250726_08-49-03/epoch10/adapter_model.safetensors\n",
      "Found edited image: /workspace/myfolder/data/edited_image.jpg\n",
      "Using paths:\n",
      "  Model root directory: /workspace/Wan2.1-T2V-1.3B\n",
      "  Data directory: /workspace/myfolder/data\n",
      "  LoRA file: /workspace/myfolder/data/lora/20250726_08-49-03/epoch10/adapter_model.safetensors\n",
      "  Edited image: /workspace/myfolder/data/edited_image.jpg\n",
      "Loading models...\n",
      "Loading models from: ['/workspace/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors']\n",
      "    model_name: wan_video_dit model_class: WanModel\n",
      "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 16, 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 16, 'num_heads': 12, 'num_layers': 30, 'eps': 1e-06}\n",
      "    The following models are loaded: ['wan_video_dit'].\n",
      "Loading models from: /workspace/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "    model_name: wan_video_text_encoder model_class: WanTextEncoder\n",
      "    The following models are loaded: ['wan_video_text_encoder'].\n",
      "Loading models from: /workspace/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\n",
      "    model_name: wan_video_vae model_class: WanVideoVAE\n",
      "    The following models are loaded: ['wan_video_vae'].\n",
      "Loading LoRA models from file: /workspace/myfolder/data/lora/20250726_08-49-03/epoch10/adapter_model.safetensors\n",
      "    Adding LoRA to wan_video_dit (['/workspace/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors']).\n",
      "    300 tensors are updated.\n",
      "Using wan_video_text_encoder from /workspace/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth.\n",
      "Using wan_video_dit from ['/workspace/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors'].\n",
      "Using wan_video_vae from /workspace/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth.\n",
      "No wan_video_image_encoder models available.\n",
      "No wan_video_motion_controller models available.\n",
      "Initializing Florence model...\n",
      "Loading Florence model, please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82819d33a4b54737b34a4cc58ebdc6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91114b8ee0d74cf7bf6802666b72ab21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_florence2.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/multimodalart/Florence-2-large-no-flash-attn:\n",
      "- configuration_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4036acb3641c4e219cdf2143f35b10a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_florence2.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/multimodalart/Florence-2-large-no-flash-attn:\n",
      "- modeling_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3bcc8ad8674a0f953bd5022d91d031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9460039b5fde40fb8bb728904d08c378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6d006c91e74e16b3e412cd60c3f478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7928b417e4ee49dc97430e29666a13f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_florence2.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/multimodalart/Florence-2-large-no-flash-attn:\n",
      "- processing_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b97106348204b98ab683a7323a38ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139da9fb8d2544b7b286309f781ea223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ae17c8a9f543d2864af66de0c63a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence model loaded successfully\n",
      "prefix.txt file not found: /workspace/myfolder/data/prefix.txt, using default prefix\n",
      "Generating caption for edited image...\n",
      "Generated prompt: p3rs0n, a woman sitting on a couch, surrounded by cushions, using a laptop computer. The background is slightly blurred, giving the focus to the woman and her laptop.\n",
      "Using random seed: 769003855\n",
      "Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:50<00:00,  3.69s/it]\n",
      "VAE decoding: 100%|██████████| 9/9 [00:18<00:00,  2.00s/it]\n",
      "Saving video:   0%|          | 0/81 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving video: 100%|██████████| 81/81 [00:00<00:00, 83.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to: /workspace/myfolder/data/edited_video.mp4\n"
     ]
    }
   ],
   "source": [
    "main(config.model_root_dir, config.data_dir, use_additional=config.additional)\n",
    "#lora 폴더를 data폴더 안으로 집어넣기\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "apHladUpWN5t",
    "outputId": "0189aba5-36b9-4119-8bdb-6d90b44ce2e9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1-2206545329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_root_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_additional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "main(config.model_root_dir, config.data_dir, use_additional=config.additional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BJ5U5MbnEfB",
    "outputId": "973e3397-de63-458d-ecd0-9cc6f58fddee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/video\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "import decord\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def sample_video_frames(video_path, num_frames=None):\n",
    "    vr = decord.VideoReader(video_path)\n",
    "    total_frames = len(vr)\n",
    "\n",
    "    if num_frames is None:\n",
    "        frame_indices = np.arange(total_frames)\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        frame = vr[int(idx)].asnumpy()\n",
    "        pil_image = Image.fromarray(frame)\n",
    "        frames.append(pil_image)\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def compute_farneback_optical_flow(frames):\n",
    "    prev_gray = cv2.cvtColor(np.array(frames[0]), cv2.COLOR_BGR2GRAY)\n",
    "    flow_maps = []\n",
    "    magnitudes = []\n",
    "    angles = []\n",
    "    images = []\n",
    "    hsv = np.zeros_like(frames[0])\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    for frame in frames[1:]:\n",
    "        gray = cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY)\n",
    "        flow_map = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray,\n",
    "            gray,\n",
    "            flow=None,\n",
    "            pyr_scale=0.5,\n",
    "            levels=3,\n",
    "            winsize=15,\n",
    "            iterations=3,\n",
    "            poly_n=5,\n",
    "            poly_sigma=1.2,\n",
    "            flags=0,\n",
    "        )\n",
    "        magnitude, angle = cv2.cartToPolar(flow_map[..., 0], flow_map[..., 1])\n",
    "        hsv[..., 0] = angle * 180 / np.pi / 2\n",
    "        hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        flow_maps.append(flow_map)\n",
    "        magnitudes.append(magnitude)\n",
    "        angles.append(angle)\n",
    "        images.append(bgr)\n",
    "        prev_gray = gray\n",
    "    return flow_maps, magnitudes, angles, images\n",
    "\n",
    "\n",
    "def compute_lk_optical_flow(frames):\n",
    "    maxCorners = 50\n",
    "    feature_params = {\n",
    "        \"maxCorners\": maxCorners,\n",
    "        \"qualityLevel\": 0.3,\n",
    "        \"minDistance\": 7,\n",
    "        \"blockSize\": 7,\n",
    "    }\n",
    "    lk_params = {\n",
    "        \"winSize\": (15, 15),\n",
    "        \"maxLevel\": 2,\n",
    "        \"criteria\": (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    }\n",
    "    color = np.random.randint(0, 255, (maxCorners, 3))\n",
    "    old_frame = frames[0]\n",
    "    old_gray = cv2.cvtColor(np.array(old_frame), cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    for frame in frames[1:]:\n",
    "        frame_gray = cv2.cvtColor(np.array(frame), cv2.COLOR_BGR2GRAY)\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "            old_gray, frame_gray, p0, None, **lk_params\n",
    "        )\n",
    "        if p1 is not None:\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(\n",
    "                mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2\n",
    "            )\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _downscale_maps(flow_maps, downscale_size: int = 16):\n",
    "    return [\n",
    "        cv2.resize(\n",
    "            flow,\n",
    "            (downscale_size, int(flow.shape[0] * (downscale_size / flow.shape[1]))),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "        )\n",
    "        for flow in flow_maps\n",
    "    ]\n",
    "\n",
    "\n",
    "def _motion_score(flow_maps):\n",
    "    average_flow_map = np.mean(np.array(flow_maps), axis=0)\n",
    "    return np.mean(average_flow_map)\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    frames = sample_video_frames(video_path, num_frames=None)\n",
    "\n",
    "    farneback, _, _, _ = compute_farneback_optical_flow(frames)\n",
    "    farneback = float(_motion_score(_downscale_maps(farneback)))\n",
    "    lucas_kanade = float(_motion_score(compute_lk_optical_flow(frames)))\n",
    "\n",
    "    return {\n",
    "        \"motion_fb\": abs(farneback),\n",
    "        \"motion_lk\": lucas_kanade,\n",
    "    }\n",
    "\n",
    "\n",
    "# def parse_args():\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\n",
    "    #     \"--input_video_folder\",\n",
    "    #     type=str,\n",
    "    #     default=\"demo_result/model_name_input_video\",\n",
    "    # )\n",
    "    # parser.add_argument(\n",
    "    #     \"--output_json_folder\",\n",
    "    #     type=str,\n",
    "    #     default=\"demo_result/model_name_output_json\",\n",
    "    # )\n",
    "    # parser.add_argument(\"--num_workers\", type=int, default=32)\n",
    "    # return parser.parse_args()\n",
    "\n",
    "\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--input_video_folder\",\n",
    "#         type=str,\n",
    "#         default=\"content/video\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--output_json_folder\",\n",
    "#         type=str,\n",
    "#         default=\"content/output\",\n",
    "#     )\n",
    "#     parser.add_argument(\"--num_workers\", type=int, default=32)\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     # EasyDict로 변환\n",
    "#     config = ed(vars(args))\n",
    "\n",
    "#     return config\n",
    "# import argparse\n",
    "# from easydict import EasyDict as ed\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--input_video_folder\",\n",
    "        type=str,\n",
    "        default=\"/content/video\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_json_folder\",\n",
    "        type=str,\n",
    "        default=\"/content/output\",\n",
    "    )\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=32)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    config = ed(vars(args))\n",
    "    return config\n",
    "\n",
    "# 사용\n",
    "config = parse_args()\n",
    "print(config.input_video_folder)\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    input_video_folder = args.input_video_folder\n",
    "    output_json_folder = args.output_json_folder\n",
    "    num_workers = args.num_workers\n",
    "\n",
    "    output_json_file = os.path.join(output_json_folder, \"motionscore.json\")\n",
    "    os.makedirs(output_json_folder, exist_ok=True)\n",
    "\n",
    "    all_results = {}\n",
    "    video_files = [f for f in os.listdir(input_video_folder) if f.endswith(\".mp4\")]\n",
    "\n",
    "    def worker(filename):\n",
    "        video_path = os.path.join(input_video_folder, filename)\n",
    "        video_prefix = os.path.splitext(filename)[0]\n",
    "        motion_scores = process_video(video_path)\n",
    "        return video_prefix, motion_scores\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(worker, filename) for filename in video_files]\n",
    "        for future in as_completed(futures):\n",
    "            video_prefix, motion_scores = future.result()\n",
    "            all_results[video_prefix] = motion_scores\n",
    "\n",
    "    with open(output_json_file, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "\n",
    "    print(f\"All results have been saved to {output_json_file}\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CoBVLGcVn-C",
    "outputId": "0e63c56f-7360-487b-eb79-0cb5cc903dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results have been saved to /content/output/motionscore.json\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tA3y_1CNNHVy"
   },
   "outputs": [],
   "source": [
    "  !cp /content/drive/MyDrive/vlora/data/A.mp4 /content/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "kBFvqXaY20ZR",
    "outputId": "628531df-e419-4e84-ab43-4595dd383b87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: colab_kernel_launcher.py [-h] [--input_video_folder INPUT_VIDEO_FOLDER]\n",
      "                                [--output_json_folder OUTPUT_JSON_FOLDER]\n",
      "                                [--num_workers NUM_WORKERS]\n",
      "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-54a0da6b-b0ed-42cf-87c4-7a645fdd0d91.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--input_video_folder\",\n",
    "        type=str,\n",
    "        default=\"content/video\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_json_folder\",\n",
    "        type=str,\n",
    "        default=\"content/output\",\n",
    "    )\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=32)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # EasyDict로 변환\n",
    "    config = ed(vars(args))\n",
    "\n",
    "    return config\n",
    "\n",
    "# 사용 예시\n",
    "config = parse_args()\n",
    "print(config.input_video_folder)  # 'demo_result/model_name_input_video'\n",
    "print(config.num_workers)  # 32\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
